{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "760be327-e4b9-4808-a960-b4d7a426e22e",
   "metadata": {},
   "source": [
    "This file can either compute the Wasserstein, Bottleneck or Landscape distances to the \n",
    "Wasserstein, Bottleneck or the Landscape barycenters of each class.\n",
    "It can also compute the respective distances to the origin diagram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a81b9c9-a2e9-46c2-8ae8-4a5f02dd0571",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyedflib\n",
    "import statistics\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "from gtda.time_series import SingleTakensEmbedding\n",
    "from gtda.homology import VietorisRipsPersistence\n",
    "from gtda.diagrams import PersistenceEntropy, Amplitude, NumberOfPoints, ComplexPolynomial, PersistenceLandscape, HeatKernel, Silhouette, BettiCurve, PairwiseDistance, ForgetDimension\n",
    "import random\n",
    "from sklearn import preprocessing\n",
    "import plotly.io as pio\n",
    "from gtda.plotting import plot_diagram\n",
    "import h5py\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c5789b-3037-4003-b297-f304256b4831",
   "metadata": {},
   "source": [
    "# Choose parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "858bf09d-c57b-4e40-9d71-ee25d2b39dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose individuum\n",
    "subject = \"m292\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e2a0a0b-70e1-458e-bc66-32d88014bc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the distance metric here\n",
    "\n",
    "metric = \"wasserstein\"\n",
    "#metric = \"landscape\"\n",
    "#metric = \"bottleneck\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e477091-acd6-4c72-be90-fcdda79d795a",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e8fa954-7644-4d6a-a8f5-46084db65610",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = [0, 1, 2, 3, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6f5a8b2-8c1c-480b-8678-00aee6f13bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = {}\n",
    "\n",
    "for label in label_list:\n",
    "    filename = \"Data/\"+str(subject)+\"/run0\"+str(label)+\"/Brain_Imaging_Data.h5\"\n",
    "    file = h5py.File(filename,'r')\n",
    "    dataframes[label] = file['Data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85fd9907-0ecf-4827-bd57-da10d9c03cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load persistence diagrams\n",
    "\n",
    "persistence_diagrams = np.load('Embeddings_and_Persistence_Diagrams/'+str(subject)+'/Persistence_Diagrams.npy', \\\n",
    "                allow_pickle=True).item() # .item() to convert the dtype to dict again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ed7cd49-1db6-4679-a795-88fbf9b29ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_persistence_diagrams = np.load('Embeddings_and_Persistence_Diagrams/'+str(subject)+'/Extended_Persistence_Diagrams.npz', \\\n",
    "                allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87a3804-8096-4313-88ce-30faa8f19cde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cfb824a7-a2ba-44a2-b860-891bb2a702e2",
   "metadata": {},
   "source": [
    "# Computing the distance to the Wasserstein Barycenter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d656de-ce09-4239-83ec-345675529e21",
   "metadata": {},
   "source": [
    "## Wasserstein Barycenter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fd3f18-ecdd-4d6d-a6fe-38be70222f6a",
   "metadata": {},
   "source": [
    "The Wasserstein Barycenter is the most representative persistence diagram in a set of diagrams (of one class), so the one with the lowest overall (Wasserstein) distance to all other diagrams. Because it takes long to compute, we will for now only use a part of the data as training data. For now, these training samples can also be in the test set of the simple classifier in the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9da68b4-a267-4535-8ef9-111883c012ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will look at 0-, 1- and 2-dimensional holes\n",
    "homology_dimensions = [0, 1, 2]\n",
    "\n",
    "# We will use a Vietoris Rips filtrations\n",
    "persistence = VietorisRipsPersistence(\n",
    "    homology_dimensions=homology_dimensions, n_jobs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd31991-eaa1-415b-b484-3fb2ddbd736d",
   "metadata": {},
   "source": [
    "### Only take random subset of persistence diagrams into account (for computational efficiency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0883ee17-fb8b-409c-980f-28e7d51240b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO If I use the segment barycenters, use portion of segments here\n",
    "\n",
    "def get_random_subsets(extended_persistence_diagrams, subset_ratio):\n",
    "    \"\"\"\n",
    "    Selects a random subset of elements from each key in the provided dictionary of persistence diagrams.\n",
    "\n",
    "    Parameters:\n",
    "    - extended_persistence_diagrams (dict): A dictionary where each value is a list or array of persistence diagrams.\n",
    "    - subset_ratio (float): The ratio of elements to select from each list. Default is 0.15 (i.e., 15%).\n",
    "\n",
    "    Returns:\n",
    "    - random_subsets (dict): A new dictionary containing the random subsets.\n",
    "    \"\"\"\n",
    "    random_subsets = {}\n",
    "    \n",
    "    for key, value in extended_persistence_diagrams.items():\n",
    "        subset_size = int(len(value) * subset_ratio)\n",
    "        indices = np.arange(len(value))\n",
    "        random_indices = random.sample(sorted(indices), subset_size)\n",
    "        random_subsets[key] = value[random_indices]\n",
    "    \n",
    "    return random_subsets\n",
    "\n",
    "subset_ratio = (len(extended_persistence_diagrams[\"Label_0\"])-80*50)/len(extended_persistence_diagrams[\"Label_0\"])\n",
    "\n",
    "random_subsets = get_random_subsets(extended_persistence_diagrams, subset_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866a088b-5e7a-49f3-b02d-ba2939f6e89a",
   "metadata": {},
   "source": [
    "### Computing the Wasserstein Barycenter for all labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3fc51a-6957-457f-b4f5-fda96a39d555",
   "metadata": {},
   "source": [
    "Compute Wasserstein barycenter of each segment (but only using a portion of the diagrams in each segment for computational efficiency), and then compute the Wasserstein barycenter of all segment Wasserstein barycenters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3107113-4a6c-4f03-9d7e-fbe26f0855f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting computation for label 0\n",
      "Processing segment 0/75\n",
      "Processing pair 120/120Processing segment 1/75\n",
      "Processing pair 10/120"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from gtda.diagrams import PairwiseDistance\n",
    "from joblib import Parallel, delayed\n",
    "import sys\n",
    "\n",
    "\n",
    "def get_random_subsets(diagrams, subset_ratio):\n",
    "    \"\"\"\n",
    "    Selects a random subset of elements from each key in the provided dictionary of persistence diagrams.\n",
    "\n",
    "    Parameters:\n",
    "    - extended_persistence_diagrams (dict): A dictionary where each value is a list or array of persistence diagrams.\n",
    "    - subset_ratio (float): The ratio of elements to select from each list. Default is 0.15 (i.e., 15%).\n",
    "\n",
    "    Returns:\n",
    "    - random_subsets (dict): A new dictionary containing the random subsets.\n",
    "    \"\"\"\n",
    "    random_subsets = {}\n",
    "    \n",
    "    subset_size = int(len(diagrams) * subset_ratio)\n",
    "    indices = np.arange(len(diagrams))\n",
    "    random_indices = random.sample(sorted(indices), subset_size)\n",
    "    random_subsets = diagrams[random_indices]\n",
    "    \n",
    "    return random_subsets\n",
    "\n",
    "\n",
    "def custom_logger(idx, total_segments):\n",
    "    sys.stdout.write(f\"\\rProcessing pair {idx + 1}/{total_segments}\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "def compute_wasserstein_distances(diagrams):\n",
    "    n = len(diagrams)\n",
    "    total_pairs = (n * (n - 1)) // 2  # Total number of unique pairs\n",
    "    distances = np.zeros((n, n))\n",
    "    \n",
    "    # Initialize PairwiseDistance with the Wasserstein metric\n",
    "    pairwise_dist = PairwiseDistance(metric='wasserstein')\n",
    "    \n",
    "    def compute_pair(i, j, idx):\n",
    "        # Log progress\n",
    "        custom_logger(idx, total_pairs)\n",
    "        # Compute the Wasserstein distance between diagrams[i] and diagrams[j]\n",
    "        return pairwise_dist.fit_transform([diagrams[i], diagrams[j]])[0, 0]\n",
    "    \n",
    "    # Generate all unique pairs of indices (i, j)\n",
    "    pairs = [(i, j) for i in range(n) for j in range(i + 1, n)]\n",
    "    results = Parallel(n_jobs=-1)(delayed(compute_pair)(i, j, idx)\n",
    "                                  for idx, (i, j) in enumerate(pairs))\n",
    "    \n",
    "    for idx, dist in enumerate(results):\n",
    "        i, j = pairs[idx]\n",
    "        distances[i, j] = dist\n",
    "        distances[j, i] = dist\n",
    "    \n",
    "    return distances\n",
    "\n",
    "\n",
    "def find_barycenters_for_each_segment(diagrams, dataframes, label, subsample_size, n_jobs=-1):\n",
    "    # Initialize PairwiseDistance with the Wasserstein metric\n",
    "    pairwise_dist = PairwiseDistance(metric='wasserstein')\n",
    "\n",
    "    segment_length = 80 \n",
    "\n",
    "    segment_barycenters = []\n",
    "\n",
    "    for idx in range(int(len(diagrams) / segment_length)):\n",
    "\n",
    "        print(\"Processing segment \" + str(idx) + \"/\" + str(int(len(diagrams) / segment_length)))\n",
    "        \n",
    "        # Compute the pairwise Wasserstein distances\n",
    "        segment_diagrams = diagrams[segment_length * idx:segment_length * (idx+1)]\n",
    "\n",
    "        subsample_of_segment_diagrams = get_random_subsets(segment_diagrams, 0.2)        \n",
    "        \n",
    "        pairwise_wasserstein_distances_for_segment = compute_wasserstein_distances(subsample_of_segment_diagrams)\n",
    "\n",
    "        # For each hole, calculate the sum of distances to all other holes\n",
    "        sum_distances_for_segment = [sum(dist) for dist in pairwise_wasserstein_distances_for_segment]\n",
    "\n",
    "        # Find the index of the Wasserstein barycenter\n",
    "        most_representative_index_in_segment = np.argmin(sum_distances_for_segment)\n",
    "\n",
    "        # Wasserstein Barycenter for our label\n",
    "        most_representative_diagram_in_segment = persistence.fit_transform([dataframes[most_representative_index_in_segment]])\n",
    "\n",
    "        segment_barycenters.append(most_representative_diagram_in_segment[0])\n",
    "\n",
    "    return segment_barycenters\n",
    "\n",
    "\n",
    "def find_barycenter(diagrams, dataframes, label, subsample_size, n_jobs=-1):\n",
    "\n",
    "    segment_barycenters = find_barycenters_for_each_segment(diagrams, dataframes, label, subsample_size, n_jobs=-1)\n",
    "\n",
    "    print(segment_barycenters)\n",
    "\n",
    "    # Compute pairwise Wasserstein distances in parallel\n",
    "    pairwise_wasserstein_distances = compute_wasserstein_distances(segment_barycenters)\n",
    "\n",
    "    # For each diagram, calculate the sum of distances to all other diagrams\n",
    "    sum_distances = [sum(dist) for dist in pairwise_wasserstein_distances]\n",
    "\n",
    "    # Find the index of the Wasserstein barycenter\n",
    "    most_representative_index = np.argmin(sum_distances)\n",
    "\n",
    "    # Wasserstein Barycenter for our label\n",
    "    most_representative_diagram = persistence.fit_transform([dataframes[most_representative_index]])\n",
    "\n",
    "    fig = plot_diagram(most_representative_diagram[0])\n",
    "    fig.show()\n",
    "    pio.write_image(fig, 'Plots/BI_'+str(subject)+'_Label ' + str(label) + ' Most Representative Diagram (Extended Diagrams).png')\n",
    "\n",
    "    return most_representative_diagram\n",
    "\n",
    "representative_diagrams = {}  # barycenters for all labels\n",
    "\n",
    "for label in label_list:\n",
    "    print(\"Starting computation for label \" +str(label))\n",
    "    representative_diagrams[\"Label_\"+str(label)] = find_barycenter(extended_persistence_diagrams[\"Label_\"+str(label)], dataframes[label], label, subsample_size=0.3, n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d48846-64c3-4d01-bfd2-350ca37e930a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('Embeddings_and_Persistence_Diagrams/'+str(subject)+'/Most_Representative_Diagrams_(Extended_Diagrams).npy', \\\n",
    "            np.array(representative_diagrams, dtype=object), allow_pickle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
