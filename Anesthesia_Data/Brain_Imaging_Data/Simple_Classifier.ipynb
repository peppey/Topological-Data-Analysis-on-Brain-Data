{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e9f3ffa4-2d95-4158-8ac6-92b145e05e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "from sklearn.utils import shuffle\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7a7382e9-201b-4832-b71b-17eba2db91ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_list = [\"m292\", \"m294\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2af7d8fd-2f42-4be9-8710-2e2064d7665a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_and_concatenate_brain_imaging_feature_datasets(subjects):\n",
    "    \n",
    "    \"\"\"\n",
    "    Load feature DataFrames for specified subjects.\n",
    "    \n",
    "    Args:\n",
    "    - subjects (list): List of subject names.\n",
    "    \n",
    "    Returns:\n",
    "    - dict: Dictionary containing subject feature DataFrames.\n",
    "    - list: List of all labels across subjects.\n",
    "    \"\"\"\n",
    "    subject_feature_dfs = {}\n",
    "    all_labels = []\n",
    "\n",
    "    for subject in subjects:\n",
    "        subject_feature_dfs[subject] = pd.DataFrame()\n",
    "        single_data_frames = []\n",
    "\n",
    "        # Topological Features\n",
    "        #single_data_frames.append(pd.read_csv(\"Features/\"+str(subject)+\"/Topological_Summary_Statistics.csv\"))\n",
    "        #single_data_frames.append(pd.read_csv(\"Features/\"+str(subject)+\"/Advanced_Features.csv\"))\n",
    "        #single_data_frames.append(pd.read_csv(\"Features/\"+str(subject)+\"/Signature_Statistics.csv\"))\n",
    "\n",
    "        # Non-topological Features\n",
    "        single_data_frames.append(pd.read_csv(\"Features/\"+str(subject)+\"/Traditional_Features.csv\"))\n",
    "\n",
    "        \n",
    "        for df_idx, df in enumerate(single_data_frames):\n",
    "            df.drop(df.columns[df.columns.str.contains('unnamed',case=False)], axis=1, inplace=True)\n",
    "\n",
    "            if len(subject_feature_dfs[subject].index) > 0:\n",
    "                subject_feature_dfs[subject] = pd.concat([subject_feature_dfs[subject], df], axis=1)\n",
    "            else:\n",
    "                subject_feature_dfs[subject] = pd.concat([subject_feature_dfs[subject], df], ignore_index=True)\n",
    "                subject_feature_dfs[subject].drop(subject_feature_dfs[subject].columns[subject_feature_dfs[subject].columns.str.contains('_left',case=False)], axis=1, inplace=True)\n",
    "\n",
    "        for label in [0, 1, 2, 3, 4]:\n",
    "            if len(single_data_frames) > 1:\n",
    "                subject_feature_dfs[subject] = subject_feature_dfs[subject].drop(subject_feature_dfs[subject][subject_feature_dfs[subject][\"Label\"]==label].index[-1])\n",
    "            else:\n",
    "                subject_feature_dfs[subject] = subject_feature_dfs[subject].drop(subject_feature_dfs[subject][subject_feature_dfs[subject][\"Label\"]==label].index[-1])\n",
    "\n",
    "        \n",
    "        subject_feature_dfs[subject][\"Subject\"] = subjects.index(subject)\n",
    "\n",
    "        if len(single_data_frames) > 1:\n",
    "            all_labels.extend(list(subject_feature_dfs[subject][\"Label\"].iloc[:, 0]))\n",
    "        else: \n",
    "            all_labels.extend(list(subject_feature_dfs[subject][\"Label\"]))\n",
    "\n",
    "\n",
    "    brain_imaging_feature_df = pd.concat([subject_feature_dfs[subject] for subject in subjects], ignore_index=True)\n",
    "    brain_imaging_feature_df.drop(columns=[\"Label\"], inplace=True)\n",
    "\n",
    "    return subject_feature_dfs, all_labels, brain_imaging_feature_df\n",
    "\n",
    "subject_feature_dfs, all_labels, feature_df = import_and_concatenate_brain_imaging_feature_datasets(subject_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96ef8fb-0483-47c0-a098-4765de47b4f5",
   "metadata": {},
   "source": [
    "# Save Concatenated Features for Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "caa3972e-ba2f-4b3c-ad3a-181bb16b747e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataframe for data exploration\n",
    "feature_df.to_csv(\"Features/All_Features.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f333182-30ea-498e-9fe7-030de10a57e8",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e0b70ae8-9494-4114-9f9c-cd786af04d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_indices_all_subjects(subject_list):\n",
    "    \"\"\"\n",
    "    Load train, validation, and test set indices for all subjects.\n",
    "    \n",
    "    Args:\n",
    "    - subject_list (list): List of subject names.\n",
    "    \n",
    "    Returns:\n",
    "    - dict: Dictionary containing train indices for all subjects.\n",
    "    - dict: Dictionary containing validation indices for all subjects.\n",
    "    - dict: Dictionary containing test indices for all subjects.\n",
    "    \"\"\"\n",
    "    train_indices = {}\n",
    "    validation_indices = {}\n",
    "    test_indices_dict_all_subjects = {}\n",
    "\n",
    "    for subject in subject_list:\n",
    "        # Train indices\n",
    "        train_indices[subject] = np.load(\"../Time_Series/Train_Test_Splitting/\"+str(subject)+\"/Train_Indices_All_Labels_All_Folds.npy\", allow_pickle=True).item()\n",
    "\n",
    "        # Validation indices\n",
    "        validation_indices[subject] = np.load(\"../Time_Series/Train_Test_Splitting/\"+str(subject)+\"/Validation_Indices_All_Labels_All_Folds.npy\", allow_pickle=True).item()\n",
    "\n",
    "        # Final Test set indices\n",
    "        test_indices_dict_all_subjects[subject] = np.load(\"../Time_Series/Train_Test_Splitting/\"+str(subject)+\"/Final_Test_Set_Indices_All_Labels.npy\", allow_pickle=True).item()\n",
    "\n",
    "    return train_indices, validation_indices, test_indices_dict_all_subjects\n",
    "\n",
    "train_indices, validation_indices, test_indices = load_indices_all_subjects(subject_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f93452bb-c1f3-44ab-a6d4-100d8faa182d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_dataframe_with_indices(feature_df, all_labels, indices_dict_all_subjects):\n",
    "    \"\"\"\n",
    "    indices_dict_all_subjects: Dictionary. Structure {subject: {label: {fold: indices list}}}.\n",
    "    The indices list is a list of indices within each \"label\" dataframe (for each subject). If there are\n",
    "    71 segments of each label (for a subject), then the indices list would be a subset of range(0, 71).\n",
    "    \"\"\"\n",
    "\n",
    "    features_dfs_all_folds = {}\n",
    "    labels_all_folds = {}\n",
    "\n",
    "    # Initialize dictionarys with folds as keys and the train/validation sets/ their labels as values\n",
    "    subject = list(indices_dict_all_subjects.keys())[0]\n",
    "    for fold, fold_key in enumerate(indices_dict_all_subjects[subject][list(indices_dict_all_subjects[subject].keys())[0]]):\n",
    "        features_dfs_all_folds[fold_key] = pd.DataFrame()\n",
    "        labels_all_folds[fold_key] = []\n",
    "\n",
    "    \n",
    "    for subject_idx, subject in enumerate(indices_dict_all_subjects.keys()):\n",
    "\n",
    "        # dictionarys with folds as labels and the train/validation sets/ their labels as values \n",
    "        labels_with_set_indices = {}\n",
    "        features_dfs_for_subject = {}\n",
    "\n",
    "        filtered_subject_df = feature_df[feature_df[\"Subject\"] == subject_idx]\n",
    "\n",
    "        indices_filtered_subject_df = filtered_subject_df.index # Save indices for labels\n",
    "        labels_for_subject = [all_labels[idx] for idx in indices_filtered_subject_df]\n",
    "        \n",
    "        filtered_subject_df = filtered_subject_df.reset_index()\n",
    "\n",
    "\n",
    "        for fold, fold_key in enumerate(indices_dict_all_subjects[subject][list(indices_dict_all_subjects[subject].keys())[0]]):\n",
    "            \n",
    "            features_dfs_for_subject[fold_key] = pd.DataFrame()\n",
    "            labels_with_set_indices[fold_key] = []\n",
    "\n",
    "        \n",
    "\n",
    "        for label, label_key in enumerate(train_indices[subject].keys()):\n",
    "\n",
    "            indices_of_label_within_subject_dataframe = [index for index, value in enumerate(labels_for_subject) if value == label]\n",
    "\n",
    "\n",
    "            filtered_label_df = filtered_subject_df.loc[indices_of_label_within_subject_dataframe]\n",
    "\n",
    "            #filtered_label_df.drop(columns = [\"level_0\"], inplace = True)\n",
    "\n",
    "            filtered_label_df = filtered_label_df.reset_index()\n",
    "\n",
    "\n",
    "            for fold, fold_key in enumerate(indices_dict_all_subjects[subject][label_key].keys()):\n",
    "\n",
    "                set_indices_in_filtered_df = indices_dict_all_subjects[subject][label_key][fold_key]\n",
    "\n",
    "\n",
    "                feature_df_with_set_indices = filtered_label_df.loc[set_indices_in_filtered_df]\n",
    "\n",
    "                labels_with_set_indices[fold_key].extend([label]*len(feature_df_with_set_indices.index))\n",
    "                \n",
    "        \n",
    "                features_dfs_for_subject[fold_key] = pd.concat([features_dfs_for_subject[fold_key], feature_df_with_set_indices], ignore_index=True)\n",
    "\n",
    "        \n",
    "        for fold, fold_key in enumerate(indices_dict_all_subjects[subject][list(indices_dict_all_subjects[subject].keys())[0]]):\n",
    "            features_dfs_all_folds[fold_key] =  pd.concat([features_dfs_for_subject[fold_key], features_dfs_for_subject[fold_key]], ignore_index=True)\n",
    "\n",
    "            labels_all_folds[fold_key].extend(labels_with_set_indices[fold_key])\n",
    "            \n",
    "            # Postprocessing\n",
    "            features_dfs_all_folds[fold_key].drop(columns = [\"level_0\"], inplace = True)\n",
    "            features_dfs_all_folds[fold_key].drop(columns = [\"index\"], inplace = True)\n",
    "\n",
    "\n",
    "    \n",
    "    return features_dfs_all_folds, labels_all_folds\n",
    "\n",
    "train_features_dfs_all_folds, train_labels_all_folds = filter_dataframe_with_indices(feature_df, all_labels, train_indices)\n",
    "validation_features_dfs_all_folds, validation_labels_all_folds = filter_dataframe_with_indices(feature_df, all_labels, validation_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "162ffa1c-43a9-45d1-943c-6402a541407d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_fold_dicts(train_features_dfs_all_folds, train_labels_all_folds, validation_features_dfs_all_folds, validation_labels_all_folds, n_folds = 5):\n",
    "    \"\"\"\n",
    "    Initialize dictionaries with folds as keys and assign features and labels accordingly.\n",
    "    \n",
    "    Args:\n",
    "    - train_features_dfs_all_folds (dict): Dictionary containing training features for all folds.\n",
    "    - train_labels_all_folds (dict): Dictionary containing training labels for all folds.\n",
    "    - validation_features_dfs_all_folds (dict): Dictionary containing validation features for all folds.\n",
    "    - validation_labels_all_folds (dict): Dictionary containing validation labels for all folds.\n",
    "    - n_folds (int): Number of folds.\n",
    "    \n",
    "    Returns:\n",
    "    - dict: Dictionary containing training features for each fold.\n",
    "    - dict: Dictionary containing training labels for each fold.\n",
    "    - dict: Dictionary containing validation features for each fold.\n",
    "    - dict: Dictionary containing validation labels for each fold.\n",
    "    \"\"\"\n",
    "    X_train = {}\n",
    "    y_train = {}\n",
    "    X_test = {}\n",
    "    y_test = {}\n",
    "\n",
    "    for fold in range(n_folds):\n",
    "        # Set random seed for reproducibility\n",
    "        np.random.seed(42)\n",
    "\n",
    "        # Shuffle indices\n",
    "        indices_train = np.random.permutation(len(train_features_dfs_all_folds[\"Fold_\" + str(fold)]))\n",
    "        indices_test = np.random.permutation(len(validation_features_dfs_all_folds[\"Fold_\" + str(fold)]))\n",
    "\n",
    "        # Shuffle rows of X_train[fold] and y_train[fold]\n",
    "        X_train_fold = train_features_dfs_all_folds[\"Fold_\" + str(fold)].iloc[indices_train]\n",
    "        y_train_fold = [train_labels_all_folds[\"Fold_\" + str(fold)][index] for index in indices_train]\n",
    "\n",
    "        # Shuffle rows of X_test[fold] and y_test[fold]\n",
    "        X_test_fold = validation_features_dfs_all_folds[\"Fold_\" + str(fold)].iloc[indices_test]\n",
    "        y_test_fold = [validation_labels_all_folds[\"Fold_\" + str(fold)][index] for index in indices_test]\n",
    "\n",
    "        X_train[fold] = X_train_fold\n",
    "        y_train[fold] = y_train_fold\n",
    "        X_test[fold] = X_test_fold\n",
    "        y_test[fold] = y_test_fold\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "X_train, y_train, X_test, y_test = initialize_fold_dicts(train_features_dfs_all_folds, train_labels_all_folds, validation_features_dfs_all_folds, validation_labels_all_folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613bcf0c-eff9-4be3-9112-87d2eae8a676",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "51a5995c-42e5-41c8-ad7a-a787e5e4029b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/piabaronetzky/anaconda3/envs/time-delay-embeddings/lib/python3.10/site-packages/sklearn/utils/validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/piabaronetzky/anaconda3/envs/time-delay-embeddings/lib/python3.10/site-packages/sklearn/utils/validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/piabaronetzky/anaconda3/envs/time-delay-embeddings/lib/python3.10/site-packages/sklearn/utils/validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for fold 0 : 0.7666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/piabaronetzky/anaconda3/envs/time-delay-embeddings/lib/python3.10/site-packages/sklearn/utils/validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/piabaronetzky/anaconda3/envs/time-delay-embeddings/lib/python3.10/site-packages/sklearn/utils/validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for fold 1 : 0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/piabaronetzky/anaconda3/envs/time-delay-embeddings/lib/python3.10/site-packages/sklearn/utils/validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/piabaronetzky/anaconda3/envs/time-delay-embeddings/lib/python3.10/site-packages/sklearn/utils/validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for fold 2 : 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/piabaronetzky/anaconda3/envs/time-delay-embeddings/lib/python3.10/site-packages/sklearn/utils/validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/piabaronetzky/anaconda3/envs/time-delay-embeddings/lib/python3.10/site-packages/sklearn/utils/validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for fold 3 : 0.7833333333333333\n",
      "Accuracy for fold 4 : 0.8363636363636363\n",
      "Mean Accuracy: 0.7472727272727273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/piabaronetzky/anaconda3/envs/time-delay-embeddings/lib/python3.10/site-packages/sklearn/utils/validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n"
     ]
    }
   ],
   "source": [
    "def train_rf_cross_validation(X_train, y_train, X_test, y_test, n_estimators=500, random_state=5):\n",
    "    \"\"\"\n",
    "    Train RandomForestClassifier using cross-validation and calculate mean accuracy.\n",
    "    \n",
    "    Args:\n",
    "    - X_train (dict): Dictionary containing training features for each fold.\n",
    "    - y_train (dict): Dictionary containing training labels for each fold.\n",
    "    - X_test (dict): Dictionary containing validation features for each fold.\n",
    "    - y_test (dict): Dictionary containing validation labels for each fold.\n",
    "    - n_estimators (int): Number of trees in the forest (default=900).\n",
    "    - random_state (int): Random seed (default=5).\n",
    "    \n",
    "    Returns:\n",
    "    - float: Mean accuracy across all folds.\n",
    "    \"\"\"\n",
    "    rf = RandomForestClassifier(random_state=random_state, n_estimators=n_estimators)\n",
    "    all_accuracies = []\n",
    "\n",
    "    for fold in range(len(X_train)):\n",
    "        rf.fit(X_train[fold], y_train[fold])\n",
    "        y_pred = rf.predict(X_test[fold])\n",
    "        accuracy = accuracy_score(y_pred, y_test[fold])\n",
    "        all_accuracies.append(accuracy)\n",
    "        print(\"Accuracy for fold\", fold, \":\", accuracy)\n",
    "\n",
    "    mean_accuracy = np.mean(all_accuracies)\n",
    "    print(\"Mean Accuracy:\", mean_accuracy)\n",
    "    pass\n",
    "\n",
    "train_rf_cross_validation(X_train, y_train, X_test, y_test)\n",
    "\n",
    "\n",
    "# Use less data for parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf608d24-82fe-4a5a-a629-635bb7fb4036",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d606a402-8292-4525-8cca-f02726105433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for fold 0 : 0.9833333333333333\n",
      "Accuracy for fold 1 : 0.9333333333333333\n",
      "Accuracy for fold 2 : 1.0\n",
      "Accuracy for fold 3 : 0.9833333333333333\n",
      "Accuracy for fold 4 : 0.9818181818181818\n",
      "Mean Accuracy: 0.9763636363636363\n"
     ]
    }
   ],
   "source": [
    "def train_xgb_cross_validation(X_train, y_train, X_test, y_test, seed=41):\n",
    "    \"\"\"\n",
    "    Train XGBoost Classifier using cross-validation and calculate mean accuracy.\n",
    "    \n",
    "    Args:\n",
    "    - X_train (dict): Dictionary containing training features for each fold.\n",
    "    - y_train (dict): Dictionary containing training labels for each fold.\n",
    "    - X_test (dict): Dictionary containing validation features for each fold.\n",
    "    - y_test (dict): Dictionary containing validation labels for each fold.\n",
    "    - seed (int): Random seed (default=41).\n",
    "    \n",
    "    Returns:\n",
    "    - float: Mean accuracy across all folds.\n",
    "    \"\"\"\n",
    "    model = xgb.XGBClassifier(seed=seed)\n",
    "    all_accuracies = []\n",
    "\n",
    "    for fold in range(len(X_train)):\n",
    "        # Remove duplicate columns\n",
    "        X_train[fold] = X_train[fold].loc[:, ~X_train[fold].columns.duplicated()]\n",
    "\n",
    "        model.fit(X_train[fold], y_train[fold])\n",
    "\n",
    "        X_test[fold] = X_test[fold].loc[:, ~X_test[fold].columns.duplicated()]\n",
    "\n",
    "        y_pred = model.predict(X_test[fold])\n",
    "        accuracy = accuracy_score(y_pred, y_test[fold])\n",
    "        all_accuracies.append(accuracy)\n",
    "        print(\"Accuracy for fold\", fold, \":\", accuracy)\n",
    "\n",
    "    mean_accuracy = np.mean(all_accuracies)\n",
    "    print(\"Mean Accuracy:\", mean_accuracy)\n",
    "    return mean_accuracy\n",
    "\n",
    "mean_accuracy_xgb = train_xgb_cross_validation(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c04a3d5-a0e1-488b-becd-d6832adeb6f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
