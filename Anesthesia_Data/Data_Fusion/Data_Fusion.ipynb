{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a81b9c9-a2e9-46c2-8ae8-4a5f02dd0571",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from gtda.homology import VietorisRipsPersistence\n",
    "from gtda.diagrams import PersistenceEntropy, Amplitude, NumberOfPoints, ComplexPolynomial, PersistenceLandscape, HeatKernel, Silhouette, BettiCurve, PairwiseDistance, ForgetDimension\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9823a6-57bc-4bef-9350-14eb32a035fe",
   "metadata": {},
   "source": [
    "# Choose EEG or EMG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a556dad-ea22-4937-811d-6efbdc4aa317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose if you want to look at EEG or EMG data\n",
    "\n",
    "data_type = \"EEG\" # Does not have an effect yet, will be added later when processing anesthesia data\n",
    "#data_type = \"EMG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58eb7941-b1bf-4088-b8d6-30b435ecd761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose individuum\n",
    "subject = \"m294\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc1f407-122b-4eda-86f0-622f93ccf082",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "384db2ae-4245-4142-a740-7e20ee169e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = [0, 1, 2, 3, 4]\n",
    "\n",
    "data_type_list = [\"EEG\", \"EMG\"]\n",
    "\n",
    "subject_list = [\"m292\", \"m294\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "048043a1-ae93-4ec2-87d5-b98e2d15dc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EEG & EMG data\n",
    "time_series_dataframes = {}\n",
    "\n",
    "for label in label_list:\n",
    "    time_series_dataframes[label] = pd.read_csv(\"../Time_Series/Data/\"+str(subject)+\"/run0\"+str(label)+\"/Time_Series_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37dca9e6-3543-46ae-9e4d-500e52081113",
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_imaging_dataframes = {}\n",
    "\n",
    "for label in label_list:\n",
    "    filename = \"../Brain_Imaging/Data/\"+str(subject)+\"/run0\"+str(label)+\"/Brain_Imaging_Data.h5\"\n",
    "    file = h5py.File(filename,'r')\n",
    "    brain_imaging_dataframes[label] = file['Data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6cd7596-e777-4740-a73b-32a681fef567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment EEG & EMG data into segments of the same \"length\" that one brain imaging picture has\n",
    "\n",
    "def segment_data(df, segment_size, step_size = 2):\n",
    "    \"\"\"\n",
    "    Segments time-series data into EEG and EMG segments.\n",
    "\n",
    "    Parameters:\n",
    "    - df (DataFrame): The input dataframe containing the columns \"Time\", \"EEG\" and \"EMG\".\n",
    "    - segment_size (float): The desired size of each segment in seconds.\n",
    "    - step_size (float, optional): The step size of \"Time\" in milliseconds. Default is 2 millisecond.\n",
    "\n",
    "    Returns:\n",
    "    Tuple of two lists:\n",
    "    - List of EEG segments.\n",
    "    - List of EMG segments.\n",
    "    \"\"\"\n",
    "\n",
    "    n_segments = int(df[\"time\"].iloc[-1]) // segment_size\n",
    "    eeg_segments = []\n",
    "    emg_segments = []\n",
    "\n",
    "    for i in range(n_segments):\n",
    "        start_idx = int(i* segment_size*1000/step_size)\n",
    "        end_idx = start_idx + int(segment_size*1000/step_size)\n",
    "        segment = df.iloc[start_idx:end_idx]\n",
    "        eeg_segments.append(list(segment[\"voltage\"]))\n",
    "        emg_segments.append(list(segment[\"emg\"]))\n",
    "\n",
    "    return eeg_segments, emg_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd0961a5-b61c-45a4-aaa3-883b7bec1475",
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_size = 4\n",
    "eeg_segments = {}\n",
    "\n",
    "\n",
    "for label in label_list:\n",
    "    eeg_segments[label],_ = segment_data(time_series_dataframes[label], segment_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "362ae4e7-67e4-4ad3-94c1-ed93ed9e56eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment the data\n",
    "segment_size = 80\n",
    "brain_imaging_segments = {}\n",
    "\n",
    "def segment_brain_imaging_data(df, segment_size):\n",
    "\n",
    "    n_segments = 75\n",
    "    brain_imaging_segments = []\n",
    "\n",
    "    for i in range(n_segments):\n",
    "        start_idx = int(i* segment_size)\n",
    "        end_idx = start_idx + int(segment_size)\n",
    "        segment = df[start_idx:end_idx]\n",
    "\n",
    "        brain_imaging_segments.append(list(segment))\n",
    "\n",
    "    return brain_imaging_segments\n",
    "\n",
    "for label in label_list:\n",
    "    segments = segment_brain_imaging_data(brain_imaging_dataframes[label], segment_size) \n",
    "     # Remove the last segment for each label\n",
    "    segments = segments[:-1]\n",
    "    # Save in dictionary\n",
    "    brain_imaging_segments[label] = segments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed8c95c-4f96-422f-b287-ffa159ddb93e",
   "metadata": {},
   "source": [
    "# Data Fusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2460ac66-0844-4906-97fd-17a26912ee43",
   "metadata": {},
   "source": [
    "Joint ICA + Reconstruction with Generative Model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04268995-065c-4f2f-8e91-b2ea35537044",
   "metadata": {},
   "source": [
    "## First try of Joint ICA with test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae64dd22-c748-4c87-80e0-5d7371a3a9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import FastICA\n",
    "\n",
    "np.random.seed(0)\n",
    "n_samples = 200\n",
    "n_features_x = 64  # Number of EEG channels\n",
    "n_features_y = 100  # Number of video features\n",
    "\n",
    "x = np.random.rand(n_samples, n_features_x)\n",
    "y = np.random.rand(n_samples, n_features_y)\n",
    "\n",
    "# Apply Joint Independent Component Analysis (jICA) for early fusion\n",
    "# Assuming x represents EEG data and y represents 2D video data\n",
    "def joint_ICA(X, Y):\n",
    "    # Concatenate the EEG and video data\n",
    "    data = np.concatenate((X, Y), axis=1)\n",
    "    \n",
    "    # Apply FastICA for joint independent component analysis\n",
    "    transformer = FastICA(n_components=10, random_state=0)\n",
    "    joint_components = transformer.fit_transform(data)\n",
    "    \n",
    "    # Separate the joint components back into EEG and video components\n",
    "    EEG_components = joint_components[:, :n_features_x]\n",
    "    video_components = joint_components[:, n_features_x:]\n",
    "    \n",
    "    return joint_components, EEG_components, video_components\n",
    "\n",
    "# Apply joint ICA to the EEG and video data\n",
    "joint_components, EEG_components, video_components = joint_ICA(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d160a66d-6a4f-45ec-a9c0-151798bae8b5",
   "metadata": {},
   "source": [
    "In this code snippet:\n",
    "\n",
    "- We generate sample EEG data (x) and 2D video data (y) for demonstration purposes.\n",
    "- The joint_ICA function performs Joint Independent Component Analysis (jICA) on the concatenated EEG and video data.\n",
    "- The resulting components are separated back into EEG components and video components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c89352da-821b-40be-bd4d-a42b40988ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of joint components: (200, 10)\n",
      "Shape of EEG components: (200, 10)\n",
      "Shape of video components: (200, 0)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of the extracted components\n",
    "print(\"Shape of joint components:\", joint_components.shape)\n",
    "print(\"Shape of EEG components:\", EEG_components.shape)\n",
    "print(\"Shape of video components:\", video_components.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83b255a-a244-4f7b-abd7-f518b50940a5",
   "metadata": {},
   "source": [
    "## Trying Data Fusion with test data with the correct dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006ec45d-d7ce-45c9-95d8-dfd26b2604b1",
   "metadata": {},
   "source": [
    "Now we apply the same function to our actual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7bdc8971-efb8-4065-bbfb-abc55e3d5b7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74, 2000)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(eeg_segments[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb3530fa-14a5-4296-8e1b-7d41793b01d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74, 80, 300, 260)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(brain_imaging_segments[0]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8408b47-9c20-4b95-988a-b832f349221e",
   "metadata": {},
   "source": [
    "These different shapes will lead to problems, so we should reshape or use dimensionality reduction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d062a698-3706-45eb-8608-97de17618937",
   "metadata": {},
   "source": [
    "### Get first functions running"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fd0dc7-1830-43d6-a0f9-3f83686c9624",
   "metadata": {},
   "source": [
    "#### Approach 1: Joint_ICA function with dimensionality reduction for both EEG and imaging segments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d8b45b-adcd-4667-b88e-3a6ba41935e2",
   "metadata": {},
   "source": [
    "Both functions do still not converge now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "737f252a-555c-4ec0-9c37-708da0e83860",
   "metadata": {},
   "outputs": [],
   "source": [
    "def joint_ICA_with_dim_reduction(EEG_segments, imaging_segments):\n",
    "    n_segments = EEG_segments.shape[0]\n",
    "    n_features = min(EEG_segments.shape[1], imaging_segments.shape[1] * imaging_segments.shape[2] * imaging_segments.shape[3])\n",
    "    \n",
    "    # Apply PCA for dimensionality reduction on EEG segments\n",
    "    pca_EEG = PCA(n_components=n_segments)\n",
    "    EEG_segments_pca = pca_EEG.fit_transform(EEG_segments)\n",
    "    \n",
    "    # Reshape and apply PCA for dimensionality reduction to the imaging segments\n",
    "    n_samples, n_x, n_y, n_z = imaging_segments.shape\n",
    "    imaging_segments_reshaped = imaging_segments.reshape(n_samples, n_x * n_y * n_z)\n",
    "    pca_imaging = PCA(n_components=n_segments)\n",
    "    imaging_segments_pca = pca_imaging.fit_transform(imaging_segments_reshaped)\n",
    "    \n",
    "    # Concatenate the reduced EEG and imaging segments\n",
    "    data_segments = np.concatenate((EEG_segments_pca, imaging_segments_pca), axis=1)\n",
    "    \n",
    "    # Apply FastICA for joint independent component analysis on segments\n",
    "    # Adapt ICA parameters because previously it did not converge\n",
    "    transformer = FastICA(n_components=10, random_state=0, tol=0.0001, max_iter=2000, algorithm='parallel')\n",
    "    joint_components = transformer.fit_transform(data_segments)\n",
    "    \n",
    "    return joint_components\n",
    "\n",
    "# EEG_segments shape: (74, 2000), imaging_segments shape: (74, 80, 300, 260)\n",
    "EEG_segments = np.random.rand(74, 2000)\n",
    "imaging_segments = np.random.rand(74, 80, 300, 260)\n",
    "\n",
    "# Apply joint ICA to the EEG and video data\n",
    "joint_components_with_dim_reduction = joint_ICA_with_dim_reduction(EEG_segments, imaging_segments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0421e4a-7c95-43a4-b963-5f884fcc1104",
   "metadata": {},
   "source": [
    "#### Approach 2: Joint_ICA function with reshaping for EEG and imaging segments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4308e435-bf0f-478b-bd77-19a635e6b8f0",
   "metadata": {},
   "source": [
    "Does this approach converge now with the new parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24eb42c5-6708-4cb6-a642-71f85dc37709",
   "metadata": {},
   "outputs": [],
   "source": [
    "def joint_ICA_with_reshaping(EEG_segments, imaging_segments):\n",
    "    n_segments = EEG_segments.shape[0]\n",
    "    n_features_EEG = EEG_segments.shape[1]\n",
    "    \n",
    "    # Reshape the EEG segments to have a 2D shape\n",
    "    EEG_segments_reshaped = EEG_segments.reshape(n_segments, n_features_EEG)\n",
    "    \n",
    "    # Reshape the imaging segments to 2D\n",
    "    n_samples, n_x, n_y, n_z = imaging_segments.shape\n",
    "    imaging_segments_reshaped = imaging_segments.reshape(n_samples, n_x * n_y * n_z)\n",
    "    \n",
    "    # Concatenate EEG and imaging segments\n",
    "    data_segments = np.concatenate((EEG_segments_reshaped, imaging_segments_reshaped), axis=1)\n",
    "    \n",
    "    # Apply FastICA for joint independent component analysis on segments with adjusted parameters\n",
    "    # Adapt ICA parameters because previously it did not converge\n",
    "    transformer = FastICA(n_components=10, random_state=0, tol=0.0001, max_iter=2000, algorithm='parallel')\n",
    "    joint_components = transformer.fit_transform(data_segments)\n",
    "\n",
    "    return joint_components\n",
    "\n",
    "# EEG_segments shape: (74, 2000), imaging_segments shape: (74, 80, 300, 260)\n",
    "EEG_segments = np.random.rand(74, 2000)\n",
    "imaging_segments = np.random.rand(74, 80, 300, 260)\n",
    "\n",
    "# Apply joint ICA to the EEG and video data\n",
    "joint_components_with_reshaping = joint_ICA_with_reshaping(EEG_segments, imaging_segments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01530096-b3e5-485b-8dac-bb734b8b3496",
   "metadata": {},
   "source": [
    "Next steps: Experiment with parameters (n_components, tol, max_iter) to ensure convergence and be able to minimize the reconstruction error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e4e525-c0ac-4d26-ae4f-6318877e4d3f",
   "metadata": {},
   "source": [
    "#### Approach 3: Simple Multimodal linear model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6300ac07-df97-42e4-b376-9baab6b996f4",
   "metadata": {},
   "source": [
    "Generative model as described in the paper. Does not work yet!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4544291c-b415-4976-9ca6-9edf7460324a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# EEG_segments shape: (74, 2000), imaging_segments shape: (74, 80, 300, 260)\\nEEG_segments = np.random.rand(74, 2000)\\nimaging_segments = np.random.rand(74, 80, 300, 260)\\n\\n# Reshape imaging_segments to (74, 80*300*260) for linear decoding\\nimaging_segments_flat = imaging_segments.reshape(74, -1)\\n\\n# Concatenate EEG and flattened imaging data for joint linear decoding\\njoint_data = np.concatenate((EEG_segments, imaging_segments_flat), axis=1)\\n\\n# Perform linear decoding to estimate neural sources\\n# Assuming W_x is the spatial extraction filter matrix\\nW_x = np.linalg.pinv(joint_data)  # Pseudo-inverse of joint data as decoding matrix\\n\\n# Estimate neural sources\\nestimated_sources = np.dot(joint_data, W_x)\\n\\n# Extract EEG and imaging source estimates\\nestimated_EEG_sources = estimated_sources[:, :2000]\\nestimated_imaging_sources_flat = estimated_sources[:, 2000:]\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# EEG_segments shape: (74, 2000), imaging_segments shape: (74, 80, 300, 260)\n",
    "EEG_segments = np.random.rand(74, 2000)\n",
    "imaging_segments = np.random.rand(74, 80, 300, 260)\n",
    "\n",
    "# Reshape imaging_segments to (74, 80*300*260) for linear decoding\n",
    "imaging_segments_flat = imaging_segments.reshape(74, -1)\n",
    "\n",
    "# Concatenate EEG and flattened imaging data for joint linear decoding\n",
    "joint_data = np.concatenate((EEG_segments, imaging_segments_flat), axis=1)\n",
    "\n",
    "# Perform linear decoding to estimate neural sources\n",
    "# Assuming W_x is the spatial extraction filter matrix\n",
    "W_x = np.linalg.pinv(joint_data)  # Pseudo-inverse of joint data as decoding matrix\n",
    "\n",
    "# Estimate neural sources\n",
    "estimated_sources = np.dot(joint_data, W_x)\n",
    "\n",
    "# Extract EEG and imaging source estimates\n",
    "estimated_EEG_sources = estimated_sources[:, :2000]\n",
    "estimated_imaging_sources_flat = estimated_sources[:, 2000:]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c7668c-5899-4f5b-a226-dc3d74fc0727",
   "metadata": {},
   "source": [
    "## Trying Data Fusion with the actual data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3e396a-e369-4875-a68a-936862169ca2",
   "metadata": {},
   "source": [
    "Only label 0 right now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c87e441-6ba5-4167-b176-69e5ad564d2c",
   "metadata": {},
   "source": [
    "### Producing joint components with Joint ICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb4b8373-94c6-4cb2-9405-408d88c73eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def joint_ICA_with_dim_reduction(EEG_segments, imaging_segments):\n",
    "    n_segments = EEG_segments.shape[0]\n",
    "    n_features = min(EEG_segments.shape[1], imaging_segments.shape[1] * imaging_segments.shape[2] * imaging_segments.shape[3])\n",
    "    \n",
    "    # Apply PCA for dimensionality reduction on EEG segments\n",
    "    pca_EEG = PCA(n_components=n_segments)\n",
    "    EEG_segments_pca = pca_EEG.fit_transform(EEG_segments)\n",
    "    \n",
    "    # Reshape and apply PCA for dimensionality reduction to the imaging segments\n",
    "    n_samples, n_x, n_y, n_z = imaging_segments.shape\n",
    "    imaging_segments_reshaped = imaging_segments.reshape(n_samples, n_x * n_y * n_z)\n",
    "    pca_imaging = PCA(n_components=n_segments)\n",
    "    imaging_segments_pca = pca_imaging.fit_transform(imaging_segments_reshaped)\n",
    "    \n",
    "    # Concatenate the reduced EEG and imaging segments\n",
    "    data_segments = np.concatenate((EEG_segments_pca, imaging_segments_pca), axis=1)\n",
    "    \n",
    "    # Apply FastICA for joint independent component analysis on segments\n",
    "    # Adapt ICA parameters because previously it did not converge\n",
    "    transformer = FastICA(n_components=10, random_state=0, tol=0.0001, max_iter=2000, algorithm='parallel')\n",
    "    joint_components = transformer.fit_transform(data_segments)\n",
    "    \n",
    "    return joint_components\n",
    "\n",
    "# Apply joint ICA to the EEG and video data\n",
    "\n",
    "joint_components_dict = {}\n",
    "\n",
    "for label in label_list:\n",
    "    joint_components_dict[label] = joint_ICA_with_dim_reduction(np.array(eeg_segments[label]), np.array(brain_imaging_segments[label]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f16f40-f14c-4a78-8308-e752d234bc5c",
   "metadata": {},
   "source": [
    "Does Fast ICA converge? => Yes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f471c3-3a8e-4896-8e57-f1c31bd915c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_components_dict = {}\n",
    "\n",
    "#joint_components_dict[0] = joint_ICA_with_dim_reduction(np.array(eeg_segments[0]), np.array(brain_imaging_segments[0]))\n",
    "#joint_components_dict[1] = joint_ICA_with_dim_reduction(np.array(eeg_segments[1]), np.array(brain_imaging_segments[1]))\n",
    "#joint_components_dict[2] = joint_ICA_with_dim_reduction(np.array(eeg_segments[2]), np.array(brain_imaging_segments[2]))\n",
    "#joint_components_dict[3] = joint_ICA_with_dim_reduction(np.array(eeg_segments[3]), np.array(brain_imaging_segments[3]))\n",
    "joint_components_dict[4] = joint_ICA_with_dim_reduction(np.array(eeg_segments[4]), np.array(brain_imaging_segments[4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2810f3e9-6302-40ac-8d2c-be8a81e80b1b",
   "metadata": {},
   "source": [
    "### Computing Persistence Diagrams from the joint components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a24abd-c237-47a5-8868-d1e20f6a220f",
   "metadata": {},
   "source": [
    "Find optimal parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fbf558-eb15-4bd8-b11d-8a00d9016e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the embedding\n",
    "max_embedding_dimension = 30\n",
    "max_time_delay = 30\n",
    "stride = 5\n",
    "\n",
    "embedder = SingleTakensEmbedding(\n",
    "    parameters_type=\"search\",\n",
    "    time_delay=max_time_delay,\n",
    "    dimension=max_embedding_dimension,\n",
    "    stride=stride,\n",
    ")\n",
    "\n",
    "\n",
    "def find_optimal_parameters(embedder, segments, max_index, iterations = 8):\n",
    "    \"\"\"\n",
    "    Finds (approximate) optimal embedding parameters by averaging optimal parameters of random segments.\n",
    "\n",
    "    Parameters:\n",
    "    - embedder (object): defined by SingleTakensEmbedding() or similar\n",
    "    - segments (list of lists): Complete EEG/EMG segments\n",
    "    - max_index (int): How many segments there are\n",
    "    - iteratiors (int): How many random indices to sample\n",
    "\n",
    "    Returns:\n",
    "    Tuple of two floats:\n",
    "    - Average optimal embedding dimension\n",
    "    - Average optimal time delay\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    optimal_embeddings_dimensions = []\n",
    "    optimal_time_delays = []\n",
    "    \n",
    "    for _ in range(iterations):\n",
    "        random_index = random.randint(0, max_index)\n",
    "        embedding = embedder.fit_transform(segments[random_index])\n",
    "        \n",
    "         # append optimal embedding dimension for this segment\n",
    "        optimal_embeddings_dimensions.append(embedder.dimension_)\n",
    "\n",
    "        # append optimal time delay for this segment\n",
    "        optimal_time_delays.append(embedder.time_delay_)\n",
    "\n",
    "        print(\"The optimal embedding dimension is \" + str(np.mean(optimal_embeddings_dimensions)) + \n",
    "              \" and the optimal time delay is \" + str(np.mean(optimal_time_delays)))\n",
    "        \n",
    "        return int(np.mean(optimal_embeddings_dimensions)), int(np.mean(optimal_time_delays))\n",
    "\n",
    "\n",
    "\n",
    "# Compute optimal embedding parameters\n",
    "\n",
    "embedding_dimension, embedding_time_delay = find_optimal_parameters(embedder, joint_components_dict[0], len(all_segments), iterations = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9405389-e2cb-481f-b119-cbcf0a77a6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting parameters for point cloud embeddings\n",
    "\n",
    "#embedding_dimension= 3 # for data exploration\n",
    "stride = 10\n",
    "\n",
    "embedder = SingleTakensEmbedding(\n",
    "    parameters_type=\"fixed\",\n",
    "    n_jobs=2,\n",
    "    time_delay=embedding_time_delay, # computed above\n",
    "    dimension=embedding_dimension, # computed above\n",
    "    stride=stride,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42192eec-f9cc-4941-8769-0d10e18eea40",
   "metadata": {},
   "source": [
    "Compute final persistence diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c868bf06-c676-4e4b-80a6-0cf1d5f978d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will look at 0, 1 and 2 dimensional holes\n",
    "homology_dimensions = [0, 1, 2]\n",
    "\n",
    "# We will use a Vietoris Rips filtrations\n",
    "persistence = VietorisRipsPersistence(\n",
    "    homology_dimensions=homology_dimensions, n_jobs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8d3a51-d447-45b5-98ca-9f4e48dcb7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_embeddings_and_diagrams(segments, time_delay_embeddings, persistence_diagrams, all_indices_dict, label):\n",
    "\n",
    "    time_delay_embeddings[\"Label_\"+str(label)] = []\n",
    "    persistence_diagrams[\"Label_\"+str(label)] = []\n",
    "\n",
    "    # Compute embeddings and diagrams for the complete data\n",
    "    for diagram_idx in range(len(segments[label])):\n",
    "        time_delay_embeddings[\"Label_\"+str(label)].append(embedder.fit_transform(segments[label][diagram_idx])[None, :, :])\n",
    "        persistence_diagrams[\"Label_\"+str(label)].append(persistence.fit_transform_plot(time_delay_embeddings[\"Label_\"+str(label)][diagram_idx]))\n",
    "    \n",
    "    return time_delay_embeddings, persistence_diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ec41f0-5492-4e13-97be-c306998737e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute embeddings and persistence diagrams for the complete data\n",
    "\n",
    "time_delay_embeddings = {}\n",
    "persistence_diagrams = {}\n",
    "\n",
    "for label in label_list:\n",
    "    time_delay_embeddings, persistence_diagrams = compute_embeddings_and_diagrams(joint_components_dict, time_delay_embeddings, persistence_diagrams, all_indices_dict, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efacfa1-0f35-43dc-b220-4bc9ecba7745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persistence diagrams\n",
    "np.save('Embeddings_and_Persistence_Diagrams/'+str(subject)+'/'+str(data_type)+'/Persistence_Diagrams_All_Labels.npy', \\\n",
    "            np.array(persistence_diagrams, dtype=object), allow_pickle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
