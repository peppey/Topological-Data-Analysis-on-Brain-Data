{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a81b9c9-a2e9-46c2-8ae8-4a5f02dd0571",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from gtda.time_series import SingleTakensEmbedding\n",
    "from gtda.homology import VietorisRipsPersistence\n",
    "from gtda.diagrams import PersistenceEntropy, Amplitude, NumberOfPoints, ComplexPolynomial, PersistenceLandscape, HeatKernel, Silhouette, BettiCurve, PairwiseDistance, ForgetDimension\n",
    "import random\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import napari\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9823a6-57bc-4bef-9350-14eb32a035fe",
   "metadata": {},
   "source": [
    "# Choose EEG or EMG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a556dad-ea22-4937-811d-6efbdc4aa317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose if you want to look at EEG or EMG data\n",
    "\n",
    "data_type = \"EEG\" # Does not have an effect yet, will be added later when processing anesthesia data\n",
    "#data_type = \"EMG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58eb7941-b1bf-4088-b8d6-30b435ecd761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose individuum\n",
    "subject = \"m292\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b77b7899-f84c-4d5a-a546-2c4231c4e9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of components for joint ICA\n",
    "\n",
    "hidden_dim = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc1f407-122b-4eda-86f0-622f93ccf082",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "384db2ae-4245-4142-a740-7e20ee169e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = [0, 1, 2, 3, 4]\n",
    "\n",
    "data_type_list = [\"EEG\", \"EMG\"]\n",
    "\n",
    "subject_list = [\"m292\", \"m294\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "048043a1-ae93-4ec2-87d5-b98e2d15dc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EEG & EMG data\n",
    "time_series_dataframes = {}\n",
    "\n",
    "for label in label_list:\n",
    "    time_series_dataframes[label] = pd.read_csv(\"../Time_Series/Data/\"+str(subject)+\"/run0\"+str(label)+\"/Time_Series_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37dca9e6-3543-46ae-9e4d-500e52081113",
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_imaging_dataframes = {}\n",
    "\n",
    "for label in label_list:\n",
    "    filename = \"../Brain_Imaging/Data/\"+str(subject)+\"/run0\"+str(label)+\"/Brain_Imaging_Data.h5\"\n",
    "    file = h5py.File(filename,'r')\n",
    "    brain_imaging_dataframes[label] = file['Data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6cd7596-e777-4740-a73b-32a681fef567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment EEG & EMG data into segments of the same \"length\" that one brain imaging picture has\n",
    "\n",
    "def segment_data(df, segment_size, step_size = 2):\n",
    "    \"\"\"\n",
    "    Segments time-series data into EEG and EMG segments.\n",
    "\n",
    "    Parameters:\n",
    "    - df (DataFrame): The input dataframe containing the columns \"Time\", \"EEG\" and \"EMG\".\n",
    "    - segment_size (float): The desired size of each segment in seconds.\n",
    "    - step_size (float, optional): The step size of \"Time\" in milliseconds. Default is 2 millisecond.\n",
    "\n",
    "    Returns:\n",
    "    Tuple of two lists:\n",
    "    - List of EEG segments.\n",
    "    - List of EMG segments.\n",
    "    \"\"\"\n",
    "\n",
    "    n_segments = int(df[\"time\"].iloc[-1]) // segment_size\n",
    "    eeg_segments = []\n",
    "    emg_segments = []\n",
    "\n",
    "    for i in range(n_segments):\n",
    "        start_idx = int(i* segment_size*1000/step_size)\n",
    "        end_idx = start_idx + int(segment_size*1000/step_size)\n",
    "        segment = df.iloc[start_idx:end_idx]\n",
    "        eeg_segments.append(list(segment[\"voltage\"]))\n",
    "        emg_segments.append(list(segment[\"emg\"]))\n",
    "\n",
    "    return eeg_segments, emg_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd0961a5-b61c-45a4-aaa3-883b7bec1475",
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_size = 4\n",
    "eeg_segments = {}\n",
    "\n",
    "\n",
    "for label in label_list:\n",
    "    eeg_segments[label],_ = segment_data(time_series_dataframes[label], segment_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "362ae4e7-67e4-4ad3-94c1-ed93ed9e56eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment the data\n",
    "segment_size = 80\n",
    "brain_imaging_segments = {}\n",
    "\n",
    "def segment_brain_imaging_data(df, segment_size):\n",
    "\n",
    "    n_segments = 75\n",
    "    brain_imaging_segments = []\n",
    "\n",
    "    for i in range(n_segments):\n",
    "        start_idx = int(i* segment_size)\n",
    "        end_idx = start_idx + int(segment_size)\n",
    "        segment = df[start_idx:end_idx]\n",
    "\n",
    "        brain_imaging_segments.append(list(segment))\n",
    "\n",
    "    return brain_imaging_segments\n",
    "\n",
    "for label in label_list:\n",
    "    segments = segment_brain_imaging_data(brain_imaging_dataframes[label], segment_size) \n",
    "     # Remove the last segment for each label\n",
    "    segments = segments[:-1]\n",
    "    # Save in dictionary\n",
    "    brain_imaging_segments[label] = segments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed8c95c-4f96-422f-b287-ffa159ddb93e",
   "metadata": {},
   "source": [
    "# Data Fusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fd0dc7-1830-43d6-a0f9-3f83686c9624",
   "metadata": {},
   "source": [
    "## Approach 1: Joint_ICA function with dimensionality reduction for both EEG and imaging segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "737f252a-555c-4ec0-9c37-708da0e83860",
   "metadata": {},
   "outputs": [],
   "source": [
    "def joint_ICA_with_dim_reduction(EEG_segments, imaging_segments, hidden_dim):\n",
    "    n_segments = EEG_segments.shape[0]\n",
    "    n_features = min(EEG_segments.shape[1], imaging_segments.shape[1] * imaging_segments.shape[2] * imaging_segments.shape[3])\n",
    "    \n",
    "    # Apply PCA for dimensionality reduction on EEG segments\n",
    "    pca_EEG = PCA(n_components=n_segments)\n",
    "    EEG_segments_pca = pca_EEG.fit_transform(EEG_segments)\n",
    "    \n",
    "    # Reshape and apply PCA for dimensionality reduction to the imaging segments\n",
    "    n_samples, n_x, n_y, n_z = imaging_segments.shape\n",
    "    imaging_segments_reshaped = imaging_segments.reshape(n_samples, n_x * n_y * n_z)\n",
    "    pca_imaging = PCA(n_components=n_segments)\n",
    "    imaging_segments_pca = pca_imaging.fit_transform(imaging_segments_reshaped)\n",
    "    \n",
    "    # Concatenate the reduced EEG and imaging segments\n",
    "    print(EEG_segments_pca.shape)\n",
    "    print(imaging_segments_pca.shape)\n",
    "\n",
    "    data_segments = np.concatenate((EEG_segments_pca, imaging_segments_pca), axis=1)\n",
    "    \n",
    "    # Apply FastICA for joint independent component analysis on segments\n",
    "    # Adapt ICA parameters because previously it did not converge\n",
    "    #transformer = FastICA(n_components=hidden_dim, random_state=0, tol=0.0001, max_iter=2000, algorithm='parallel')\n",
    "    transformer = FastICA(n_components=hidden_dim, random_state=0, tol=0.001, max_iter=1500, algorithm='parallel')\n",
    "    joint_components = transformer.fit_transform(data_segments)\n",
    "\n",
    "\n",
    "    # Reconstruct both data modalities\n",
    "    reconstructed_data_segments = transformer.inverse_transform(joint_components)\n",
    "\n",
    "    # Split into dimensionality reduced modalities\n",
    "    reconstruced_EEG_segments_pca = reconstructed_data_segments[:, :74]\n",
    "    reconstruced_imaging_segments_pca = reconstructed_data_segments[:, 74:]\n",
    "\n",
    "    # Reconstruct each modality\n",
    "    reconstructed_reshaped_imaging_segments = pca_imaging.inverse_transform(reconstruced_imaging_segments_pca)\n",
    "    reconstructed_imaging_segments = reconstructed_reshaped_imaging_segments.reshape(n_samples, n_x, n_y, n_z)\n",
    "    reconstructed_EEG_segments = pca_EEG.inverse_transform(reconstruced_EEG_segments_pca)\n",
    "    \n",
    "    return reconstructed_EEG_segments, reconstructed_imaging_segments\n",
    "\n",
    "#### Test on test data ####\n",
    "\n",
    "# EEG_segments shape: (74, 2000), imaging_segments shape: (74, 80, 300, 260)\n",
    "#EEG_segments = np.random.rand(74, 2000)\n",
    "#imaging_segments = np.random.rand(74, 80, 300, 260)\n",
    "\n",
    "# Apply joint ICA to the test EEG and video data\n",
    "#data_segments = joint_ICA_with_dim_reduction(EEG_segments, imaging_segments, hidden_dim=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d963fc60-bb92-4a3e-9f8d-4040952e1f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(74, 74)\n",
      "(74, 74)\n"
     ]
    }
   ],
   "source": [
    "reconstructed_EEG_segments, reconstructed_imaging_segments = joint_ICA_with_dim_reduction(np.array(eeg_segments[0]), np.array(brain_imaging_segments[0]), hidden_dim=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6272c3de-8bd5-434a-b9be-5a4f4f438390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Viewer(camera=Camera(center=(0.0, 149.5, 129.5), zoom=1.6698888888888888, angles=(0.0, 0.0, 90.0), perspective=0.0, mouse_pan=True, mouse_zoom=True), cursor=Cursor(position=(39.0, 1.0, 0.0), scaled=True, size=1, style=<CursorStyle.STANDARD: 'standard'>), dims=Dims(ndim=3, ndisplay=2, last_used=0, range=((0.0, 80.0, 1.0), (0.0, 300.0, 1.0), (0.0, 260.0, 1.0)), current_step=(39, 149, 129), order=(0, 1, 2), axis_labels=('0', '1', '2')), grid=GridCanvas(stride=1, shape=(-1, -1), enabled=False), layers=[<Image layer 'Image' at 0x7df05da20>], help='use <2> for transform', status='Ready', tooltip=Tooltip(visible=False, text=''), theme='dark', title='napari', mouse_over_canvas=False, mouse_move_callbacks=[], mouse_drag_callbacks=[], mouse_double_click_callbacks=[], mouse_wheel_callbacks=[<function dims_scroll at 0x7d2f5b010>], _persisted_mouse_event={}, _mouse_drag_gen={}, _mouse_wheel_gen={}, keymap={})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "napari.view_image(np.array(reconstructed_imaging_segments[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c921396-3b7f-4bc3-a307-fe14757ce26e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3aef5be1-279f-4a6f-b6f0-83e76ebf4641",
   "metadata": {},
   "source": [
    "We will use this approach for now. It converges with the new parameters, but not always\n",
    "\n",
    "=> Increase tolerance\n",
    "\n",
    "=> Then increase iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89519f92-d78a-430b-aba3-46aff05a6f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dictionary with labels as keys and joint components as values\n",
    "\n",
    "joint_components_dict = {}\n",
    "\n",
    "for label in label_list:\n",
    "    joint_components_dict[label] = joint_ICA_with_dim_reduction(np.array(eeg_segments[label]), np.array(brain_imaging_segments[label]), hidden_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0421e4a-7c95-43a4-b963-5f884fcc1104",
   "metadata": {},
   "source": [
    "## Approach 2: Joint_ICA function with reshaping for EEG and imaging segments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4308e435-bf0f-478b-bd77-19a635e6b8f0",
   "metadata": {},
   "source": [
    "Does this approach converge now with the new parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24eb42c5-6708-4cb6-a642-71f85dc37709",
   "metadata": {},
   "outputs": [],
   "source": [
    "def joint_ICA_with_reshaping(EEG_segments, imaging_segments):\n",
    "    n_segments = EEG_segments.shape[0]\n",
    "    n_features_EEG = EEG_segments.shape[1]\n",
    "    \n",
    "    # Reshape the EEG segments to have a 2D shape\n",
    "    EEG_segments_reshaped = EEG_segments.reshape(n_segments, n_features_EEG)\n",
    "    \n",
    "    # Reshape the imaging segments to 2D\n",
    "    n_samples, n_x, n_y, n_z = imaging_segments.shape\n",
    "    imaging_segments_reshaped = imaging_segments.reshape(n_samples, n_x * n_y * n_z)\n",
    "    \n",
    "    # Concatenate EEG and imaging segments\n",
    "    data_segments = np.concatenate((EEG_segments_reshaped, imaging_segments_reshaped), axis=1)\n",
    "    \n",
    "    # Apply FastICA for joint independent component analysis on segments with adjusted parameters\n",
    "    # Adapt ICA parameters because previously it did not converge\n",
    "    transformer = FastICA(n_components=10, random_state=0, tol=0.0001, max_iter=2000, algorithm='parallel')\n",
    "    joint_components = transformer.fit_transform(data_segments)\n",
    "\n",
    "    return joint_components\n",
    "\n",
    "#### Test on test data ####\n",
    "\n",
    "# EEG_segments shape: (74, 2000), imaging_segments shape: (74, 80, 300, 260)\n",
    "EEG_segments = np.random.rand(74, 2000)\n",
    "imaging_segments = np.random.rand(74, 80, 300, 260)\n",
    "\n",
    "# Apply joint ICA to the test EEG and video data\n",
    "#joint_components_with_reshaping = joint_ICA_with_reshaping(EEG_segments, imaging_segments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01530096-b3e5-485b-8dac-bb734b8b3496",
   "metadata": {},
   "source": [
    "Next steps: Experiment with parameters (n_components, tol, max_iter) to ensure convergence and be able to minimize the reconstruction error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e4e525-c0ac-4d26-ae4f-6318877e4d3f",
   "metadata": {},
   "source": [
    "## Approach 3: Simple Multimodal linear model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6300ac07-df97-42e4-b376-9baab6b996f4",
   "metadata": {},
   "source": [
    "Generative model as described in the paper. Does not work yet!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4544291c-b415-4976-9ca6-9edf7460324a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# EEG_segments shape: (74, 2000), imaging_segments shape: (74, 80, 300, 260)\\nEEG_segments = np.random.rand(74, 2000)\\nimaging_segments = np.random.rand(74, 80, 300, 260)\\n\\n# Reshape imaging_segments to (74, 80*300*260) for linear decoding\\nimaging_segments_flat = imaging_segments.reshape(74, -1)\\n\\n# Concatenate EEG and flattened imaging data for joint linear decoding\\njoint_data = np.concatenate((EEG_segments, imaging_segments_flat), axis=1)\\n\\n# Perform linear decoding to estimate neural sources\\n# Assuming W_x is the spatial extraction filter matrix\\nW_x = np.linalg.pinv(joint_data)  # Pseudo-inverse of joint data as decoding matrix\\n\\n# Estimate neural sources\\nestimated_sources = np.dot(joint_data, W_x)\\n\\n# Extract EEG and imaging source estimates\\nestimated_EEG_sources = estimated_sources[:, :2000]\\nestimated_imaging_sources_flat = estimated_sources[:, 2000:]\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# EEG_segments shape: (74, 2000), imaging_segments shape: (74, 80, 300, 260)\n",
    "EEG_segments = np.random.rand(74, 2000)\n",
    "imaging_segments = np.random.rand(74, 80, 300, 260)\n",
    "\n",
    "# Reshape imaging_segments to (74, 80*300*260) for linear decoding\n",
    "imaging_segments_flat = imaging_segments.reshape(74, -1)\n",
    "\n",
    "# Concatenate EEG and flattened imaging data for joint linear decoding\n",
    "joint_data = np.concatenate((EEG_segments, imaging_segments_flat), axis=1)\n",
    "\n",
    "# Perform linear decoding to estimate neural sources\n",
    "# Assuming W_x is the spatial extraction filter matrix\n",
    "W_x = np.linalg.pinv(joint_data)  # Pseudo-inverse of joint data as decoding matrix\n",
    "\n",
    "# Estimate neural sources\n",
    "estimated_sources = np.dot(joint_data, W_x)\n",
    "\n",
    "# Extract EEG and imaging source estimates\n",
    "estimated_EEG_sources = estimated_sources[:, :2000]\n",
    "estimated_imaging_sources_flat = estimated_sources[:, 2000:]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2810f3e9-6302-40ac-8d2c-be8a81e80b1b",
   "metadata": {},
   "source": [
    "# Computing Persistence Diagrams from the joint components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42192eec-f9cc-4941-8769-0d10e18eea40",
   "metadata": {},
   "source": [
    "## Compute and Save Persistence Diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c868bf06-c676-4e4b-80a6-0cf1d5f978d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will look at 0, 1 and 2 dimensional holes\n",
    "homology_dimensions = [0, 1, 2]\n",
    "\n",
    "# We will use a Vietoris Rips filtrations\n",
    "persistence = VietorisRipsPersistence(\n",
    "    homology_dimensions=homology_dimensions, n_jobs=10\n",
    ")\n",
    "\n",
    "\n",
    "embedding_dimension= 6 # for data exploration\n",
    "embedding_time_delay = 7\n",
    "stride = 1\n",
    "\n",
    "embedder = SingleTakensEmbedding(\n",
    "    parameters_type=\"fixed\",\n",
    "    n_jobs=2,\n",
    "    time_delay=embedding_time_delay, # computed above\n",
    "    dimension=embedding_dimension, # computed above\n",
    "    stride=stride,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2ed9acb-daa1-4849-8d9f-0f2b100f97e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_embeddings_and_diagrams(segments, time_delay_embeddings, persistence_diagrams, label):\n",
    "\n",
    "    time_delay_embeddings[\"Label_\"+str(label)] = []\n",
    "    persistence_diagrams[\"Label_\"+str(label)] = []\n",
    "\n",
    "    # Compute embeddings and diagrams for the complete data\n",
    "    for diagram_idx in range(len(segments[label])):\n",
    "        time_delay_embeddings[\"Label_\"+str(label)].append(embedder.fit_transform(segments[label][diagram_idx])[None, :, :])\n",
    "        persistence_diagrams[\"Label_\"+str(label)].append(persistence.fit_transform(time_delay_embeddings[\"Label_\"+str(label)][diagram_idx]))\n",
    "    \n",
    "    return time_delay_embeddings, persistence_diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d610f193-dbbb-49b3-95c6-5b559fcf1222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute embeddings and persistence diagrams for the complete data\n",
    "\n",
    "time_delay_embeddings = {}\n",
    "persistence_diagrams = {}\n",
    "\n",
    "for label in label_list:\n",
    "    time_delay_embeddings, persistence_diagrams = compute_embeddings_and_diagrams(joint_components_dict, time_delay_embeddings, persistence_diagrams, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83ec41f0-5492-4e13-97be-c306998737e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"Embeddings_and_Persistence_Diagrams/\"+str(subject)+\"/Persistence_Diagrams_Hidden_Dim\"+str(hidden_dim)+\".npy\", np.array(persistence_diagrams, dtype=object), allow_pickle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
