{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b4ca714b-5b12-4c04-96c0-4ebc0cc0a790",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyedflib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from statsmodels.tsa import stattools\n",
    "from scipy.signal import periodogram\n",
    "import logging\n",
    "from itertools import groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ab9309b2-0b0d-4d86-8156-be523d39551a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose if you want to look at EEG or EMG data\n",
    "data_type = \"EEG\"\n",
    "data_type = \"EMG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ae01d79f-af79-44e3-9d52-186a9d41152b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose individuum\n",
    "subject = \"m294\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0a81b9c9-a2e9-46c2-8ae8-4a5f02dd0571",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = [0, 1, 2, 3, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "85fd9907-0ecf-4827-bd57-da10d9c03cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EEG & EMG data\n",
    "data = {}\n",
    "\n",
    "for label in label_list:\n",
    "    data[label] = pd.read_csv(\"Data/\"+str(subject)+\"/run0\"+str(label)+\"/Time_Series_Data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ea3b4c-8747-430b-9966-2e7eaaca0b74",
   "metadata": {},
   "source": [
    "# Segmenting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4d599237-77e5-4221-9b79-f8a638334fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_data(df, segment_size, step_size = 2):\n",
    "    \"\"\"\n",
    "    Segments time-series data into EEG and EMG segments.\n",
    "\n",
    "    Parameters:\n",
    "    - df (DataFrame): The input dataframe containing the columns \"Time\", \"EEG\" and \"EMG\".\n",
    "    - segment_size (float): The desired size of each segment in seconds.\n",
    "    - step_size (float, optional): The step size of \"Time\" in milliseconds. Default is 2 millisecond.\n",
    "\n",
    "    Returns:\n",
    "    Tuple of two lists:\n",
    "    - List of EEG segments.\n",
    "    - List of EMG segments.\n",
    "    \"\"\"\n",
    "\n",
    "    n_segments = int(df[\"time\"].iloc[-1]) // segment_size\n",
    "    eeg_segments = []\n",
    "    emg_segments = []\n",
    "\n",
    "    for i in range(n_segments):\n",
    "        start_idx = int(i* segment_size*1000/step_size)\n",
    "        end_idx = start_idx + int(segment_size*1000/step_size)\n",
    "        segment = df.iloc[start_idx:end_idx]\n",
    "        eeg_segments.append(list(segment[\"voltage\"]))\n",
    "        emg_segments.append(list(segment[\"emg\"]))\n",
    "\n",
    "    return eeg_segments, emg_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0518ccd3-0e88-4807-819e-d2ebea2dadb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment the data\n",
    "segment_size = 4  # seconds\n",
    "eeg_segments = {}\n",
    "emg_segments = {}\n",
    "\n",
    "for label in label_list:\n",
    "    eeg_segments[label], emg_segments[label] = segment_data(data[label], segment_size, step_size = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "238a7837-307c-47e3-a24d-d7dc3dfd2297",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_type == \"EEG\":\n",
    "    segments = segments\n",
    "else:\n",
    "    segments = eeg_segments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9bc134-5884-4d66-b869-6ff1544366a1",
   "metadata": {},
   "source": [
    "## Choose Train and Test Data Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2958da95-219a-4153-b0b3-47372f5b2e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical Features\n",
    "\n",
    "def compute_means(segments,  label):\n",
    "    \"\"\"\n",
    "    Computes means of all segments for a certain label\n",
    "\n",
    "    Parameters:\n",
    "    - segments (list of lists): Complete EEG/EMG segments\n",
    "    - indices_dict (dicts): dictionary which contains all segment indices (values) for each label (key) for either train or test set.\n",
    "    - label (int): Label we want to compute means for. 1, 3, 5 or 7.\n",
    "\n",
    "    Returns:\n",
    "    - Means of time series segments (list of floats)\n",
    "    \"\"\"\n",
    "    \n",
    "    means = []\n",
    "\n",
    "    for sgmt in segments:\n",
    "        means.append(statistics.mean(sgmt))\n",
    "\n",
    "    return means\n",
    "    \n",
    "\n",
    "\n",
    "def compute_variance(segments,  label):\n",
    "    \"\"\"\n",
    "    Computes variances of all segments for a certain label\n",
    "\n",
    "    Parameters:\n",
    "    - segments (list of lists): Complete EEG/EMG segments\n",
    "    - indices_dict (dicts): dictionary which contains all segment indices (values) for each label (key) for either train or test set.\n",
    "    - label (int): Label we want to compute means for. 1, 3, 5 or 7.\n",
    "\n",
    "    Returns:\n",
    "    - Variances of time series segments (list of floats)\n",
    "    \"\"\"\n",
    "    variances = []\n",
    "\n",
    "    for sgmt in segments:\n",
    "        variances.append(statistics.variance(sgmt))\n",
    "\n",
    "    return variances\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compute_entropy(segments,  label, freq = 1):\n",
    "    \"\"\"\n",
    "    Computes entropies of all segments for a certain label\n",
    "\n",
    "    Parameters:\n",
    "    - segments (list of lists): Complete EEG/EMG segments\n",
    "    - indices_dict (dicts): dictionary which contains all segment indices (values) for each label (key) for either train or test set.\n",
    "    - label (int): Label we want to compute means for. 1, 3, 5 or 7.\n",
    "\n",
    "    Returns:\n",
    "    - Entropies of time series segments (list of floats) \n",
    "    \"\"\"\n",
    "    entropies = []\n",
    "\n",
    "    for sgmt in segments:\n",
    "\n",
    "        _, psd = periodogram(sgmt, freq)\n",
    "        psd_norm = psd / np.sum(psd)\n",
    "        entropy = np.nansum(psd_norm * np.log2(psd_norm))\n",
    "        entropies.append(-(entropy / np.log2(psd_norm.size)))\n",
    "\n",
    "    return entropies\n",
    "\n",
    "\n",
    "def compute_lumpiness(segments,  label, window_size = 30):\n",
    "    \"\"\"\n",
    "    Computes lumpiness of all segments for a certain label\n",
    "\n",
    "    Parameters:\n",
    "    - segments (list of lists): Complete EEG/EMG segments\n",
    "    - indices_dict (dicts): dictionary which contains all segment indices (values) for each label (key) for either train or test set.\n",
    "    - label (int): Label we want to compute means for. 1, 3, 5 or 7.\n",
    "\n",
    "    Returns:\n",
    "    - Lumpinesses of time series segments (list of floats)\n",
    "    \"\"\"\n",
    "    lumpinesses = []\n",
    "\n",
    "    for sgmt in segments:\n",
    "        lumpinesses.append(np.var([np.var(x_w) for x_w in np.array_split(sgmt, len(sgmt) // window_size + 1)]))\n",
    "\n",
    "    return lumpinesses\n",
    "\n",
    "\n",
    "def compute_stabilities(segments,  label, window_size = 30):\n",
    "    \"\"\"\n",
    "    Computes stabilities of all segments for a certain label\n",
    "\n",
    "    Parameters:\n",
    "    - segments (list of lists): Complete EEG/EMG segments\n",
    "    - indices_dict (dicts): dictionary which contains all segment indices (values) for each label (key) for either train or test set.\n",
    "    - label (int): Label we want to compute means for. 1, 3, 5 or 7.\n",
    "\n",
    "    Returns:\n",
    "    - Stabilities of time series segments (list of floats)\n",
    "    \"\"\"\n",
    "    stabilities = []\n",
    "\n",
    "    for sgmt in segments:\n",
    "        stabilities.append(np.var([np.mean(x_w) for x_w in np.array_split(sgmt, len(sgmt) // window_size + 1)]))\n",
    "\n",
    "    return stabilities\n",
    "\n",
    "\n",
    "\n",
    "def compute_hursts(segments,  label, lag_size = 30):\n",
    "    \"\"\"\n",
    "    Computes hursts of all segments for a certain label\n",
    "\n",
    "    Parameters:\n",
    "    - segments (list of lists): Complete EEG/EMG segments\n",
    "    - indices_dict (dicts): dictionary which contains all segment indices (values) for each label (key) for either train or test set.\n",
    "    - label (int): Label we want to compute means for. 1, 3, 5 or 7.\n",
    "\n",
    "    Returns:\n",
    "    - Hursts of time series segments (list of floats)\n",
    "    \"\"\"\n",
    "    hursts = []\n",
    "\n",
    "    for sgmt in segments:\n",
    "        # Create the range of lag values\n",
    "        lags = range(2, min(lag_size, len(sgmt) - 1))\n",
    "        # Calculate the array of the variances of the lagged differences\n",
    "        tau = [np.std(np.asarray(sgmt)[lag:] - np.asarray(sgmt)[:-lag]) for lag in lags]\n",
    "        # Use a linear fit to estimate the Hurst Exponent\n",
    "        poly = np.polyfit(np.log(lags), np.log(tau), 1)\n",
    "        # Return the Hurst exponent from the polyfit output\n",
    "        hursts.append(poly[0] if not np.isnan(poly[0]) else 0)\n",
    "    return hursts\n",
    "\n",
    "\n",
    "\n",
    "def compute_standard_dev_of_first_der(segments,  label):\n",
    "    \"\"\"\n",
    "    Computes standard deviation of the first derivative of all segments for a certain label\n",
    "\n",
    "    Parameters:\n",
    "    - segments (list of lists): Complete EEG/EMG segments\n",
    "    - indices_dict (dicts): dictionary which contains all segment indices (values) for each label (key) for either train or test set.\n",
    "    - label (int): Label we want to compute means for. 1, 3, 5 or 7.\n",
    "\n",
    "    Returns:\n",
    "    - standard deviation of the first derivative of time series segments (list of floats)\n",
    "    \"\"\"\n",
    "    stds = []\n",
    "\n",
    "    for sgmt in segments:\n",
    "        stds.append(np.std(np.gradient(sgmt)))\n",
    "\n",
    "    return stds\n",
    "\n",
    "    \n",
    "    \n",
    "def compute_crossing_points(segments,  label):\n",
    "    \"\"\"\n",
    "    Computes crossing points of all segments for a certain label.\n",
    "    Crossing points happen when a time series crosses the median line.\n",
    "\n",
    "\n",
    "    Parameters:\n",
    "    - segments (list of lists): Complete EEG/EMG segments\n",
    "    - indices_dict (dicts): dictionary which contains all segment indices (values) for each label (key) for either train or test set.\n",
    "    - label (int): Label we want to compute means for. 1, 3, 5 or 7.\n",
    "\n",
    "    Returns:\n",
    "    - crossing points of time series segments (list of floats)\n",
    "    \"\"\"\n",
    "    \n",
    "    crossing_points = []\n",
    "\n",
    "    for sgmt in segments:\n",
    "        # Calculate the number of crossing points.\n",
    "        median = np.median(sgmt)\n",
    "        cp = 0\n",
    "        for i in range(len(sgmt) - 1):\n",
    "            if sgmt[i] <= median < sgmt[i + 1] or sgmt[i] >= median > sgmt[i + 1]:\n",
    "                cp += 1\n",
    "        crossing_points.append(cp)\n",
    "        \n",
    "    return crossing_points\n",
    "\n",
    "\n",
    "\n",
    "def compute_binarized_means(segments,  label):\n",
    "    \"\"\"\n",
    "    Computes binarized means of all segments for a certain label.\n",
    "    Converts time series array into a binarized version.\n",
    "    Time-series values above its mean are given 1, and those below the mean\n",
    "    are 0. Returns the average value of the binarized vector.\n",
    "\n",
    "\n",
    "    Parameters:\n",
    "    - segments (list of lists): Complete EEG/EMG segments\n",
    "    - indices_dict (dicts): dictionary which contains all segment indices (values) for each label (key) for either train or test set.\n",
    "    - label (int): Label we want to compute means for. 1, 3, 5 or 7.\n",
    "\n",
    "    Returns:\n",
    "    - binarized menas of time series segments (list of floats)\n",
    "    \"\"\"\n",
    "    binarized_means = []\n",
    "\n",
    "    for sgmt in segments:\n",
    "        binarized_means.append(np.mean(np.asarray(sgmt) > np.mean(sgmt)))\n",
    "\n",
    "    return binarized_means\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dc9f033c-e2e1-4771-b48e-c4c062f3cc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_dataframes(label_list, segments, data_type, subject):\n",
    "    \"\"\"\n",
    "    Create feature dataframes for each label using segment data and concatenate them.\n",
    "    \n",
    "    Args:\n",
    "    - label_list (list): List of labels.\n",
    "    - segments (dict): Dictionary containing segments for each label.\n",
    "    - data_type (str): Type of data.\n",
    "    - subject (str): Subject identifier.\n",
    "    \n",
    "    Returns:\n",
    "    - pd.DataFrame: Concatenated feature dataframe.\n",
    "    \"\"\"\n",
    "    feature_dataframes = {}\n",
    "\n",
    "    for label in label_list:\n",
    "        feature_dataframes[label] = pd.DataFrame()\n",
    "        feature_dataframes[label][str(data_type)+\"_Mean\"] = compute_means(segments[label], label)\n",
    "        feature_dataframes[label][str(data_type)+\"_Variance\"] = compute_variance(segments[label], label)\n",
    "        feature_dataframes[label][str(data_type)+\"_Entropy\"] = compute_entropy(segments[label], label)\n",
    "        feature_dataframes[label][str(data_type)+\"_Lumpiness\"] = compute_lumpiness(segments[label], label)\n",
    "        feature_dataframes[label][str(data_type)+\"_Stability\"] = compute_stabilities(segments[label], label)\n",
    "        feature_dataframes[label][str(data_type)+\"_Hurst\"] = compute_hursts(segments[label], label)\n",
    "        feature_dataframes[label][str(data_type)+\"_STD_Derivative\"] = compute_standard_dev_of_first_der(segments[label], label)\n",
    "        feature_dataframes[label][str(data_type)+\"_Crossing_Points\"] = compute_crossing_points(segments[label], label)\n",
    "        feature_dataframes[label][str(data_type)+\"_Binarized_Means\"] = compute_binarized_means(segments[label], label)\n",
    "\n",
    "        feature_dataframes[label][\"Label\"] = label\n",
    "        feature_dataframes[label][\"Subject\"] = subject\n",
    "        feature_dataframes[label][\"Train\"] = True\n",
    "\n",
    "    # Concatenate dataframes while resetting indices (ignore_index=True)\n",
    "    feature_df = pd.concat([feature_dataframes[0], feature_dataframes[1], feature_dataframes[2],\n",
    "                                  feature_dataframes[3], feature_dataframes[4]], ignore_index=True)\n",
    "    \n",
    "    return feature_df\n",
    "\n",
    "feature_df = create_feature_dataframes(label_list, segments, data_type, subject)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a82d601f-1a86-40eb-b090-4d29b867e93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df.to_csv(\"Features/\"+str(subject)+\"/\"+str(data_type)+\"/Statistical_Features.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257522a3-afef-4af0-b82b-2d74fe873223",
   "metadata": {},
   "source": [
    "This code contains modified functions from the python package kats, which itself is only\n",
    "available for earlier Python versions.\n",
    "\n",
    "MIT License\n",
    "\n",
    "Copyright (c) Facebook, Inc. and its affiliates.\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
