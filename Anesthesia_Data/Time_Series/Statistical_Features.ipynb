{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4ca714b-5b12-4c04-96c0-4ebc0cc0a790",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyedflib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from statsmodels.tsa import stattools\n",
    "from scipy.signal import periodogram\n",
    "import logging\n",
    "from itertools import groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db8f81dd-194a-4942-a42b-79af77d32bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose EEG or EMG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab9309b2-0b0d-4d86-8156-be523d39551a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose if you want to look at EEG or EMG data\n",
    "\n",
    "data_type = \"EEG\" # Does not have an effect yet, will be added later when processing anesthesia data\n",
    "#data_type = \"EMG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a81b9c9-a2e9-46c2-8ae8-4a5f02dd0571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EEG/EMG data\n",
    "\n",
    "def read_edf_file(file_path):\n",
    "    \"\"\"\n",
    "    Reads an .edf file and returns the EEG and EMG streams as pandas DataFrames.\n",
    "    \"\"\"\n",
    "    f = pyedflib.EdfReader(file_path)\n",
    "\n",
    "    # Assuming the EEG channel is the first channel and EMG is the second channel\n",
    "    eeg_signal = f.readSignal(0)\n",
    "    emg_signal = f.readSignal(1)\n",
    "\n",
    "    # Extract the channel names for the DataFrame\n",
    "    eeg_channel_name = f.getSignalLabels()[0]\n",
    "    emg_channel_name = f.getSignalLabels()[1]\n",
    "\n",
    "    # Get the sample frequency\n",
    "    sample_frequency = f.getSampleFrequency(0)  # Assuming both streams have the same frequency\n",
    "\n",
    "    # Calculate the timestamps for the samples\n",
    "    n_samples = min(len(eeg_signal), len(emg_signal))\n",
    "    time = [i / sample_frequency for i in range(n_samples)]\n",
    "\n",
    "    # Create pandas DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'Time': time,\n",
    "        eeg_channel_name: eeg_signal[:n_samples],\n",
    "        emg_channel_name: emg_signal[:n_samples],\n",
    "    })\n",
    "\n",
    "    # Close the EdfReader\n",
    "    f.close()\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Read file\n",
    "file = 'Data/edf_293.edf'\n",
    "\n",
    "# Convert to pandas DataFrame\n",
    "data = read_edf_file(file)\n",
    "data = data.iloc[1:] # The first label is NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85fd9907-0ecf-4827-bd57-da10d9c03cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels\n",
    "\n",
    "# Read data\n",
    "label_df = pd.read_csv(\"Data/Data_293.csv\")\n",
    "labels = label_df[\"NAPS_Numeric\"].iloc[1:] # The first label is NaN\n",
    "\n",
    "# Convert to list\n",
    "labels = [int(label) for label in labels] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ea3b4c-8747-430b-9966-2e7eaaca0b74",
   "metadata": {},
   "source": [
    "# Segmenting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d599237-77e5-4221-9b79-f8a638334fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_data(df, segment_size, step_size = 2):\n",
    "    \"\"\"\n",
    "    Segments time-series data into EEG and EMG segments.\n",
    "\n",
    "    Parameters:\n",
    "    - df (DataFrame): The input dataframe containing the columns \"Time\", \"EEG\" and \"EMG\".\n",
    "    - segment_size (float): The desired size of each segment in seconds.\n",
    "    - step_size (float, optional): The step size of \"Time\" in milliseconds. Default is 2 millisecond.\n",
    "\n",
    "    Returns:\n",
    "    Tuple of two lists:\n",
    "    - List of EEG segments.\n",
    "    - List of EMG segments.\n",
    "    \"\"\"\n",
    "\n",
    "    n_segments = int(df[\"Time\"].iloc[-1]) // segment_size\n",
    "    eeg_segments = []\n",
    "    emg_segments = []\n",
    "\n",
    "    for i in range(n_segments):\n",
    "        start_idx = int(i* segment_size*1000/step_size)\n",
    "        end_idx = start_idx + int(segment_size*1000/step_size)\n",
    "        segment = df.iloc[start_idx:end_idx]\n",
    "        eeg_segments.append(list(segment[\"EEG\"]))\n",
    "        emg_segments.append(list(segment[\"EMG\"]))\n",
    "\n",
    "    return eeg_segments, emg_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0518ccd3-0e88-4807-819e-d2ebea2dadb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment the data\n",
    "segment_size = 4  # seconds\n",
    "eeg_segments, emg_segments = segment_data(data, segment_size, step_size = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38babf61-f34a-48f1-939f-5e38ce415512",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Choose Train and Test Data Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2efd17e-f338-4a6f-a614-bbe3e9d83c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose test data set size for classification later (recommended: 0.2-0.3)\n",
    "\n",
    "test_size = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7696563c-9996-40dd-99bc-8ec2b960bd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the labels into training and testing set labels\n",
    "all_indices = np.arange(len(labels))\n",
    "\n",
    "# Should be the same as in Preprocessing_And_Computing_Persistence Diagrams due to fixed random state\n",
    "_, _, _, _, train_indices, test_indices = train_test_split(eeg_segments, labels, all_indices, test_size=test_size, random_state=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f2c7c53-1d9d-4464-8413-b9b4a5f60367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many segments per label do you want to analyze?\n",
    "no_segments = len(labels) # complete data in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4dedfa31-daf8-4d28-8325-6246f7d96cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionaries which contain all (test and train) segment indices (values) for each label (key)\n",
    "\n",
    "train_indices_dict = {}\n",
    "test_indices_dict = {}\n",
    "\n",
    "for label in list(set(labels)): \n",
    "    indices = [index for index, value in enumerate(labels) if (value == label and index in train_indices)][:no_segments]\n",
    "    train_indices_dict[label] = indices\n",
    "\n",
    "for label in list(set(labels)): \n",
    "    indices = [index for index, value in enumerate(labels) if (value == label and index in test_indices)][:no_segments]\n",
    "    test_indices_dict[label] = indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2958da95-219a-4153-b0b3-47372f5b2e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical Features\n",
    "\n",
    "def compute_means(segments, indices_dict, label):\n",
    "    \"\"\"\n",
    "    Computes means of all segments for a certain label\n",
    "\n",
    "    Parameters:\n",
    "    - segments (list of lists): Complete EEG/EMG segments\n",
    "    - indices_dict (dicts): dictionary which contains all segment indices (values) for each label (key) for either train or test set.\n",
    "    - label (int): Label we want to compute means for. 1, 3, 5 or 7.\n",
    "\n",
    "    Returns:\n",
    "    - Means of time series segments (list of floats)\n",
    "    \"\"\"\n",
    "    \n",
    "    means = []\n",
    "\n",
    "    for label_idx in indices_dict[label]:\n",
    "        means.append(statistics.mean(eeg_segments[label_idx]))\n",
    "\n",
    "    return means\n",
    "    \n",
    "\n",
    "\n",
    "def compute_variance(segments, indices_dict, label):\n",
    "    \"\"\"\n",
    "    Computes variances of all segments for a certain label\n",
    "\n",
    "    Parameters:\n",
    "    - segments (list of lists): Complete EEG/EMG segments\n",
    "    - indices_dict (dicts): dictionary which contains all segment indices (values) for each label (key) for either train or test set.\n",
    "    - label (int): Label we want to compute means for. 1, 3, 5 or 7.\n",
    "\n",
    "    Returns:\n",
    "    - Variances of time series segments (list of floats)\n",
    "    \"\"\"\n",
    "    variances = []\n",
    "\n",
    "    for label_idx in indices_dict[label]:\n",
    "        variances.append(statistics.variance(segments[label_idx]))\n",
    "\n",
    "    return variances\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compute_entropy(segments, indices_dict, label, freq = 1):\n",
    "    \"\"\"\n",
    "    Computes entropies of all segments for a certain label\n",
    "\n",
    "    Parameters:\n",
    "    - segments (list of lists): Complete EEG/EMG segments\n",
    "    - indices_dict (dicts): dictionary which contains all segment indices (values) for each label (key) for either train or test set.\n",
    "    - label (int): Label we want to compute means for. 1, 3, 5 or 7.\n",
    "\n",
    "    Returns:\n",
    "    - Entropies of time series segments (list of floats) \n",
    "    \"\"\"\n",
    "    entropies = []\n",
    "\n",
    "    for label_idx in indices_dict[label]:\n",
    "\n",
    "        _, psd = periodogram(segments[label_idx], freq)\n",
    "        psd_norm = psd / np.sum(psd)\n",
    "        entropy = np.nansum(psd_norm * np.log2(psd_norm))\n",
    "        entropies.append(-(entropy / np.log2(psd_norm.size)))\n",
    "\n",
    "    return entropies\n",
    "\n",
    "\n",
    "def compute_lumpiness(segments, indices_dict, label, window_size = 30):\n",
    "    \"\"\"\n",
    "    Computes lumpiness of all segments for a certain label\n",
    "\n",
    "    Parameters:\n",
    "    - segments (list of lists): Complete EEG/EMG segments\n",
    "    - indices_dict (dicts): dictionary which contains all segment indices (values) for each label (key) for either train or test set.\n",
    "    - label (int): Label we want to compute means for. 1, 3, 5 or 7.\n",
    "\n",
    "    Returns:\n",
    "    - Lumpinesses of time series segments (list of floats)\n",
    "    \"\"\"\n",
    "    lumpinesses = []\n",
    "\n",
    "    for label_idx in indices_dict[label]:\n",
    "        lumpinesses.append(np.var([np.var(x_w) for x_w in np.array_split(segments[label_idx], len(segments[label_idx]) // window_size + 1)]))\n",
    "\n",
    "    return lumpinesses\n",
    "\n",
    "\n",
    "def compute_stabilities(segments, indices_dict, label, window_size = 30):\n",
    "    \"\"\"\n",
    "    Computes stabilities of all segments for a certain label\n",
    "\n",
    "    Parameters:\n",
    "    - segments (list of lists): Complete EEG/EMG segments\n",
    "    - indices_dict (dicts): dictionary which contains all segment indices (values) for each label (key) for either train or test set.\n",
    "    - label (int): Label we want to compute means for. 1, 3, 5 or 7.\n",
    "\n",
    "    Returns:\n",
    "    - Stabilities of time series segments (list of floats)\n",
    "    \"\"\"\n",
    "    stabilities = []\n",
    "\n",
    "    for label_idx in indices_dict[label]:\n",
    "        stabilities.append(np.var([np.mean(x_w) for x_w in np.array_split(segments[label_idx], len(segments[label_idx]) // window_size + 1)]))\n",
    "\n",
    "    return stabilities\n",
    "\n",
    "\n",
    "\n",
    "def compute_hursts(segments, indices_dict, label, lag_size = 30):\n",
    "    \"\"\"\n",
    "    Computes hursts of all segments for a certain label\n",
    "\n",
    "    Parameters:\n",
    "    - segments (list of lists): Complete EEG/EMG segments\n",
    "    - indices_dict (dicts): dictionary which contains all segment indices (values) for each label (key) for either train or test set.\n",
    "    - label (int): Label we want to compute means for. 1, 3, 5 or 7.\n",
    "\n",
    "    Returns:\n",
    "    - Hursts of time series segments (list of floats)\n",
    "    \"\"\"\n",
    "    hursts = []\n",
    "\n",
    "    for label_idx in indices_dict[label]:\n",
    "        # Create the range of lag values\n",
    "        lags = range(2, min(lag_size, len(segments[label_idx]) - 1))\n",
    "        # Calculate the array of the variances of the lagged differences\n",
    "        tau = [np.std(np.asarray(segments[label_idx])[lag:] - np.asarray(segments[label_idx])[:-lag]) for lag in lags]\n",
    "        # Use a linear fit to estimate the Hurst Exponent\n",
    "        poly = np.polyfit(np.log(lags), np.log(tau), 1)\n",
    "        # Return the Hurst exponent from the polyfit output\n",
    "        hursts.append(poly[0] if not np.isnan(poly[0]) else 0)\n",
    "    return hursts\n",
    "\n",
    "\n",
    "\n",
    "def compute_standard_dev_of_first_der(segments, indices_dict, label):\n",
    "    \"\"\"\n",
    "    Computes standard deviation of the first derivative of all segments for a certain label\n",
    "\n",
    "    Parameters:\n",
    "    - segments (list of lists): Complete EEG/EMG segments\n",
    "    - indices_dict (dicts): dictionary which contains all segment indices (values) for each label (key) for either train or test set.\n",
    "    - label (int): Label we want to compute means for. 1, 3, 5 or 7.\n",
    "\n",
    "    Returns:\n",
    "    - standard deviation of the first derivative of time series segments (list of floats)\n",
    "    \"\"\"\n",
    "    stds = []\n",
    "\n",
    "    for label_idx in indices_dict[label]:\n",
    "        stds.append(np.std(np.gradient(segments[label_idx])))\n",
    "\n",
    "    return stds\n",
    "\n",
    "    \n",
    "    \n",
    "def compute_crossing_points(segments, indices_dict, label):\n",
    "    \"\"\"\n",
    "    Computes crossing points of all segments for a certain label.\n",
    "    Crossing points happen when a time series crosses the median line.\n",
    "\n",
    "\n",
    "    Parameters:\n",
    "    - segments (list of lists): Complete EEG/EMG segments\n",
    "    - indices_dict (dicts): dictionary which contains all segment indices (values) for each label (key) for either train or test set.\n",
    "    - label (int): Label we want to compute means for. 1, 3, 5 or 7.\n",
    "\n",
    "    Returns:\n",
    "    - crossing points of time series segments (list of floats)\n",
    "    \"\"\"\n",
    "    \n",
    "    crossing_points = []\n",
    "\n",
    "    for label_idx in indices_dict[label]:\n",
    "        # Calculate the number of crossing points.\n",
    "        median = np.median(segments[label_idx])\n",
    "        cp = 0\n",
    "        for i in range(len(segments[label_idx]) - 1):\n",
    "            if segments[label_idx][i] <= median < segments[label_idx][i + 1] or segments[label_idx][i] >= median > segments[label_idx][i + 1]:\n",
    "                cp += 1\n",
    "        crossing_points.append(cp)\n",
    "        \n",
    "    return crossing_points\n",
    "\n",
    "\n",
    "\n",
    "def compute_binarized_means(segments, indices_dict, label):\n",
    "    \"\"\"\n",
    "    Computes binarized means of all segments for a certain label.\n",
    "    Converts time series array into a binarized version.\n",
    "    Time-series values above its mean are given 1, and those below the mean\n",
    "    are 0. Returns the average value of the binarized vector.\n",
    "\n",
    "\n",
    "    Parameters:\n",
    "    - segments (list of lists): Complete EEG/EMG segments\n",
    "    - indices_dict (dicts): dictionary which contains all segment indices (values) for each label (key) for either train or test set.\n",
    "    - label (int): Label we want to compute means for. 1, 3, 5 or 7.\n",
    "\n",
    "    Returns:\n",
    "    - binarized menas of time series segments (list of floats)\n",
    "    \"\"\"\n",
    "    binarized_means = []\n",
    "\n",
    "    for label_idx in indices_dict[label]:\n",
    "        binarized_means.append(np.mean(np.asarray(segments[label_idx]) > np.mean(segments[label_idx])))\n",
    "\n",
    "    return binarized_means\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dc9f033c-e2e1-4771-b48e-c4c062f3cc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data features for label 1\n",
    "\n",
    "train_feature_df_label_1 = pd.DataFrame()\n",
    "\n",
    "train_feature_df_label_1[\"Mean\"] = compute_means(eeg_segments, train_indices_dict, 1)\n",
    "train_feature_df_label_1[\"Variance\"] = compute_variance(eeg_segments, train_indices_dict, 1)\n",
    "train_feature_df_label_1[\"Entropy\"] = compute_entropy(eeg_segments, train_indices_dict, 1)\n",
    "train_feature_df_label_1[\"Lumpiness\"] = compute_lumpiness(eeg_segments, train_indices_dict, 1)\n",
    "train_feature_df_label_1[\"Stability\"] = compute_stabilities(eeg_segments, train_indices_dict, 1)\n",
    "train_feature_df_label_1[\"Hurst\"] = compute_hursts(eeg_segments, train_indices_dict, 1)\n",
    "train_feature_df_label_1[\"STD_Derivative\"] = compute_standard_dev_of_first_der(eeg_segments, train_indices_dict, 1)\n",
    "train_feature_df_label_1[\"Crossing_Points\"] = compute_crossing_points(eeg_segments, train_indices_dict, 1)\n",
    "train_feature_df_label_1[\"Binarized_Means\"] = compute_binarized_means(eeg_segments, train_indices_dict, 1)\n",
    "\n",
    "train_feature_df_label_1[\"Label\"] = 1\n",
    "\n",
    "\n",
    "# Train data features for label 1\n",
    "test_feature_df_label_1 = pd.DataFrame()\n",
    "\n",
    "test_feature_df_label_1[\"Mean\"] = compute_means(eeg_segments, test_indices_dict, 1)\n",
    "test_feature_df_label_1[\"Variance\"] = compute_variance(eeg_segments, test_indices_dict, 1)\n",
    "test_feature_df_label_1[\"Entropy\"] = compute_entropy(eeg_segments, test_indices_dict, 1)\n",
    "test_feature_df_label_1[\"Lumpiness\"] = compute_lumpiness(eeg_segments, test_indices_dict, 1)\n",
    "test_feature_df_label_1[\"Stability\"] = compute_stabilities(eeg_segments, test_indices_dict, 1)\n",
    "test_feature_df_label_1[\"Hurst\"] = compute_hursts(eeg_segments, test_indices_dict, 1)\n",
    "test_feature_df_label_1[\"STD_Derivative\"] = compute_standard_dev_of_first_der(eeg_segments, test_indices_dict, 1)\n",
    "test_feature_df_label_1[\"Crossing_Points\"] = compute_crossing_points(eeg_segments, test_indices_dict, 1)\n",
    "test_feature_df_label_1[\"Binarized_Means\"] = compute_binarized_means(eeg_segments, test_indices_dict, 1)\n",
    "\n",
    "test_feature_df_label_1[\"Label\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7b114c08-ca86-4460-8d0c-3ac98f4b5658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data features for label 3\n",
    "\n",
    "train_feature_df_label_3 = pd.DataFrame()\n",
    "\n",
    "train_feature_df_label_3[\"Mean\"] = compute_means(eeg_segments, train_indices_dict, 3)\n",
    "train_feature_df_label_3[\"Variance\"] = compute_variance(eeg_segments, train_indices_dict, 3)\n",
    "train_feature_df_label_3[\"Entropy\"] = compute_entropy(eeg_segments, train_indices_dict, 3)\n",
    "train_feature_df_label_3[\"Lumpiness\"] = compute_lumpiness(eeg_segments, train_indices_dict, 3)\n",
    "train_feature_df_label_3[\"Stability\"] = compute_stabilities(eeg_segments, train_indices_dict, 3)\n",
    "train_feature_df_label_3[\"Hurst\"] = compute_hursts(eeg_segments, train_indices_dict, 3)\n",
    "train_feature_df_label_3[\"STD_Derivative\"] = compute_standard_dev_of_first_der(eeg_segments, train_indices_dict, 3)\n",
    "train_feature_df_label_3[\"Crossing_Points\"] = compute_crossing_points(eeg_segments, train_indices_dict, 3)\n",
    "train_feature_df_label_3[\"Binarized_Means\"] = compute_binarized_means(eeg_segments, train_indices_dict, 3)\n",
    "\n",
    "train_feature_df_label_3[\"Label\"] = 3\n",
    "\n",
    "\n",
    "# Train data features for label 3\n",
    "test_feature_df_label_3 = pd.DataFrame()\n",
    "\n",
    "test_feature_df_label_3[\"Mean\"] = compute_means(eeg_segments, test_indices_dict, 3)\n",
    "test_feature_df_label_3[\"Variance\"] = compute_variance(eeg_segments, test_indices_dict, 3)\n",
    "test_feature_df_label_3[\"Entropy\"] = compute_entropy(eeg_segments, test_indices_dict, 3)\n",
    "test_feature_df_label_3[\"Lumpiness\"] = compute_lumpiness(eeg_segments, test_indices_dict, 3)\n",
    "test_feature_df_label_3[\"Stability\"] = compute_stabilities(eeg_segments, test_indices_dict, 3)\n",
    "test_feature_df_label_3[\"Hurst\"] = compute_hursts(eeg_segments, test_indices_dict, 3)\n",
    "test_feature_df_label_3[\"STD_Derivative\"] = compute_standard_dev_of_first_der(eeg_segments, test_indices_dict, 3)\n",
    "test_feature_df_label_3[\"Crossing_Points\"] = compute_crossing_points(eeg_segments, test_indices_dict, 3)\n",
    "test_feature_df_label_3[\"Binarized_Means\"] = compute_binarized_means(eeg_segments, test_indices_dict, 3)\n",
    "\n",
    "test_feature_df_label_3[\"Label\"] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5589a2eb-2627-4934-be66-1a060bce98a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data features for label 5\n",
    "\n",
    "train_feature_df_label_5 = pd.DataFrame()\n",
    "\n",
    "train_feature_df_label_5[\"Mean\"] = compute_means(eeg_segments, train_indices_dict, 5)\n",
    "train_feature_df_label_5[\"Variance\"] = compute_variance(eeg_segments, train_indices_dict, 5)\n",
    "train_feature_df_label_5[\"Entropy\"] = compute_entropy(eeg_segments, train_indices_dict, 5)\n",
    "train_feature_df_label_5[\"Lumpiness\"] = compute_lumpiness(eeg_segments, train_indices_dict, 5)\n",
    "train_feature_df_label_5[\"Stability\"] = compute_stabilities(eeg_segments, train_indices_dict, 5)\n",
    "train_feature_df_label_5[\"Hurst\"] = compute_hursts(eeg_segments, train_indices_dict, 5)\n",
    "train_feature_df_label_5[\"STD_Derivative\"] = compute_standard_dev_of_first_der(eeg_segments, train_indices_dict, 5)\n",
    "train_feature_df_label_5[\"Crossing_Points\"] = compute_crossing_points(eeg_segments, train_indices_dict, 5)\n",
    "train_feature_df_label_5[\"Binarized_Means\"] = compute_binarized_means(eeg_segments, train_indices_dict, 5)\n",
    "\n",
    "train_feature_df_label_5[\"Label\"] = 5\n",
    "\n",
    "\n",
    "# Train data features for label 5\n",
    "test_feature_df_label_5 = pd.DataFrame()\n",
    "\n",
    "test_feature_df_label_5[\"Mean\"] = compute_means(eeg_segments, test_indices_dict, 5)\n",
    "test_feature_df_label_5[\"Variance\"] = compute_variance(eeg_segments, test_indices_dict, 5)\n",
    "test_feature_df_label_5[\"Entropy\"] = compute_entropy(eeg_segments, test_indices_dict, 5)\n",
    "test_feature_df_label_5[\"Lumpiness\"] = compute_lumpiness(eeg_segments, test_indices_dict, 5)\n",
    "test_feature_df_label_5[\"Stability\"] = compute_stabilities(eeg_segments, test_indices_dict, 5)\n",
    "test_feature_df_label_5[\"Hurst\"] = compute_hursts(eeg_segments, test_indices_dict, 5)\n",
    "test_feature_df_label_5[\"STD_Derivative\"] = compute_standard_dev_of_first_der(eeg_segments, test_indices_dict, 5)\n",
    "test_feature_df_label_5[\"Crossing_Points\"] = compute_crossing_points(eeg_segments, test_indices_dict, 5)\n",
    "test_feature_df_label_5[\"Binarized_Means\"] = compute_binarized_means(eeg_segments, test_indices_dict, 5)\n",
    "\n",
    "test_feature_df_label_5[\"Label\"] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "88d889e3-3a26-43c5-a93f-ed6ae7199a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data features for label 7\n",
    "\n",
    "train_feature_df_label_7 = pd.DataFrame()\n",
    "\n",
    "train_feature_df_label_7[\"Mean\"] = compute_means(eeg_segments, train_indices_dict, 7)\n",
    "train_feature_df_label_7[\"Variance\"] = compute_variance(eeg_segments, train_indices_dict, 7)\n",
    "train_feature_df_label_7[\"Entropy\"] = compute_entropy(eeg_segments, train_indices_dict, 7)\n",
    "train_feature_df_label_7[\"Lumpiness\"] = compute_lumpiness(eeg_segments, train_indices_dict, 7)\n",
    "train_feature_df_label_7[\"Stability\"] = compute_stabilities(eeg_segments, train_indices_dict, 7)\n",
    "train_feature_df_label_7[\"Hurst\"] = compute_hursts(eeg_segments, train_indices_dict, 7)\n",
    "train_feature_df_label_7[\"STD_Derivative\"] = compute_standard_dev_of_first_der(eeg_segments, train_indices_dict, 7)\n",
    "train_feature_df_label_7[\"Crossing_Points\"] = compute_crossing_points(eeg_segments, train_indices_dict, 7)\n",
    "train_feature_df_label_7[\"Binarized_Means\"] = compute_binarized_means(eeg_segments, train_indices_dict, 7)\n",
    "\n",
    "train_feature_df_label_7[\"Label\"] = 7\n",
    "\n",
    "\n",
    "# Train data features for label 7\n",
    "test_feature_df_label_7 = pd.DataFrame()\n",
    "\n",
    "test_feature_df_label_7[\"Mean\"] = compute_means(eeg_segments, test_indices_dict, 7)\n",
    "test_feature_df_label_7[\"Variance\"] = compute_variance(eeg_segments, test_indices_dict, 7)\n",
    "test_feature_df_label_7[\"Entropy\"] = compute_entropy(eeg_segments, test_indices_dict, 7)\n",
    "test_feature_df_label_7[\"Lumpiness\"] = compute_lumpiness(eeg_segments, test_indices_dict, 7)\n",
    "test_feature_df_label_7[\"Stability\"] = compute_stabilities(eeg_segments, test_indices_dict, 7)\n",
    "test_feature_df_label_7[\"Hurst\"] = compute_hursts(eeg_segments, test_indices_dict, 7)\n",
    "test_feature_df_label_7[\"STD_Derivative\"] = compute_standard_dev_of_first_der(eeg_segments, test_indices_dict, 7)\n",
    "test_feature_df_label_7[\"Crossing_Points\"] = compute_crossing_points(eeg_segments, test_indices_dict, 7)\n",
    "test_feature_df_label_7[\"Binarized_Means\"] = compute_binarized_means(eeg_segments, test_indices_dict, 7)\n",
    "\n",
    "test_feature_df_label_7[\"Label\"] = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "67b2a28e-3a92-4100-954e-89c9b57fb165",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature_df = pd.concat([train_feature_df_label_1, train_feature_df_label_3, train_feature_df_label_5, train_feature_df_label_7])\n",
    "test_feature_df = pd.concat([test_feature_df_label_1, test_feature_df_label_3, test_feature_df_label_5, test_feature_df_label_7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a82d601f-1a86-40eb-b090-4d29b867e93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature_df.to_csv(\"Features/Train_Statistical_Features.csv\")\n",
    "test_feature_df.to_csv(\"Features/Test_Statistical_Features.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257522a3-afef-4af0-b82b-2d74fe873223",
   "metadata": {},
   "source": [
    "This code contains modified functions from the python package kats, which itself is only\n",
    "available for earlier Python versions.\n",
    "\n",
    "MIT License\n",
    "\n",
    "Copyright (c) Facebook, Inc. and its affiliates.\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
