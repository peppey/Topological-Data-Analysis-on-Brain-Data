{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "b4ca714b-5b12-4c04-96c0-4ebc0cc0a790",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyedflib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from statsmodels.tsa import stattools\n",
    "from scipy.signal import periodogram\n",
    "import logging\n",
    "from itertools import groupby\n",
    "import scipy.stats as stats\n",
    "from statsmodels.tsa.stattools import acf, kpss, pacf\n",
    "from statsmodels.stats.diagnostic import het_arch\n",
    "from scipy.signal import find_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "ab9309b2-0b0d-4d86-8156-be523d39551a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose if you want to look at EEG or EMG data\n",
    "data_type = \"EEG\"\n",
    "#data_type = \"EMG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "ae01d79f-af79-44e3-9d52-186a9d41152b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose individuum\n",
    "subject = \"m292\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "0a81b9c9-a2e9-46c2-8ae8-4a5f02dd0571",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = [0, 1, 2, 3, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "85fd9907-0ecf-4827-bd57-da10d9c03cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EEG & EMG data\n",
    "data = {}\n",
    "\n",
    "for label in label_list:\n",
    "    data[label] = pd.read_csv(\"Data/\"+str(subject)+\"/run0\"+str(label)+\"/Time_Series_Data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ea3b4c-8747-430b-9966-2e7eaaca0b74",
   "metadata": {},
   "source": [
    "# Segmenting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "4d599237-77e5-4221-9b79-f8a638334fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_data(df, segment_size, step_size = 2):\n",
    "    \"\"\"\n",
    "    Segments time-series data into EEG and EMG segments.\n",
    "\n",
    "    Parameters:\n",
    "    - df (DataFrame): The input dataframe containing the columns \"Time\", \"EEG\" and \"EMG\".\n",
    "    - segment_size (float): The desired size of each segment in seconds.\n",
    "    - step_size (float, optional): The step size of \"Time\" in milliseconds. Default is 2 millisecond.\n",
    "\n",
    "    Returns:\n",
    "    Tuple of two lists:\n",
    "    - List of EEG segments.\n",
    "    - List of EMG segments.\n",
    "    \"\"\"\n",
    "\n",
    "    n_segments = int(df[\"time\"].iloc[-1]) // segment_size\n",
    "    eeg_segments = []\n",
    "    emg_segments = []\n",
    "\n",
    "    for i in range(n_segments):\n",
    "        start_idx = int(i* segment_size*1000/step_size)\n",
    "        end_idx = start_idx + int(segment_size*1000/step_size)\n",
    "        segment = df.iloc[start_idx:end_idx]\n",
    "        eeg_segments.append(list(segment[\"voltage\"]))\n",
    "        emg_segments.append(list(segment[\"emg\"]))\n",
    "\n",
    "    return eeg_segments, emg_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "0518ccd3-0e88-4807-819e-d2ebea2dadb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment the data\n",
    "segment_size = 4  # seconds\n",
    "eeg_segments = {}\n",
    "emg_segments = {}\n",
    "\n",
    "for label in label_list:\n",
    "    eeg_segments[label], emg_segments[label] = segment_data(data[label], segment_size, step_size = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "238a7837-307c-47e3-a24d-d7dc3dfd2297",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_type == \"EEG\":\n",
    "    segments = eeg_segments\n",
    "else:\n",
    "    segments = emg_segments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9bc134-5884-4d66-b869-6ff1544366a1",
   "metadata": {},
   "source": [
    "## Compute Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1ac96b-7618-4223-8fd7-86808be23b36",
   "metadata": {},
   "source": [
    "This computes all features of the categories \"statistics\", \"level_shift_features\" and \"acfpacf_features\" (Autocorrelation) which are contained in the Python module 'kats', as well as skewness and kurtosis. (It does not compute time series length because length stays the same.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "2958da95-219a-4153-b0b3-47372f5b2e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### KATS FEATURES OF CATEGORY \"statistics\" ###\n",
    "\n",
    "def compute_means(segments,  label):\n",
    "    \"\"\"\n",
    "    Computes means of all segments for a certain label\n",
    "\n",
    "    Parameters:\n",
    "    - segments (list of lists): Complete EEG/EMG segments\n",
    "    - indices_dict (dicts): dictionary which contains all segment indices (values) for each label (key) for either train or test set.\n",
    "    - label (int): Label we want to compute means for. 1, 3, 5 or 7.\n",
    "\n",
    "    Returns:\n",
    "    - Means of time series segments (list of floats)\n",
    "    \"\"\"\n",
    "    \n",
    "    means = []\n",
    "\n",
    "    for sgmt in segments:\n",
    "        means.append(statistics.mean(sgmt))\n",
    "\n",
    "    return means\n",
    "\n",
    "\n",
    "def compute_percentiles(segments, label, percentile):\n",
    "    \"\"\"\n",
    "    Computes percentiles of all segments for a certain label\n",
    "\n",
    "    Parameters:\n",
    "    - segments (list of lists): Complete EEG/EMG segments\n",
    "    - indices_dict (dicts): dictionary which contains all segment indices (values) for each label (key) for either train or test set.\n",
    "    - label (int): Label we want to compute percentiles for. 1, 3, 5 or 7.\n",
    "    - percentile (float): Percentile to compute (e.g., 0.25 for 25th percentile)\n",
    "\n",
    "    Returns:\n",
    "    - Percentiles of time series segments (list of floats)\n",
    "    \"\"\"\n",
    "    \n",
    "    percentiles = []\n",
    "\n",
    "    for sgmt in segments:\n",
    "        percentiles.append(np.percentile(sgmt, percentile * 100))\n",
    "\n",
    "    return percentiles\n",
    "\n",
    "\n",
    "def compute_number_of_peaks(segments, label):\n",
    "    \"\"\"\n",
    "    Computes number of peaks of all segments for a certain label\n",
    "\n",
    "    Parameters:\n",
    "    - segments (list of lists): Complete EEG/EMG segments\n",
    "    - indices_dict (dicts): dictionary which contains all segment indices (values) for each label (key) for either train or test set.\n",
    "    - label (int): Label we want to compute number of peaks for. 1, 3, 5 or 7.\n",
    "\n",
    "    Returns:\n",
    "    - Number of peaks of time series segments (list of ints)\n",
    "    \"\"\"\n",
    "    \n",
    "    number_of_peaks = []\n",
    "\n",
    "    for sgmt in segments:\n",
    "        peaks, _ = find_peaks(sgmt)\n",
    "        number_of_peaks.append(len(peaks))\n",
    "\n",
    "    return number_of_peaks\n",
    "\n",
    "\n",
    "def compute_number_of_valleys(segments, label):\n",
    "    \"\"\"\n",
    "    Computes number of valleys of all segments for a certain label\n",
    "\n",
    "    Parameters:\n",
    "    - segments (list of lists): Complete EEG/EMG segments\n",
    "    - indices_dict (dicts): dictionary which contains all segment indices (values) for each label (key) for either train or test set.\n",
    "    - label (int): Label we want to compute number of valleys for. 1, 3, 5 or 7.\n",
    "\n",
    "    Returns:\n",
    "    - Number of valleys of time series segments (list of ints)\n",
    "    \"\"\"\n",
    "    \n",
    "    number_of_valleys = []\n",
    "\n",
    "    for sgmt in segments:\n",
    "        valleys, _ = find_peaks([-x for x in sgmt])\n",
    "        number_of_valleys.append(len(valleys))\n",
    "\n",
    "    return number_of_valleys\n",
    "\n",
    "\n",
    "    \n",
    "def compute_variance(segments,  label):\n",
    "    \"\"\"\n",
    "    Computes variances of all segments for a certain label\n",
    "\n",
    "    Parameters:\n",
    "    - segments (list of lists): Complete EEG/EMG segments\n",
    "    - indices_dict (dicts): dictionary which contains all segment indices (values) for each label (key) for either train or test set.\n",
    "    - label (int): Label we want to compute means for. 1, 3, 5 or 7.\n",
    "\n",
    "    Returns:\n",
    "    - Variances of time series segments (list of floats)\n",
    "    \"\"\"\n",
    "    variances = []\n",
    "\n",
    "    for sgmt in segments:\n",
    "        variances.append(statistics.variance(sgmt))\n",
    "\n",
    "    return variances\n",
    "\n",
    "\n",
    "def compute_entropy(segments,  label, freq = 1):\n",
    "    \"\"\"\n",
    "    Computes entropies of all segments for a certain label\n",
    "\n",
    "    Parameters:\n",
    "    - segments (list of lists): Complete EEG/EMG segments\n",
    "    - indices_dict (dicts): dictionary which contains all segment indices (values) for each label (key) for either train or test set.\n",
    "    - label (int): Label we want to compute means for. 1, 3, 5 or 7.\n",
    "\n",
    "    Returns:\n",
    "    - Entropies of time series segments (list of floats) \n",
    "    \"\"\"\n",
    "    entropies = []\n",
    "\n",
    "    for sgmt in segments:\n",
    "\n",
    "        _, psd = periodogram(sgmt, freq)\n",
    "        psd_norm = psd / np.sum(psd)\n",
    "        entropy = np.nansum(psd_norm * np.log2(psd_norm))\n",
    "        entropies.append(-(entropy / np.log2(psd_norm.size)))\n",
    "\n",
    "    return entropies\n",
    "\n",
    "\n",
    "def compute_lumpiness(segments,  label, window_size = 30):\n",
    "    \"\"\"\n",
    "    Computes lumpiness of all segments for a certain label\n",
    "\n",
    "    Parameters:\n",
    "    - segments (list of lists): Complete EEG/EMG segments\n",
    "    - indices_dict (dicts): dictionary which contains all segment indices (values) for each label (key) for either train or test set.\n",
    "    - label (int): Label we want to compute means for. 1, 3, 5 or 7.\n",
    "\n",
    "    Returns:\n",
    "    - Lumpinesses of time series segments (list of floats)\n",
    "    \"\"\"\n",
    "    lumpinesses = []\n",
    "\n",
    "    for sgmt in segments:\n",
    "        lumpinesses.append(np.var([np.var(x_w) for x_w in np.array_split(sgmt, len(sgmt) // window_size + 1)]))\n",
    "\n",
    "    return lumpinesses\n",
    "\n",
    "\n",
    "def compute_stabilities(segments,  label, window_size = 30):\n",
    "    \"\"\"\n",
    "    Computes stabilities of all segments for a certain label\n",
    "\n",
    "    Parameters:\n",
    "    - segments (list of lists): Complete EEG/EMG segments\n",
    "    - indices_dict (dicts): dictionary which contains all segment indices (values) for each label (key) for either train or test set.\n",
    "    - label (int): Label we want to compute means for. 1, 3, 5 or 7.\n",
    "\n",
    "    Returns:\n",
    "    - Stabilities of time series segments (list of floats)\n",
    "    \"\"\"\n",
    "    stabilities = []\n",
    "\n",
    "    for sgmt in segments:\n",
    "        stabilities.append(np.var([np.mean(x_w) for x_w in np.array_split(sgmt, len(sgmt) // window_size + 1)]))\n",
    "\n",
    "    return stabilities\n",
    "\n",
    "\n",
    "def compute_flat_spots(segments,  label, nbins = 10):\n",
    "    \"\"\"\n",
    "    Getting flat spots: Maximum run-lengths across equally-sized segments of time series\n",
    "\n",
    "    Parameters:\n",
    "    - segments (list of lists): Complete EEG/EMG segments\n",
    "    - label (int): Label we want to compute means for. \n",
    "    - nbins (int): Number of bins to segment time series data into.\n",
    "\n",
    "    Returns:\n",
    "        Maximum run-lengths across segmented time series array.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    if len(x) <= nbins:\n",
    "        msg = (\n",
    "            \"Length of time series is shorter than nbins, unable to \"\n",
    "            \"calculate flat spots feature\"\n",
    "        )\n",
    "        logging.error(msg)\n",
    "        return np.nan\n",
    "\n",
    "    max_run_length = 0\n",
    "    window_size = int(len(x) / nbins)\n",
    "    for i in range(0, len(x), window_size):\n",
    "        run_length = np.max(\n",
    "            [len(list(v)) for k, v in groupby(x[i : i + window_size])]\n",
    "        )\n",
    "        if run_length > max_run_length:\n",
    "            max_run_length = run_length\n",
    "    return max_run_length\n",
    "\n",
    "\n",
    "def compute_hursts(segments,  label, lag_size = 30):\n",
    "    \"\"\"\n",
    "    Computes hursts of all segments for a certain label\n",
    "\n",
    "    Parameters:\n",
    "    - segments (list of lists): Complete EEG/EMG segments\n",
    "    - indices_dict (dicts): dictionary which contains all segment indices (values) for each label (key) for either train or test set.\n",
    "    - label (int): Label we want to compute means for. 1, 3, 5 or 7.\n",
    "\n",
    "    Returns:\n",
    "    - Hursts of time series segments (list of floats)\n",
    "    \"\"\"\n",
    "    hursts = []\n",
    "\n",
    "    for sgmt in segments:\n",
    "        # Create the range of lag values\n",
    "        lags = range(2, min(lag_size, len(sgmt) - 1))\n",
    "        # Calculate the array of the variances of the lagged differences\n",
    "        tau = [np.std(np.asarray(sgmt)[lag:] - np.asarray(sgmt)[:-lag]) for lag in lags]\n",
    "        # Use a linear fit to estimate the Hurst Exponent\n",
    "        poly = np.polyfit(np.log(lags), np.log(tau), 1)\n",
    "        # Return the Hurst exponent from the polyfit output\n",
    "        hursts.append(poly[0] if not np.isnan(poly[0]) else 0)\n",
    "    return hursts\n",
    "\n",
    "\n",
    "\n",
    "def compute_standard_dev_of_first_der(segments,  label):\n",
    "    \"\"\"\n",
    "    Computes standard deviation of the first derivative of all segments for a certain label\n",
    "\n",
    "    Parameters:\n",
    "    - segments (list of lists): Complete EEG/EMG segments\n",
    "    - indices_dict (dicts): dictionary which contains all segment indices (values) for each label (key) for either train or test set.\n",
    "    - label (int): Label we want to compute means for. 1, 3, 5 or 7.\n",
    "\n",
    "    Returns:\n",
    "    - standard deviation of the first derivative of time series segments (list of floats)\n",
    "    \"\"\"\n",
    "    stds = []\n",
    "\n",
    "    for sgmt in segments:\n",
    "        stds.append(np.std(np.gradient(sgmt)))\n",
    "\n",
    "    return stds\n",
    "\n",
    "    \n",
    "    \n",
    "def compute_crossing_points(segments,  label):\n",
    "    \"\"\"\n",
    "    Computes crossing points of all segments for a certain label.\n",
    "    Crossing points happen when a time series crosses the median line.\n",
    "\n",
    "\n",
    "    Parameters:\n",
    "    - segments (list of lists): Complete EEG/EMG segments\n",
    "    - indices_dict (dicts): dictionary which contains all segment indices (values) for each label (key) for either train or test set.\n",
    "    - label (int): Label we want to compute means for. 1, 3, 5 or 7.\n",
    "\n",
    "    Returns:\n",
    "    - crossing points of time series segments (list of floats)\n",
    "    \"\"\"\n",
    "    \n",
    "    crossing_points = []\n",
    "\n",
    "    for sgmt in segments:\n",
    "        # Calculate the number of crossing points.\n",
    "        median = np.median(sgmt)\n",
    "        cp = 0\n",
    "        for i in range(len(sgmt) - 1):\n",
    "            if sgmt[i] <= median < sgmt[i + 1] or sgmt[i] >= median > sgmt[i + 1]:\n",
    "                cp += 1\n",
    "        crossing_points.append(cp)\n",
    "        \n",
    "    return crossing_points\n",
    "\n",
    "\n",
    "\n",
    "def compute_binarized_means(segments,  label):\n",
    "    \"\"\"\n",
    "    Computes binarized means of all segments for a certain label.\n",
    "    Converts time series array into a binarized version.\n",
    "    Time-series values above its mean are given 1, and those below the mean\n",
    "    are 0. Returns the average value of the binarized vector.\n",
    "\n",
    "\n",
    "    Parameters:\n",
    "    - segments (list of lists): Complete EEG/EMG segments\n",
    "    - indices_dict (dicts): dictionary which contains all segment indices (values) for each label (key) for either train or test set.\n",
    "    - label (int): Label we want to compute means for. 1, 3, 5 or 7.\n",
    "\n",
    "    Returns:\n",
    "    - binarized menas of time series segments (list of floats)\n",
    "    \"\"\"\n",
    "    binarized_means = []\n",
    "\n",
    "    for sgmt in segments:\n",
    "        binarized_means.append(np.mean(np.asarray(sgmt) > np.mean(sgmt)))\n",
    "\n",
    "    return binarized_means\n",
    "\n",
    "\n",
    "def compute_unitroot_kpss(segments,  label):\n",
    "    \"\"\"\n",
    "    Get the test statistic based on KPSS test.\n",
    "\n",
    "    Test a null hypothesis that an observable time series is stationary\n",
    "    around a deterministic trend. A vector comprising the statistic for the\n",
    "    KPSS unit root test with linear trend and lag one\n",
    "    Wiki: https://en.wikipedia.org/wiki/KPSS_test\n",
    "\n",
    "    Parameters:\n",
    "    - segments (list of lists): Complete EEG/EMG segments\n",
    "    - label (int): Label we want to compute means for. 1, 3, 5 or 7.\n",
    "\n",
    "    Returns:\n",
    "        Test statistics acquired using KPSS test.\n",
    "    \"\"\"\n",
    "\n",
    "    test_statistics = []\n",
    "\n",
    "    for sgmt in segments:\n",
    "        test_statistics.append(kpss(sgmt, regression=\"ct\", nlags=1)[0])\n",
    "\n",
    "    return test_statistics\n",
    "\n",
    "\n",
    "def compute_heterogenity(segments,  label):\n",
    "    \"\"\"\n",
    "    Compute Engle's test for autogregressive Conditional Heteroscedasticity (ARCH).\n",
    "\n",
    "    reference: https://www.statsmodels.org/dev/generated/statsmodels.stats.diagnostic.het_arch.html\n",
    "    Engle’s Test for Autoregressive Conditional Heteroscedasticity (ARCH)\n",
    "\n",
    "    Parameters:\n",
    "    - segments (list of lists): Complete EEG/EMG segments\n",
    "    - label (int): Label we want to compute means for. 1, 3, 5 or 7.\n",
    "\n",
    "    Returns:\n",
    "            Lagrange multiplier test statistic\n",
    "    \"\"\"\n",
    "\n",
    "    test_statistics = []\n",
    "\n",
    "    for sgmt in segments:\n",
    "        test_statistics.append(het_arch(np.array(sgmt), nlags=min(10, len(sgmt) // 5))[0])\n",
    "\n",
    "    return test_statistics\n",
    "\n",
    "def compute_histogram_mode(segments,  label, nbins = 10):\n",
    "    \"\"\"\n",
    "    Measures the mode of the data vector using histograms with a given number of bins.\n",
    "    Reference: https://cran.r-project.org/web/packages/tsfeatures/vignettes/tsfeatures.html\n",
    "\n",
    "    Parameters:\n",
    "    - segments (list of lists): Complete EEG/EMG segments\n",
    "    - label (int): Label we want to compute means for. 1, 3, 5 or 7.\n",
    "    - nbins: int; Number of bins to get the histograms. Default value is 10.\n",
    "\n",
    "    Returns:\n",
    "        Mode of the data vector using histograms.\n",
    "    \"\"\"\n",
    "\n",
    "    modes = []\n",
    "\n",
    "    for sgmt in segments:\n",
    "        cnt, val = np.histogram(sgmt, bins=nbins)\n",
    "        modes.append(val[cnt.argmax()])\n",
    "\n",
    "    return modes\n",
    "\n",
    "    \n",
    "def compute_linearity(segments,  label):\n",
    "    \"\"\"\n",
    "    Compute linearity feature: R square from a fitted linear regression.\n",
    "\n",
    "    Args:\n",
    "        x: The univariate time series array in the form of 1d numpy array.\n",
    "\n",
    "    Returns:\n",
    "        R square from a fitted linear regression.\n",
    "    \"\"\"\n",
    "\n",
    "    R_squares = []\n",
    "\n",
    "    for sgmt in segments:\n",
    "        _, _, r_value, _, _ = stats.linregress(np.arange(len(sgmt)), sgmt)\n",
    "\n",
    "        R_squares.append(r_value**2)\n",
    "\n",
    "    return R_squares\n",
    "\n",
    "\n",
    "### KATS FEATURES OF CATEGORY \"level_shift_features\" ###\n",
    "\n",
    "def compute_level_shift_idx(segments, label, window_size = 20):\n",
    "    \"\"\"\n",
    "    Calculates level_shift_idx: Location of the maximum mean value difference,\n",
    "    between two consecutive sliding windows\n",
    "\n",
    "\n",
    "    Parameters:\n",
    "    - segments (list of lists): Complete EEG/EMG segments\n",
    "    - label (int): Label we want to compute medians for.\n",
    "    - window_size (int) Length of the sliding window.\n",
    "\n",
    "    Returns:\n",
    "    List of Level Shift indices\n",
    "    \"\"\"\n",
    "\n",
    "    level_shift_indices = []\n",
    "\n",
    "    for sgmt in segments:\n",
    "        if len(sgmt) < window_size:\n",
    "            raise ValueError(\"Segment length must be greater than or equal to the window size\")\n",
    "        \n",
    "        # Convert segment to NumPy array\n",
    "        sgmt_array = np.array(sgmt)\n",
    "        \n",
    "        # Create a sliding window view\n",
    "        sliding_windows = np.lib.stride_tricks.sliding_window_view(sgmt_array, window_size)\n",
    "        \n",
    "        # Compute the means over the sliding windows\n",
    "        means = np.mean(sliding_windows, axis=1)\n",
    "        \n",
    "        # Compute the absolute differences between consecutive means\n",
    "        mean_diff = np.abs(means[:-1] - means[1:])\n",
    "        \n",
    "        # Find the index of the maximum level shift\n",
    "        level_shift_idx = np.argmax(mean_diff)\n",
    "        \n",
    "        level_shift_indices.append(level_shift_idx)\n",
    "\n",
    "    return level_shift_indices\n",
    "\n",
    "\n",
    "def compute_level_shift_size(segments, label, window_size = 20):\n",
    "    \"\"\"\n",
    "    \n",
    "    Calculate level_shift_size: Size of the maximum mean value difference,\n",
    "    between two consecutive sliding windows\n",
    "\n",
    "\n",
    "    Parameters:\n",
    "    - segments (list of lists): Complete EEG/EMG segments\n",
    "    - label (int): Label we want to compute medians for.\n",
    "    - window_size (int) Length of the sliding window.\n",
    "\n",
    "    Returns:\n",
    "    List of Level Shift sizes\n",
    "    \"\"\"\n",
    "\n",
    "    level_shift_sizes = []\n",
    "\n",
    "    for sgmt in segments:\n",
    "        if len(sgmt) < window_size:\n",
    "            raise ValueError(\"Segment length must be greater than or equal to the window size\")\n",
    "        \n",
    "        # Convert segment to NumPy array\n",
    "        sgmt_array = np.array(sgmt)\n",
    "        \n",
    "        # Create a sliding window view\n",
    "        sliding_windows = np.lib.stride_tricks.sliding_window_view(sgmt_array, window_size)\n",
    "        \n",
    "        # Compute the means over the sliding windows\n",
    "        means = np.mean(sliding_windows, axis=1)\n",
    "        \n",
    "        # Compute the absolute differences between consecutive means\n",
    "        mean_diff = np.abs(means[:-1] - means[1:])\n",
    "        \n",
    "        # Find the index of the maximum level shift\n",
    "        level_shift_sz = mean_diff[np.argmax(mean_diff)]\n",
    "        \n",
    "        level_shift_sizes.append(level_shift_sz)\n",
    "\n",
    "    return level_shift_sizes\n",
    "\n",
    "\n",
    "### KATS FEATURES OF CATEGORY \"acfpacf_features\" AND \"special_ac\" ###\n",
    "### Autocorrelation Function (ACF) and Partial Autocorrelation Function (PACF) features ###\n",
    "\n",
    "\n",
    "def log_helper(x, period = 7):\n",
    "\n",
    "    if len(x) < 10 or len(x) < period or len(np.unique(x)) == 1:\n",
    "        msg = (\n",
    "            \"Length is shorter than period, or constant time series, \"\n",
    "            \"unable to calculate acf/pacf features\"\n",
    "        )\n",
    "        logging.error(msg)\n",
    "    pass\n",
    "\n",
    "\n",
    "def compute_y_acf1(segments, label, acfpacf_lag = 6, period = 7, default_status = True):\n",
    "    \"\"\"\n",
    "\n",
    "    y_acf1: first ACF value of the original series\n",
    "    \n",
    "    Reference: https://stackoverflow.com/questions/36038927/whats-the-difference-between-pandas-acf-and-statsmodel-acf\n",
    "    R code: https://cran.r-project.org/web/packages/tsfeatures/vignettes/tsfeatures.html\n",
    "    Paper: Meta-learning how to forecast time series\n",
    "\n",
    "\n",
    "    Parameters:\n",
    "    - segments (list of lists): Complete EEG/EMG segments\n",
    "    - label (int): Label we want to compute medians for.\n",
    "    - acfpacf_lag (int) Largest lag number for returning ACF/PACF features\n",
    "                via statsmodels.\n",
    "    - period (int) Seasonal period.\n",
    "    - default_status (Bool): Default status of the switch for calculate the\n",
    "                features or not.\n",
    "\n",
    "\n",
    "    Returns:\n",
    "    List of y_acf1 features\n",
    "    \"\"\"\n",
    "\n",
    "    y_acf1s = []\n",
    "    \n",
    "    for sgmt in segments:\n",
    "        log_helper(sgmt)\n",
    "\n",
    "        nlag = min(acfpacf_lag, len(sgmt) - 2)\n",
    "\n",
    "        y_acf_list = acf(sgmt, fft=True, nlags=period)[1:]\n",
    "        y_acf1s.append(y_acf_list[0])\n",
    "\n",
    "    return y_acf1s\n",
    "\n",
    "\n",
    "def compute_y_acf5(segments, label, acfpacf_lag = 6, period = 7, default_status = True):\n",
    "    \"\"\"\n",
    "\n",
    "    y_acf5: sum of squares of first 5 ACF values of original series\n",
    "    \n",
    "    Reference: https://stackoverflow.com/questions/36038927/whats-the-difference-between-pandas-acf-and-statsmodel-acf\n",
    "    R code: https://cran.r-project.org/web/packages/tsfeatures/vignettes/tsfeatures.html\n",
    "    Paper: Meta-learning how to forecast time series\n",
    "\n",
    "\n",
    "    Parameters:\n",
    "    - segments (list of lists): Complete EEG/EMG segments\n",
    "    - label (int): Label we want to compute medians for.\n",
    "    - acfpacf_lag (int) Largest lag number for returning ACF/PACF features\n",
    "                via statsmodels.\n",
    "    - period (int) Seasonal period.\n",
    "    - default_status (Bool): Default status of the switch for calculate the\n",
    "                features or not.\n",
    "\n",
    "\n",
    "    Returns:\n",
    "    List of y_acf5 features\n",
    "    \"\"\"\n",
    "    y_acf5s = []\n",
    "    \n",
    "    for sgmt in segments:\n",
    "        log_helper(sgmt)\n",
    "\n",
    "        nlag = min(acfpacf_lag, len(sgmt) - 2)\n",
    "        \n",
    "        y_acf_list = acf(sgmt, fft=True, nlags=period)[1:]\n",
    "\n",
    "        y_acf5s.append(np.sum(np.asarray(y_acf_list)[:5] ** 2))\n",
    "\n",
    "    return y_acf5s\n",
    "\n",
    "\n",
    "\n",
    "def compute_diff1y_acf1(segments, label, acfpacf_lag = 6, period = 7, default_status = True):\n",
    "    \"\"\"\n",
    "\n",
    "    diff1y_acf1: first ACF value of the differenced series\n",
    "    \n",
    "    Reference: https://stackoverflow.com/questions/36038927/whats-the-difference-between-pandas-acf-and-statsmodel-acf\n",
    "    R code: https://cran.r-project.org/web/packages/tsfeatures/vignettes/tsfeatures.html\n",
    "    Paper: Meta-learning how to forecast time series\n",
    "\n",
    "\n",
    "    Parameters:\n",
    "    - segments (list of lists): Complete EEG/EMG segments\n",
    "    - label (int): Label we want to compute medians for.\n",
    "    - acfpacf_lag (int) Largest lag number for returning ACF/PACF features\n",
    "                via statsmodels.\n",
    "    - period (int) Seasonal period.\n",
    "    - default_status (Bool): Default status of the switch for calculate the\n",
    "                features or not.\n",
    "\n",
    "\n",
    "    Returns:\n",
    "    List of diff1y_acf1 features\n",
    "    \"\"\"\n",
    "    diff1y_acf1s = []\n",
    "    \n",
    "    for sgmt in segments:\n",
    "        log_helper(sgmt)\n",
    "\n",
    "        nlag = min(acfpacf_lag, len(sgmt) - 2)\n",
    "\n",
    "        diff1x = [sgmt[i] - sgmt[i - 1] for i in range(1, len(sgmt))]\n",
    "\n",
    "        diff1y_acf_list = acf(diff1x, fft=True, nlags=nlag)[1:]\n",
    "        diff1y_acf1s.append(diff1y_acf_list[0])\n",
    "\n",
    "    return diff1y_acf1s\n",
    "\n",
    "\n",
    "\n",
    "def compute_diff1y_acf5(segments, label, acfpacf_lag = 6, period = 7, default_status = True):\n",
    "    \"\"\"\n",
    "    \n",
    "    diff1y_acf5: sum of squares of first 5 ACF values of differenced series\n",
    "    \n",
    "    Reference: https://stackoverflow.com/questions/36038927/whats-the-difference-between-pandas-acf-and-statsmodel-acf\n",
    "    R code: https://cran.r-project.org/web/packages/tsfeatures/vignettes/tsfeatures.html\n",
    "    Paper: Meta-learning how to forecast time series\n",
    "\n",
    "\n",
    "    Parameters:\n",
    "    - segments (list of lists): Complete EEG/EMG segments\n",
    "    - label (int): Label we want to compute medians for.\n",
    "    - acfpacf_lag (int) Largest lag number for returning ACF/PACF features\n",
    "                via statsmodels.\n",
    "    - period (int) Seasonal period.\n",
    "    - default_status (Bool): Default status of the switch for calculate the\n",
    "                features or not.\n",
    "\n",
    "\n",
    "    Returns:\n",
    "    List of diff1y_acf5 features\n",
    "    \"\"\"\n",
    "    diff1y_acf5s = []\n",
    "    \n",
    "    for sgmt in segments:\n",
    "        log_helper(sgmt)\n",
    "\n",
    "        nlag = min(acfpacf_lag, len(sgmt) - 2)\n",
    "\n",
    "        diff1x = [sgmt[i] - sgmt[i - 1] for i in range(1, len(sgmt))]\n",
    "\n",
    "        diff1y_acf_list = acf(diff1x, fft=True, nlags=nlag)[1:]\n",
    "        diff1y_acf5s.append(np.sum(np.asarray(diff1y_acf_list)[:5] ** 2))\n",
    "\n",
    "    return diff1y_acf5s\n",
    "                        \n",
    "\n",
    "\n",
    "\n",
    "def compute_diff2y_acf1(segments, label, acfpacf_lag = 6, period = 7, default_status = True):\n",
    "    \"\"\"\n",
    "    \n",
    "    diff2y_acf1: first ACF value of the twice-differenced series\n",
    "    \n",
    "    Reference: https://stackoverflow.com/questions/36038927/whats-the-difference-between-pandas-acf-and-statsmodel-acf\n",
    "    R code: https://cran.r-project.org/web/packages/tsfeatures/vignettes/tsfeatures.html\n",
    "    Paper: Meta-learning how to forecast time series\n",
    "\n",
    "\n",
    "    Parameters:\n",
    "    - segments (list of lists): Complete EEG/EMG segments\n",
    "    - label (int): Label we want to compute medians for.\n",
    "    - acfpacf_lag (int) Largest lag number for returning ACF/PACF features\n",
    "                via statsmodels.\n",
    "    - period (int) Seasonal period.\n",
    "    - default_status (Bool): Default status of the switch for calculate the\n",
    "                features or not.\n",
    "\n",
    "\n",
    "    Returns:\n",
    "    List of diff2y_acf1 features\n",
    "    \"\"\"\n",
    "    diff2y_acf1s = []\n",
    "    \n",
    "    for sgmt in segments:\n",
    "        log_helper(sgmt)\n",
    "\n",
    "        nlag = min(acfpacf_lag, len(sgmt) - 2)\n",
    "\n",
    "        diff1x = [sgmt[i] - sgmt[i - 1] for i in range(1, len(sgmt))]\n",
    "        diff2x = [diff1x[i] - diff1x[i - 1] for i in range(1, len(diff1x))]\n",
    "\n",
    "        diff2y_acf_list = acf(diff2x, fft=True, nlags=nlag)[1:]\n",
    "        diff2y_acf1s.append(diff2y_acf_list[0])\n",
    "\n",
    "    return diff2y_acf1s\n",
    "\n",
    "\n",
    "\n",
    "def compute_diff2y_acf5(segments, label, acfpacf_lag = 6, period = 7, default_status = True):\n",
    "    \"\"\"\n",
    "\n",
    "    diff2y_acf5: sum of squares of first 5 ACF values of twice-differenced series\n",
    "\n",
    "    \n",
    "    Reference: https://stackoverflow.com/questions/36038927/whats-the-difference-between-pandas-acf-and-statsmodel-acf\n",
    "    R code: https://cran.r-project.org/web/packages/tsfeatures/vignettes/tsfeatures.html\n",
    "    Paper: Meta-learning how to forecast time series\n",
    "\n",
    "\n",
    "    Parameters:\n",
    "    - segments (list of lists): Complete EEG/EMG segments\n",
    "    - label (int): Label we want to compute medians for.\n",
    "    - acfpacf_lag (int) Largest lag number for returning ACF/PACF features\n",
    "                via statsmodels.\n",
    "    - period (int) Seasonal period.\n",
    "    - default_status (Bool): Default status of the switch for calculate the\n",
    "                features or not.\n",
    "\n",
    "\n",
    "    Returns:\n",
    "    List of diff2y_acf5 features\n",
    "    \"\"\"\n",
    "    diff2y_acf5s = []\n",
    "    \n",
    "    for sgmt in segments:\n",
    "        log_helper(sgmt)\n",
    "\n",
    "        nlag = min(acfpacf_lag, len(sgmt) - 2)\n",
    "\n",
    "        diff1x = [sgmt[i] - sgmt[i - 1] for i in range(1, len(sgmt))]\n",
    "        diff2x = [diff1x[i] - diff1x[i - 1] for i in range(1, len(diff1x))]\n",
    "\n",
    "        diff2y_acf_list = acf(diff2x, fft=True, nlags=nlag)[1:]\n",
    "\n",
    "        diff2y_acf5s.append(np.sum(np.asarray(diff2y_acf_list)[:5] ** 2))\n",
    "\n",
    "    return diff2y_acf5s\n",
    "\n",
    "\n",
    "\n",
    "def compute_y_pacf5(segments, label, acfpacf_lag = 6, period = 7, default_status = True):\n",
    "    \"\"\"\n",
    "\n",
    "    y_pacf5: sum of squares of first 5 PACF values of original series\n",
    "    \n",
    "    Reference: https://stackoverflow.com/questions/36038927/whats-the-difference-between-pandas-acf-and-statsmodel-acf\n",
    "    R code: https://cran.r-project.org/web/packages/tsfeatures/vignettes/tsfeatures.html\n",
    "    Paper: Meta-learning how to forecast time series\n",
    "\n",
    "\n",
    "    Parameters:\n",
    "    - segments (list of lists): Complete EEG/EMG segments\n",
    "    - label (int): Label we want to compute medians for.\n",
    "    - acfpacf_lag (int) Largest lag number for returning ACF/PACF features\n",
    "                via statsmodels.\n",
    "    - period (int) Seasonal period.\n",
    "    - default_status (Bool): Default status of the switch for calculate the\n",
    "                features or not.\n",
    "\n",
    "\n",
    "    Returns:\n",
    "    List of y_pacf5 features\n",
    "    \"\"\"\n",
    "    y_pacf5s = []\n",
    "    \n",
    "    for sgmt in segments:\n",
    "        log_helper(sgmt)\n",
    "\n",
    "        nlag = min(acfpacf_lag, len(sgmt) - 2)\n",
    "\n",
    "        y_pacf_list = pacf(sgmt, nlags=period)[1:]\n",
    "\n",
    "        y_pacf5s.append(np.nansum(np.asarray(y_pacf_list)[:5] ** 2))\n",
    "\n",
    "    return y_pacf5s\n",
    "\n",
    "\n",
    "\n",
    "def compute_diff1y_pacf5(segments, label, acfpacf_lag = 6, period = 7, default_status = True):\n",
    "    \"\"\"\n",
    "\n",
    "    diff1y_pacf5: sum of squares of first 5 PACF values of differenced series\n",
    "    \n",
    "    Reference: https://stackoverflow.com/questions/36038927/whats-the-difference-between-pandas-acf-and-statsmodel-acf\n",
    "    R code: https://cran.r-project.org/web/packages/tsfeatures/vignettes/tsfeatures.html\n",
    "    Paper: Meta-learning how to forecast time series\n",
    "\n",
    "\n",
    "    Parameters:\n",
    "    - segments (list of lists): Complete EEG/EMG segments\n",
    "    - label (int): Label we want to compute medians for.\n",
    "    - acfpacf_lag (int) Largest lag number for returning ACF/PACF features\n",
    "                via statsmodels.\n",
    "    - period (int) Seasonal period.\n",
    "    - default_status (Bool): Default status of the switch for calculate the\n",
    "                features or not.\n",
    "\n",
    "\n",
    "    Returns:\n",
    "    List of diff1y_pacf5 features\n",
    "    \"\"\"\n",
    "    diff1y_pacf5s = []\n",
    "    for sgmt in segments:\n",
    "        log_helper(sgmt)\n",
    "\n",
    "        nlag = min(acfpacf_lag, len(sgmt) - 2)\n",
    "\n",
    "        diff1x = [sgmt[i] - sgmt[i - 1] for i in range(1, len(sgmt))]\n",
    "        \n",
    "        diff1y_pacf_list = pacf(diff1x, nlags=nlag)[1:]\n",
    "        diff1y_pacf5s.append(np.nansum(np.asarray(diff1y_pacf_list)[:5] ** 2))\n",
    "\n",
    "    return diff1y_pacf5s\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compute_diff2y_pacf5(segments, label, acfpacf_lag = 6, period = 7, default_status = True):\n",
    "    \"\"\"\n",
    "\n",
    "    diff2y_pacf5: sum of squares of first 5 PACF values of twice-differenced series\n",
    "    \n",
    "    Reference: https://stackoverflow.com/questions/36038927/whats-the-difference-between-pandas-acf-and-statsmodel-acf\n",
    "    R code: https://cran.r-project.org/web/packages/tsfeatures/vignettes/tsfeatures.html\n",
    "    Paper: Meta-learning how to forecast time series\n",
    "\n",
    "\n",
    "    Parameters:\n",
    "    - segments (list of lists): Complete EEG/EMG segments\n",
    "    - label (int): Label we want to compute medians for.\n",
    "    - acfpacf_lag (int) Largest lag number for returning ACF/PACF features\n",
    "                via statsmodels.\n",
    "    - period (int) Seasonal period.\n",
    "    - default_status (Bool): Default status of the switch for calculate the\n",
    "                features or not.\n",
    "\n",
    "\n",
    "    Returns:\n",
    "    List of diff2y_pacf5 features\n",
    "    \"\"\"\n",
    "    diff2y_pacf5s = []\n",
    "    \n",
    "    for sgmt in segments:\n",
    "        log_helper(sgmt)\n",
    "\n",
    "        nlag = min(acfpacf_lag, len(sgmt) - 2)\n",
    "\n",
    "        diff1x = [sgmt[i] - sgmt[i - 1] for i in range(1, len(sgmt))]\n",
    "        diff2x = [diff1x[i] - diff1x[i - 1] for i in range(1, len(diff1x))]\n",
    "\n",
    "        diff2y_pacf_list = pacf(diff2x, nlags=nlag)[1:]\n",
    "        diff2y_pacf5s.append(np.nansum(np.asarray(diff2y_pacf_list)[:5] ** 2))\n",
    "\n",
    "    return diff2y_pacf5s\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compute_seas_acf1(segments, label, acfpacf_lag = 6, period = 7, default_status = True):\n",
    "    \"\"\"\n",
    "\n",
    "    Autocorrelation coefficient at the first seasonal lag\n",
    "    \n",
    "    Reference: https://stackoverflow.com/questions/36038927/whats-the-difference-between-pandas-acf-and-statsmodel-acf\n",
    "    R code: https://cran.r-project.org/web/packages/tsfeatures/vignettes/tsfeatures.html\n",
    "    Paper: Meta-learning how to forecast time series\n",
    "\n",
    "\n",
    "    Parameters:\n",
    "    - segments (list of lists): Complete EEG/EMG segments\n",
    "    - label (int): Label we want to compute medians for.\n",
    "    - acfpacf_lag (int) Largest lag number for returning ACF/PACF features\n",
    "                via statsmodels.\n",
    "    - period (int) Seasonal period.\n",
    "    - default_status (Bool): Default status of the switch for calculate the\n",
    "                features or not.\n",
    "\n",
    "\n",
    "    Returns:\n",
    "    List of seas_acf1 features\n",
    "    \"\"\"\n",
    "    seas_acf1s = []\n",
    "    \n",
    "    for sgmt in segments:\n",
    "        log_helper(sgmt)\n",
    "\n",
    "        y_acf_list = acf(sgmt, fft=True, nlags=period)[1:]\n",
    "\n",
    "        seas_acf1s.append(y_acf_list[-1])\n",
    "\n",
    "    return seas_acf1s\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compute_seas_pacf1(segments, label, acfpacf_lag = 6, period = 7, default_status = True):\n",
    "    \"\"\"\n",
    "    Patial Autocorrelation coefficient at the first seasonal lag\n",
    "    \n",
    "    Reference: https://stackoverflow.com/questions/36038927/whats-the-difference-between-pandas-acf-and-statsmodel-acf\n",
    "    R code: https://cran.r-project.org/web/packages/tsfeatures/vignettes/tsfeatures.html\n",
    "    Paper: Meta-learning how to forecast time series\n",
    "\n",
    "\n",
    "    Parameters:\n",
    "    - segments (list of lists): Complete EEG/EMG segments\n",
    "    - label (int): Label we want to compute medians for.\n",
    "    - acfpacf_lag (int) Largest lag number for returning ACF/PACF features\n",
    "                via statsmodels.\n",
    "    - period (int) Seasonal period.\n",
    "    - default_status (Bool): Default status of the switch for calculate the\n",
    "                features or not.\n",
    "\n",
    "\n",
    "    Returns:\n",
    "    List of seas_pacf1 features\n",
    "    \"\"\"\n",
    "    seas_pacf1s = []\n",
    "\n",
    "    for sgmt in segments:\n",
    "        log_helper(sgmt)\n",
    "\n",
    "        y_pacf_list = pacf(sgmt, nlags=period)[1:]\n",
    "\n",
    "        y_pacf_list[-1]\n",
    "        seas_pacf1s.append(y_pacf_list[-1])\n",
    "\n",
    "    return seas_pacf1s\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compute_firstmin_ac(segments, label, default_status = True):\n",
    "    \"\"\"\n",
    "\n",
    "    Computes firstmin_ac: the time of first minimum in the autocorrelation function\n",
    "\n",
    "    \n",
    "    Reference: https://stackoverflow.com/questions/36038927/whats-the-difference-between-pandas-acf-and-statsmodel-acf\n",
    "    R code: https://cran.r-project.org/web/packages/tsfeatures/vignettes/tsfeatures.html\n",
    "    Paper: Meta-learning how to forecast time series\n",
    "\n",
    "\n",
    "    Parameters:\n",
    "    - segments (list of lists): Complete EEG/EMG segments\n",
    "    - label (int): Label we want to compute medians for.\n",
    "    - default_status (Bool): Default status of the switch for calculate the\n",
    "                features or not.\n",
    "\n",
    "\n",
    "    Returns:\n",
    "    List of firstmin_ac features\n",
    "    \"\"\"\n",
    "    \n",
    "    # First min AC\n",
    "    firstmin_ac_list = []\n",
    "    \n",
    "    for sgmt in segments:\n",
    "\n",
    "        AC = acf(sgmt, fft=True, nlags=len(sgmt))[1:]\n",
    "        i = 0\n",
    "        while i < len(AC) - 1:\n",
    "            if AC[i] > AC[i + 1]:\n",
    "                i += 1\n",
    "            else:\n",
    "                break\n",
    "        firstmin_ac = i + 1\n",
    "        firstmin_ac_list.append(firstmin_ac)\n",
    "    return firstmin_ac_list\n",
    "\n",
    "\n",
    "\n",
    "def compute_firstzero_ac(segments, label, default_status = True):\n",
    "    \"\"\"\n",
    "\n",
    "    Computes firstzero_ac: the time of first zero crossing the autocorrelation function.\n",
    "    \n",
    "    Reference: https://stackoverflow.com/questions/36038927/whats-the-difference-between-pandas-acf-and-statsmodel-acf\n",
    "    R code: https://cran.r-project.org/web/packages/tsfeatures/vignettes/tsfeatures.html\n",
    "    Paper: Meta-learning how to forecast time series\n",
    "\n",
    "\n",
    "    Parameters:\n",
    "    - segments (list of lists): Complete EEG/EMG segments\n",
    "    - label (int): Label we want to compute medians for.\n",
    "    - default_status (Bool): Default status of the switch for calculate the\n",
    "                features or not.\n",
    "\n",
    "\n",
    "    Returns:\n",
    "    List of firstzero_ac features\n",
    "    \"\"\"\n",
    "\n",
    "    firstzero_ac_list = []\n",
    "    \n",
    "    for sgmt in segments:\n",
    "\n",
    "        AC = acf(sgmt, fft=True, nlags=len(sgmt))[1:]\n",
    "        j = 0\n",
    "        while j < len(AC) - 1:\n",
    "            if AC[j] > 0 and AC[j + 1] < 0:\n",
    "                break\n",
    "            else:\n",
    "                j += 1\n",
    "        firstzero_ac = j + 2\n",
    "        firstzero_ac_list.append(firstzero_ac)\n",
    "        \n",
    "    return firstzero_ac_list\n",
    "\n",
    "\n",
    "\n",
    "### ADDITIONAL FEATURES NOT CONTAINED IN KATS ###\n",
    "\n",
    "def compute_medians(segments, label):\n",
    "    \"\"\"\n",
    "    Computes medians of all segments for a certain label\n",
    "\n",
    "    Parameters:\n",
    "    - segments (list of lists): Complete EEG/EMG segments\n",
    "    - indices_dict (dicts): dictionary which contains all segment indices (values) for each label (key) for either train or test set.\n",
    "    - label (int): Label we want to compute medians for. 1, 3, 5 or 7.\n",
    "\n",
    "    Returns:\n",
    "    - Medians of time series segments (list of floats)\n",
    "    \"\"\"\n",
    "    \n",
    "    medians = []\n",
    "\n",
    "    for sgmt in segments:\n",
    "        medians.append(statistics.median(sgmt))\n",
    "\n",
    "    return medians\n",
    "\n",
    "    \n",
    "\n",
    "def compute_minimums(segments, label):\n",
    "    \"\"\"\n",
    "    Computes minimums of all segments for a certain label\n",
    "\n",
    "    Parameters:\n",
    "    - segments (list of lists): Complete EEG/EMG segments\n",
    "    - indices_dict (dicts): dictionary which contains all segment indices (values) for each label (key) for either train or test set.\n",
    "    - label (int): Label we want to compute minimums for. 1, 3, 5 or 7.\n",
    "\n",
    "    Returns:\n",
    "    - Minimums of time series segments (list of floats)\n",
    "    \"\"\"\n",
    "    \n",
    "    minimums = []\n",
    "\n",
    "    for sgmt in segments:\n",
    "        minimums.append(min(sgmt))\n",
    "\n",
    "    return minimums\n",
    "\n",
    "\n",
    "def compute_maximums(segments, label):\n",
    "    \"\"\"\n",
    "    Computes maximums of all segments for a certain label\n",
    "\n",
    "    Parameters:\n",
    "    - segments (list of lists): Complete EEG/EMG segments\n",
    "    - indices_dict (dicts): dictionary which contains all segment indices (values) for each label (key) for either train or test set.\n",
    "    - label (int): Label we want to compute maximums for. 1, 3, 5 or 7.\n",
    "\n",
    "    Returns:\n",
    "    - Maximums of time series segments (list of floats)\n",
    "    \"\"\"\n",
    "    \n",
    "    maximums = []\n",
    "\n",
    "    for sgmt in segments:\n",
    "        maximums.append(max(sgmt))\n",
    "\n",
    "    return maximums\n",
    "\n",
    "\n",
    "def compute_ranges(segments, label):\n",
    "    \"\"\"\n",
    "    Computes ranges of all segments for a certain label\n",
    "\n",
    "    Parameters:\n",
    "    - segments (list of lists): Complete EEG/EMG segments\n",
    "    - indices_dict (dicts): dictionary which contains all segment indices (values) for each label (key) for either train or test set.\n",
    "    - label (int): Label we want to compute ranges for. 1, 3, 5 or 7.\n",
    "\n",
    "    Returns:\n",
    "    - Ranges of time series segments (list of floats)\n",
    "    \"\"\"\n",
    "    \n",
    "    ranges = []\n",
    "\n",
    "    for sgmt in segments:\n",
    "        ranges.append(max(sgmt) - min(sgmt))\n",
    "\n",
    "    return ranges\n",
    "\n",
    "\n",
    "def compute_kurtoses(segments, label):\n",
    "    \"\"\"\n",
    "    Computes kurtoses of all segments for a certain label\n",
    "\n",
    "    Parameters:\n",
    "    - segments (list of lists): Complete EEG/EMG segments\n",
    "    - indices_dict (dict): dictionary which contains all segment indices (values) for each label (key) for either train or test set.\n",
    "    - label (int): Label we want to compute kurtoses for. 1, 3, 5 or 7.\n",
    "\n",
    "    Returns:\n",
    "    - Kurtoses of time series segments (list of floats)\n",
    "    \"\"\"\n",
    "    \n",
    "    kurtoses = []\n",
    "\n",
    "    for sgmt in segments:\n",
    "        kurtoses.append(stats.kurtosis(sgmt))\n",
    "\n",
    "    return kurtoses\n",
    "\n",
    "\n",
    "def compute_skewnesses(segments, label):\n",
    "    \"\"\"\n",
    "    Computes skewnesses of all segments for a certain label\n",
    "\n",
    "    Parameters:\n",
    "    - segments (list of lists): Complete EEG/EMG segments\n",
    "    - indices_dict (dict): dictionary which contains all segment indices (values) for each label (key) for either train or test set.\n",
    "    - label (int): Label we want to compute skewnesses for. 1, 3, 5 or 7.\n",
    "\n",
    "    Returns:\n",
    "    - Skewnesses of time series segments (list of floats)\n",
    "    \"\"\"\n",
    "    \n",
    "    skewnesses = []\n",
    "\n",
    "    for sgmt in segments:\n",
    "        skewnesses.append(stats.skew(sgmt))\n",
    "\n",
    "    return skewnesses\n",
    "\n",
    "\n",
    "def compute_longest_strike_above_mean(segments, label):\n",
    "    \"\"\"\n",
    "    Computes the longest strike above the mean for all segments for a certain label.\n",
    "\n",
    "    Parameters:\n",
    "    - segments (list of lists): Complete EEG/EMG segments.\n",
    "    - label (int): Label we want to compute longest strikes for. (not used in this function but included to match signature)\n",
    "\n",
    "    Returns:\n",
    "    - Longest strikes above the mean of time series segments (list of ints)\n",
    "    \"\"\"\n",
    "    \n",
    "    longest_strikes_above_mean = []\n",
    "\n",
    "    for sgmt in segments:\n",
    "        mean_value = statistics.mean(sgmt)\n",
    "        longest_strike = 0\n",
    "        current_strike = 0\n",
    "\n",
    "        for value in sgmt:\n",
    "            if value > mean_value:\n",
    "                current_strike += 1\n",
    "                if current_strike > longest_strike:\n",
    "                    longest_strike = current_strike\n",
    "            else:\n",
    "                current_strike = 0\n",
    "\n",
    "        longest_strikes_above_mean.append(longest_strike)\n",
    "\n",
    "    return longest_strikes_above_mean\n",
    "\n",
    "\n",
    "def compute_longest_strike_below_mean(segments, label):\n",
    "    \"\"\"\n",
    "    Computes the longest strike below the mean for all segments for a certain label.\n",
    "\n",
    "    Parameters:\n",
    "    - segments (list of lists): Complete EEG/EMG segments.\n",
    "    - label (int): Label we want to compute longest strikes for. (not used in this function but included to match signature)\n",
    "\n",
    "    Returns:\n",
    "    - Longest strikes below the mean of time series segments (list of ints)\n",
    "    \"\"\"\n",
    "    \n",
    "    longest_strikes_below_mean = []\n",
    "\n",
    "    for sgmt in segments:\n",
    "        mean_value = statistics.mean(sgmt)\n",
    "        longest_strike = 0\n",
    "        current_strike = 0\n",
    "\n",
    "        for value in sgmt:\n",
    "            if value < mean_value:\n",
    "                current_strike += 1\n",
    "                if current_strike > longest_strike:\n",
    "                    longest_strike = current_strike\n",
    "            else:\n",
    "                current_strike = 0\n",
    "\n",
    "        longest_strikes_below_mean.append(longest_strike)\n",
    "\n",
    "    return longest_strikes_below_mean\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "dc9f033c-e2e1-4771-b48e-c4c062f3cc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_kats_statistics_feature_dataframes(label_list, segments, data_type, subject):\n",
    "    \"\"\"\n",
    "    Create feature dataframes for each label using segment data and concatenate them.\n",
    "    \n",
    "    Args:\n",
    "    - label_list (list): List of labels.\n",
    "    - segments (dict): Dictionary containing segments for each label.\n",
    "    - data_type (str): Type of data.\n",
    "    - subject (str): Subject identifier.\n",
    "    \n",
    "    Returns:\n",
    "    - pd.DataFrame: Concatenated feature dataframe.\n",
    "    \"\"\"\n",
    "    feature_dataframes = {}\n",
    "\n",
    "    for label in label_list:\n",
    "        feature_dataframes[label] = pd.DataFrame()\n",
    "        feature_dataframes[label][str(data_type)+\"_Mean\"] = compute_means(segments[label], label)\n",
    "        feature_dataframes[label][str(data_type)+\"_Variance\"] = compute_variance(segments[label], label)\n",
    "        feature_dataframes[label][str(data_type)+\"_Entropy\"] = compute_entropy(segments[label], label)\n",
    "        feature_dataframes[label][str(data_type)+\"_Lumpiness\"] = compute_lumpiness(segments[label], label)\n",
    "        feature_dataframes[label][str(data_type)+\"_Stability\"] = compute_stabilities(segments[label], label)\n",
    "        feature_dataframes[label][str(data_type)+\"_Hurst\"] = compute_hursts(segments[label], label)\n",
    "        feature_dataframes[label][str(data_type)+\"_STD_Derivative\"] = compute_standard_dev_of_first_der(segments[label], label)\n",
    "        feature_dataframes[label][str(data_type)+\"_Crossing_Points\"] = compute_crossing_points(segments[label], label)\n",
    "        feature_dataframes[label][str(data_type)+\"_Binarized_Means\"] = compute_binarized_means(segments[label], label)\n",
    "        feature_dataframes[label][str(data_type)+\"_Unitroot_KPSS\"] = compute_unitroot_kpss(segments[label], label)\n",
    "        feature_dataframes[label][str(data_type)+\"_Heterogenity\"] = compute_heterogenity(segments[label], label)\n",
    "        feature_dataframes[label][str(data_type)+\"_Histogram_Mode\"] = compute_histogram_mode(segments[label], label)\n",
    "        feature_dataframes[label][str(data_type)+\"_Linearity\"] = compute_linearity(segments[label], label)\n",
    "\n",
    "\n",
    "        feature_dataframes[label][\"Label\"] = label\n",
    "        feature_dataframes[label][\"Subject\"] = subject\n",
    "\n",
    "    # Concatenate dataframes while resetting indices (ignore_index=True)\n",
    "    feature_df = pd.concat([feature_dataframes[0], feature_dataframes[1], feature_dataframes[2],\n",
    "                                  feature_dataframes[3], feature_dataframes[4]], ignore_index=True)\n",
    "    \n",
    "    return feature_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "a82d601f-1a86-40eb-b090-4d29b867e93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_df = create_kats_statistics_feature_dataframes(label_list, segments, data_type, subject)\n",
    "#feature_df.to_csv(\"Features/\"+str(subject)+\"/\"+str(data_type)+\"/Statistical_Features_KATS_Statistics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "c2a18fe8-df6c-41cc-b24f-dafc502c6320",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_level_shift_features_dataframes(label_list, segments, data_type, subject):\n",
    "    \"\"\"\n",
    "    Create feature dataframes for each label using segment data and concatenate them.\n",
    "    \n",
    "    Args:\n",
    "    - label_list (list): List of labels.\n",
    "    - segments (dict): Dictionary containing segments for each label.\n",
    "    - data_type (str): Type of data.\n",
    "    - subject (str): Subject identifier.\n",
    "    \n",
    "    Returns:\n",
    "    - pd.DataFrame: Concatenated feature dataframe.\n",
    "    \"\"\"\n",
    "    feature_dataframes = {}\n",
    "\n",
    "    for label in label_list:\n",
    "        feature_dataframes[label] = pd.DataFrame()\n",
    "        feature_dataframes[label][str(data_type)+\"_Level_Shift_Idx\"] = compute_level_shift_idx(segments[label], label)\n",
    "        feature_dataframes[label][str(data_type)+\"_Level_Shift_Size\"] = compute_level_shift_size(segments[label], label)\n",
    "        \n",
    "        feature_dataframes[label][\"Label\"] = label\n",
    "        feature_dataframes[label][\"Subject\"] = subject\n",
    "\n",
    "    # Concatenate dataframes while resetting indices (ignore_index=True)\n",
    "    feature_df = pd.concat([feature_dataframes[0], feature_dataframes[1], feature_dataframes[2],\n",
    "                                  feature_dataframes[3], feature_dataframes[4]], ignore_index=True)\n",
    "    \n",
    "    return feature_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "535bcb41-8e0e-4e07-916d-c0f94722a685",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_df = create_level_shift_features_dataframes(label_list, segments, data_type, subject)\n",
    "#feature_df.to_csv(\"Features/\"+str(subject)+\"/\"+str(data_type)+\"/Statistical_Features_Level_Shift_Features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "a8d7ed4d-fde3-441c-8012-b21b08652378",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_autocorrelation_features_dataframes(label_list, segments, data_type, subject):\n",
    "    \"\"\"\n",
    "    Create feature dataframes for each label using segment data and concatenate them.\n",
    "    \n",
    "    Args:\n",
    "    - label_list (list): List of labels.\n",
    "    - segments (dict): Dictionary containing segments for each label.\n",
    "    - data_type (str): Type of data.\n",
    "    - subject (str): Subject identifier.\n",
    "    \n",
    "    Returns:\n",
    "    - pd.DataFrame: Concatenated feature dataframe.\n",
    "    \"\"\"\n",
    "    feature_dataframes = {}\n",
    "\n",
    "    for label in label_list:\n",
    "        feature_dataframes[label] = pd.DataFrame()\n",
    "        feature_dataframes[label][str(data_type)+\"_y_acf1\"] = compute_y_acf1(segments[label], label)\n",
    "        feature_dataframes[label][str(data_type)+\"_y_acf5\"] = compute_y_acf5(segments[label], label)\n",
    "        feature_dataframes[label][str(data_type)+\"_diff1y_acf1\"] = compute_diff1y_acf1(segments[label], label)\n",
    "        feature_dataframes[label][str(data_type)+\"_diff1y_acf5\"] = compute_diff1y_acf5(segments[label], label)\n",
    "        feature_dataframes[label][str(data_type)+\"_diff2y_acf1\"] = compute_diff2y_acf1(segments[label], label)\n",
    "        feature_dataframes[label][str(data_type)+\"_diff2y_acf5\"] = compute_diff2y_acf5(segments[label], label)\n",
    "        feature_dataframes[label][str(data_type)+\"_diff1y_pacf5\"] = compute_diff1y_pacf5(segments[label], label)\n",
    "        feature_dataframes[label][str(data_type)+\"_diff2y_pacf5\"] = compute_diff2y_pacf5(segments[label], label)\n",
    "        feature_dataframes[label][str(data_type)+\"_seas_acf1\"] = compute_seas_acf1(segments[label], label)\n",
    "        feature_dataframes[label][str(data_type)+\"_seas_pacf1\"] = compute_seas_pacf1(segments[label], label)\n",
    "        feature_dataframes[label][str(data_type)+\"_firstmin_ac\"] = compute_firstmin_ac(segments[label], label)\n",
    "        feature_dataframes[label][str(data_type)+\"_firstzero_ac\"] = compute_firstzero_ac(segments[label], label)\n",
    "        \n",
    "        feature_dataframes[label][\"Label\"] = label\n",
    "        feature_dataframes[label][\"Subject\"] = subject\n",
    "\n",
    "    # Concatenate dataframes while resetting indices (ignore_index=True)\n",
    "    feature_df = pd.concat([feature_dataframes[0], feature_dataframes[1], feature_dataframes[2],\n",
    "                                  feature_dataframes[3], feature_dataframes[4]], ignore_index=True)\n",
    "    \n",
    "    return feature_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "a1ba692f-c4d8-461f-a7bf-a47b26d1db91",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = create_autocorrelation_features_dataframes(label_list, segments, data_type, subject)\n",
    "feature_df.to_csv(\"Features/\"+str(subject)+\"/\"+str(data_type)+\"/Statistical_Features_Autocorrelation_Features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "3c3133f1-4c29-488b-86fb-94985eb93daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_additional_features_dataframes(label_list, segments, data_type, subject):\n",
    "    \"\"\"\n",
    "    Create feature dataframes for each label using segment data and concatenate them.\n",
    "    \n",
    "    Args:\n",
    "    - label_list (list): List of labels.\n",
    "    - segments (dict): Dictionary containing segments for each label.\n",
    "    - data_type (str): Type of data.\n",
    "    - subject (str): Subject identifier.\n",
    "    \n",
    "    Returns:\n",
    "    - pd.DataFrame: Concatenated feature dataframe.\n",
    "    \"\"\"\n",
    "    feature_dataframes = {}\n",
    "\n",
    "    for label in label_list:\n",
    "        feature_dataframes[label] = pd.DataFrame()\n",
    "        feature_dataframes[label][str(data_type)+\"_Median\"] = compute_medians(segments[label], label)\n",
    "        feature_dataframes[label][str(data_type)+\"_Maximum\"] = compute_maximums(segments[label], label)\n",
    "        feature_dataframes[label][str(data_type)+\"_Minimum\"] = compute_minimums(segments[label], label)\n",
    "        feature_dataframes[label][str(data_type)+\"_Range\"] = compute_ranges(segments[label], label)\n",
    "        feature_dataframes[label][str(data_type)+\"_Longest_Strike_Above_Mean\"] = compute_longest_strike_above_mean(segments[label], label)\n",
    "        feature_dataframes[label][str(data_type)+\"_Longest_Strike_Below_Mean\"] = compute_longest_strike_below_mean(segments[label], label)\n",
    "        \n",
    "        feature_dataframes[label][\"Label\"] = label\n",
    "        feature_dataframes[label][\"Subject\"] = subject\n",
    "\n",
    "    # Concatenate dataframes while resetting indices (ignore_index=True)\n",
    "    feature_df = pd.concat([feature_dataframes[0], feature_dataframes[1], feature_dataframes[2],\n",
    "                                  feature_dataframes[3], feature_dataframes[4]], ignore_index=True)\n",
    "    \n",
    "    return feature_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "0ada86e2-8cd4-4c28-8653-83893742f0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_df = create_kats_statistics_feature_dataframes(label_list, segments, data_type, subject)\n",
    "#feature_df.to_csv(\"Features/\"+str(subject)+\"/\"+str(data_type)+\"/Statistical_Features_Additional_Features.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257522a3-afef-4af0-b82b-2d74fe873223",
   "metadata": {},
   "source": [
    "This code contains modified functions from the python package kats, which itself is only\n",
    "available for earlier Python versions.\n",
    "\n",
    "MIT License\n",
    "\n",
    "Copyright (c) Facebook, Inc. and its affiliates.\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbd7976-0f9d-47f1-9f8a-2fbf5b6bb8eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b75093-3e9c-4475-becb-ace6f50dc73e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
