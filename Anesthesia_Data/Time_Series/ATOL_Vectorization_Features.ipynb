{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "316cdf4f-956c-4550-807c-ec0f392a4676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' This file vectorizes persistence diagrams and their signatures with the ATOL algorithm.'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" This file vectorizes persistence diagrams and their signatures with the ATOL algorithm.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d0019db-93cd-426a-9d0a-35871e57457a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyedflib\n",
    "import statistics\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "from gtda.time_series import SingleTakensEmbedding\n",
    "from gtda.homology import VietorisRipsPersistence\n",
    "from gtda.diagrams import PersistenceEntropy, Amplitude, NumberOfPoints, ComplexPolynomial, PersistenceLandscape, HeatKernel, Silhouette, BettiCurve, PairwiseDistance, ForgetDimension, PersistenceImage\n",
    "from gtda.plotting import plot_point_cloud, plot_heatmap, plot_diagram\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from gtda.pipeline import Pipeline \n",
    "from sklearn.cluster import KMeans\n",
    "from gudhi.representations.vector_methods import Atol\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7ff89c8-c664-46a7-8df6-f5d81b89b9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO change deprecated behaviour"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0a29cb-c9eb-4e73-84ff-9acc01af18d5",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3f188cdf-bc5e-4a6b-8dd1-5f35a10b51be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose if you want to look at EEG or EMG data\n",
    "\n",
    "data_type = \"EEG\"\n",
    "#data_type = \"EMG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ee47cf9f-1400-43e2-8e3c-2599d414fcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose individuum\n",
    "subject = \"m294\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2edc700a-6aa2-496c-bc1c-24cbf396294f",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = [0, 1, 2, 3, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1869db59-4091-4074-8c94-15c64649d445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load persistence diagrams\n",
    "\n",
    "train_persistence_diagrams = {} # dictionary with labels as keys, persistence diagrams of the respective classes as values\n",
    "test_persistence_diagrams = {} # dictionary with labels as keys, persistence diagrams of the respective classes as values\n",
    "\n",
    "\n",
    "for label in label_list:\n",
    "    train_persistence_diagrams[label] = np.load(\"Embeddings_and_Persistence_Diagrams/\"+str(subject)+\"/Train/\"+str(data_type)+\"/PD\"+str(label)+\".npy\", allow_pickle=True)\n",
    "    test_persistence_diagrams[label] = np.load(\"Embeddings_and_Persistence_Diagrams/\"+str(subject)+\"/Test/\"+str(data_type)+\"/PD\"+str(label)+\".npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6f59308d-1bd6-47b6-839a-4aa1f5237a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load shortened persistence diagrams\n",
    "\n",
    "train_shortened_diagrams = {} # dictionary with labels as keys, persistence diagrams of the respective classes as values\n",
    "test_shortened_diagrams = {} # dictionary with labels as keys, persistence diagrams of the respective classes as values\n",
    "\n",
    "\n",
    "for label in label_list:\n",
    "    train_shortened_diagrams[label] = np.load(\"Embeddings_and_Persistence_Diagrams/\"+str(subject)+\"/Train/\"+str(data_type)+\"/Shortened_Diagrams\"+str(label)+\".npy\", allow_pickle=True)\n",
    "    test_shortened_diagrams[label] = np.load(\"Embeddings_and_Persistence_Diagrams/\"+str(subject)+\"/Test/\"+str(data_type)+\"/Shortened_Diagrams\"+str(label)+\".npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "94101e71-a0b3-4d4a-bb1d-883081d11b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load removed indices\n",
    "\n",
    "train_removed_indices = {} # dictionary with labels as keys, indices of the respective classes as values\n",
    "test_removed_indices = {} # dictionary with labels as keys, indices of the respective classes as values\n",
    "\n",
    "\n",
    "for label in label_list:\n",
    "    train_removed_indices[label] = np.load(\"Embeddings_and_Persistence_Diagrams/\"+str(subject)+\"/Train/\"+str(data_type)+\"/Removed_Indices\"+str(label)+\".npy\", allow_pickle=True)\n",
    "    test_removed_indices[label] = np.load(\"Embeddings_and_Persistence_Diagrams/\"+str(subject)+\"/Test/\"+str(data_type)+\"/Removed_Indices\"+str(label)+\".npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79436ddb-23f7-4a2d-a7b8-6dbab1a866e6",
   "metadata": {},
   "source": [
    "# Set parameters and important functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "25d1d151-85ec-48a3-ad2f-e306fe68b327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose dimensionality of the vectorization\n",
    "\n",
    "# Later in the classification, a dimension of 4 works already works approx. optimally at least for persistence diagrams\n",
    "vector_dim = 4  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "37acb6b9-864c-4399-9687-70a71a0ccc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define all data type objects\n",
    "\n",
    "HK = HeatKernel(sigma=0.00003, n_bins=100)\n",
    "BC = BettiCurve()\n",
    "SH = Silhouette()\n",
    "PL = PersistenceLandscape()\n",
    "PI = PersistenceImage(sigma=0.00003, n_bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c2a4aad5-6364-4a84-882b-e2a8bb53f2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO these functions deal with HK and PI as global variables, which is not ideal. \n",
    "\n",
    "def train_atol(training_data, label_list, vector_dim, type_of_data_to_vectorize = None):\n",
    "    \"\"\" Trains the ATOl model with the training data.\n",
    "    \n",
    "    Parameters:\n",
    "    - training_data (dictionary of np.ndarrays of np.ndarrays of np.ndarrays): Data used for training. \n",
    "    Shape (labels, #persistence diagrams/features, shape of persistence diagram/feature).\n",
    "    - label_list (list): List of labels (e.g. [1, 3, 5, 7].\n",
    "    - vector_dim (int): Dimension the vectorizations should have, e.g. 4.\n",
    "    - type_of_data_to_vectorize (object): either \"HK\", \"BC\", \"SH\" or \"PL\", or None if we are directly vectorizing the data_to_vectorize.\n",
    "\n",
    "    Returns\n",
    "    - atol_vectoriser (object): Atol() object; trained model to vectorize the data to vectorize later.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Concatenate all training data\n",
    "    all_training_data = []\n",
    "    \n",
    "    for label in label_list:\n",
    "        if not type_of_data_to_vectorize:\n",
    "            all_training_data.extend(training_data[label])\n",
    "            \n",
    "         # HK & PI have a different shape than the other signatures\n",
    "        elif type_of_data_to_vectorize == HK or type_of_data_to_vectorize == PI:\n",
    "            all_training_data.extend(type_of_data_to_vectorize.fit_transform(training_data[label])[0])\n",
    "        else:\n",
    "            all_training_data.extend(type_of_data_to_vectorize.fit_transform(training_data[label]))\n",
    "            \n",
    "    # Train Atol vectorizer with all training data\n",
    "    atol_vectoriser = Atol(quantiser=KMeans(n_clusters=vector_dim, random_state=202006))\n",
    "    atol_vectoriser.fit(X=all_training_data).centers\n",
    "\n",
    "    return atol_vectoriser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a0d004d7-69bb-460c-96e3-2fcffde77f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vectorizations(data_to_vectorize, atol_vectoriser, label_list, type_of_data_to_vectorize = None):\n",
    "    \"\"\" Creates vectorizations from signatures.\n",
    "    \n",
    "    Parameters:\n",
    "    - data_to_vectorize (dictionary of np.ndarrays of np.ndarrays of np.ndarrays): Data to vectorize. \n",
    "    Shape (labels, #persistence diagrams/features, shape of persistence diagram/feature).\n",
    "    - atol_vectoriser (object): Atol() object; trained model to vectorize the data_to_vectorize.\n",
    "    - label_list (list): List of labels (e.g. [1, 3, 5, 7].\n",
    "    - type_of_data_to_vectorize (object): either \"HK\", \"BC\", \"SH\" or \"PL\", or None if we are directly vectorizing the data_to_vectorize.\n",
    "\n",
    "    Returns\n",
    "    - Vectorization. Shape (Number of homology dimensions, number of labels, data_to_vectorize, length of vectorization)\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    # If we are directly vectorizing persistence diagrams\n",
    "    \n",
    "    if not type_of_data_to_vectorize: \n",
    "        \n",
    "        vectorizations = {} # initialize dictionary with labels as keys and vectorizations as values\n",
    "\n",
    "        for label in label_list:\n",
    "            vectorizations[label] = []\n",
    "            for diagram in data_to_vectorize[label]:\n",
    "                vectorization = atol_vectoriser(diagram)\n",
    "                vectorizations[label].append(vectorization)\n",
    "\n",
    "        return vectorizations\n",
    "\n",
    "\n",
    "    # If we are vectorizing features\n",
    "    \n",
    "    vectorizations = [{}, {}, {}] # initialize list which has an dictionary for each homology dimensions, with labels as keys\n",
    "\n",
    "    for label in label_list:\n",
    "        for dim in range(3):\n",
    "\n",
    "            # Initialize list of vectorizations\n",
    "            vectorizations[dim][label] = []\n",
    "    \n",
    "            for diagram in data_to_vectorize[label]:\n",
    "                # We get a depreciation warning if we do not convert the diagram to a numeric type explicitly\n",
    "                signature = type_of_data_to_vectorize.fit_transform([diagram.astype(\"float\")])\n",
    " \n",
    "                if type_of_data_to_vectorize == HK or type_of_data_to_vectorize == PI:\n",
    "\n",
    "                    vector = atol_vectoriser(signature[0][dim])\n",
    "                    vectorizations[dim][label].append(vector)\n",
    "                else:\n",
    "                    vector = atol_vectoriser(signature[0][dim].reshape(1, -1))\n",
    "                    vectorizations[dim][label].append(vector)\n",
    "\n",
    "    return vectorizations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6c075947-2710-4d49-8fc7-ed1178ee3231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dictionaries with all vectorizations\n",
    "\n",
    "train_all_vectorizations = {}\n",
    "test_all_vectorizations = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3d768c4d-b754-4ef2-9275-da2c0dbe37b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set variable that will make sure that zero embeddings at missing indices will only be inserted once\n",
    "\n",
    "already_inserted = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9849587d-b386-4722-a800-6c3ee4e87499",
   "metadata": {},
   "source": [
    "# Vectorize persistence diagrams directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d7fbadbb-2f9b-4e09-b2b0-803cbb029966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train ATOL\n",
    "atol_vectoriser = train_atol(train_persistence_diagrams, label_list, vector_dim)\n",
    "\n",
    "# Apply trained model to the entire data\n",
    "train_all_vectorizations[\"PD\"] = create_vectorizations(train_persistence_diagrams, atol_vectoriser, label_list)\n",
    "test_all_vectorizations[\"PD\"]  = create_vectorizations(test_persistence_diagrams, atol_vectoriser, label_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb839e93-9f55-45a9-a1ee-f5a29a18d054",
   "metadata": {},
   "source": [
    "# Vectorize Signatures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0491516c-3ecc-4f5e-8748-a2bc88fc4b4d",
   "metadata": {},
   "source": [
    "## Heatkernel vectorizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "484c75b8-d7ec-4373-8db6-14d1bdbee785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train ATOL\n",
    "atol_vectoriser = train_atol(train_shortened_diagrams, label_list, vector_dim, HK)\n",
    "# Create vectorizations\n",
    "train_all_vectorizations[\"HK\"] = create_vectorizations(train_shortened_diagrams, atol_vectoriser, label_list, HK)\n",
    "test_all_vectorizations[\"HK\"] = create_vectorizations(test_shortened_diagrams, atol_vectoriser, label_list, HK)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02150806-42de-468a-9277-4764d0eac6ed",
   "metadata": {},
   "source": [
    "## Betti Curve Vectorizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e0744d0b-a94e-4011-9d8f-40abc3f1fa2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train ATOL\n",
    "atol_vectoriser = train_atol(train_shortened_diagrams, label_list, vector_dim, BC)\n",
    "\n",
    "# Create vectorizations\n",
    "train_all_vectorizations[\"BC\"] = create_vectorizations(train_shortened_diagrams, atol_vectoriser, label_list, BC)\n",
    "test_all_vectorizations[\"BC\"] = create_vectorizations(test_shortened_diagrams, atol_vectoriser, label_list, BC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0515117d-4a5c-4c3b-84b4-50e003b75188",
   "metadata": {},
   "source": [
    "## Vectorize Silhouettes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "23a964e3-1d1e-431e-9fe0-556564991130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train ATOL\n",
    "atol_vectoriser = train_atol(train_shortened_diagrams, label_list, vector_dim, SH)\n",
    "\n",
    "# Create vectorizations\n",
    "train_all_vectorizations[\"SH\"] = create_vectorizations(train_shortened_diagrams, atol_vectoriser, label_list, SH)\n",
    "test_all_vectorizations[\"SH\"] = create_vectorizations(test_shortened_diagrams, atol_vectoriser, label_list, SH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ef32f8-0871-4ec1-b0f1-4a2983bc294c",
   "metadata": {},
   "source": [
    "## Persistence Landscapes Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "51cb98f2-9b86-4aba-a6cc-cd624bbdc7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train ATOL\n",
    "atol_vectoriser = train_atol(train_shortened_diagrams, label_list, vector_dim, PL)\n",
    "\n",
    "# Create vectorizations\n",
    "train_all_vectorizations[\"PL\"] = create_vectorizations(train_shortened_diagrams, atol_vectoriser, label_list, PL)\n",
    "test_all_vectorizations[\"PL\"] = create_vectorizations(test_shortened_diagrams, atol_vectoriser, label_list, PL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1c714c-807f-4660-8e87-53601fc282c1",
   "metadata": {},
   "source": [
    "## Persistence Image Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c41f1de-8608-4cb8-a470-cd9c94846770",
   "metadata": {},
   "source": [
    "Takes long to compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "299de7a3-60a0-435b-95c0-f857ee0eea2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train ATOL\n",
    "#atol_vectoriser = train_atol(train_shortened_diagrams, label_list, vector_dim, PI)\n",
    "\n",
    "# Create vectorizations\n",
    "#train_all_vectorizations[\"PI\"] = create_vectorizations(train_shortened_diagrams, atol_vectoriser, label_list, PI)\n",
    "#test_all_vectorizations[\"PI\"] = create_vectorizations(test_shortened_diagrams, atol_vectoriser, label_list, PI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9947b42c-267f-4350-9a5b-7168286eb96e",
   "metadata": {},
   "source": [
    "# Create dataframes and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2a6dfc25-4bd4-450b-9ad2-a3d7e4bd9d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_zeros_for_removed_indices(all_vectorizations, removed_indices, vector_dim):\n",
    "    \"\"\" Inserts zero embeddings to the places where diagrams that were to short were removed before.\n",
    "    \n",
    "    Parameters:\n",
    "    - \n",
    "    - vector_dim (int): Dimension the vectorizations should have, e.g. 4.\n",
    "\n",
    "    Returns\n",
    "    - \n",
    "    \"\"\"\n",
    "\n",
    "    for type_of_data_to_vectorize in all_vectorizations.keys(): # the keys are the types of the data that was vectorized (PD, BC, HK,...)\n",
    "        for label in label_list: # labels\n",
    "\n",
    "            # Persistence diagrams do not use the shortened diagrams\n",
    "            if str(type_of_data_to_vectorize) == \"PD\":                \n",
    "                pass\n",
    "                \n",
    "            # If type_of_data_to_vectorize is a signature\n",
    "            else:\n",
    "                for dim in range(3): # homology dimension\n",
    "\n",
    "                    vectorization = all_vectorizations[type_of_data_to_vectorize][dim][label]\n",
    "                \n",
    "                    for idx in removed_indices[label]:\n",
    "                        vectorization.insert(idx, np.zeros(vector_dim))\n",
    "\n",
    "                    all_vectorizations[type_of_data_to_vectorize][dim][label] = vectorization\n",
    "\n",
    "    return all_vectorizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f0bee9a1-68b0-4f69-aff5-3e1f6122b539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add zero vectorizations to those outlier diagrams that were removed before because they are too small\n",
    "\n",
    "if not already_inserted:\n",
    "    train_all_vectorizations = insert_zeros_for_removed_indices(train_all_vectorizations, train_removed_indices, vector_dim)\n",
    "    test_all_vectorizations = insert_zeros_for_removed_indices(test_all_vectorizations, test_removed_indices, vector_dim)\n",
    "    \n",
    "# Make sure the above is only run once\n",
    "already_inserted = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2e02f243-d1ff-4aa0-bd59-5d8a619de4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_df(data_type, all_vectorizations, vector_dim, num_diagrams, label):\n",
    "    \"\"\"\n",
    "    Create DataFrame for each label from features.\n",
    "\n",
    "    Parameters:\n",
    "    - all_vectorizations (dictionary): all vectorizations for all datatypes (keys) \n",
    "    - vector_dim (int): dimension of the vectorization (e.g. 5)\n",
    "    - num_diagrams (int): How many diagrams are there in total?\n",
    "    - label (int): Label for which we want to create a dataframe. 0, 1, 2, 3 or 4\n",
    "\n",
    "    Returns:\n",
    "    - Feature DataFrame (DataFrame)\n",
    "    \"\"\"\n",
    "    \n",
    "    feature_df = pd.DataFrame(index=np.arange(0, num_diagrams))\n",
    "\n",
    "    for type_of_data_to_vectorize in all_vectorizations.keys():\n",
    "        # Persistence diagrams are shaped differently (not separated according to homology dimension)\n",
    "        if str(type_of_data_to_vectorize) == \"PD\":\n",
    "            for dim in range(vector_dim):\n",
    "                feature_df[str(data_type)+\"_PD_Vectorization_Coord_\"+str(dim)] = [arr[dim] for arr in all_vectorizations[type_of_data_to_vectorize][label]]\n",
    "\n",
    "        else:\n",
    "            for hom_dim in range(3):\n",
    "                for dim in range(vector_dim):\n",
    "                    feature_df[str(data_type)+\"_\"+str(type_of_data_to_vectorize)+\"_Vectorization_Dim_\"+str(hom_dim)+\"Coord_\"+str(dim)] = \\\n",
    "                            [arr[dim] for arr in all_vectorizations[type_of_data_to_vectorize][hom_dim][label]]\n",
    "    \n",
    "    \n",
    "    # Label\n",
    "    feature_df[\"Label\"] = label\n",
    "\n",
    "    return feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2b9af6d7-c359-4710-aa0c-f5e48c4e3fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train dataframes\n",
    "train_dataframes = {}\n",
    "\n",
    "for label in label_list:\n",
    "    train_dataframes[label] = create_feature_df(data_type, train_all_vectorizations, vector_dim, \\\n",
    "                                                len(train_persistence_diagrams[label]), label)\n",
    "\n",
    "# Create test dataframes\n",
    "test_dataframes = {}\n",
    "\n",
    "for label in label_list:\n",
    "    test_dataframes[label] = create_feature_df(data_type, test_all_vectorizations, vector_dim, \\\n",
    "                                               len(test_persistence_diagrams[label]), label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2907d3b6-2b18-4e06-b240-954f3a6233f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate and save features of training persistence diagrams\n",
    "train_feature_df = pd.concat([train_dataframes[0], train_dataframes[1], train_dataframes[2], train_dataframes[3], train_dataframes[4]], ignore_index=True)\n",
    "train_feature_df.to_csv(\"Features/\"+str(subject)+\"/Train/\"+str(data_type)+\"/Vectorization_Features.csv\")\n",
    "\n",
    "# Concatenate and save features of training persistence diagrams\n",
    "test_feature_df = pd.concat([test_dataframes[0], test_dataframes[1], test_dataframes[2], test_dataframes[3], test_dataframes[4]], ignore_index=True)\n",
    "test_feature_df.to_csv(\"Features/\"+str(subject)+\"/Test/\"+str(data_type)+\"/Vectorization_Features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e9b8eb-b353-4d50-82f0-c21f8010d517",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188d52fb-1f8a-4227-ba0b-a0f73c8b8b80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c0406b-fb99-44b7-824d-fc5ab405f1fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
