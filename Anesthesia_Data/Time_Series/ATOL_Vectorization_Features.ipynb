{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 776,
   "id": "316cdf4f-956c-4550-807c-ec0f392a4676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' This file vectorizes persistence diagrams and their signatures with the ATOL algorithm.'"
      ]
     },
     "execution_count": 776,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" This file vectorizes persistence diagrams and their signatures with the ATOL algorithm.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "id": "8d0019db-93cd-426a-9d0a-35871e57457a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyedflib\n",
    "import statistics\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "from gtda.time_series import SingleTakensEmbedding\n",
    "from gtda.homology import VietorisRipsPersistence\n",
    "from gtda.diagrams import PersistenceEntropy, Amplitude, NumberOfPoints, ComplexPolynomial, PersistenceLandscape, HeatKernel, Silhouette, BettiCurve, PairwiseDistance, ForgetDimension, PersistenceImage\n",
    "from gtda.plotting import plot_point_cloud, plot_heatmap, plot_diagram\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from gtda.pipeline import Pipeline \n",
    "from sklearn.cluster import KMeans\n",
    "from gudhi.representations.vector_methods import Atol\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0a29cb-c9eb-4e73-84ff-9acc01af18d5",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "id": "3f188cdf-bc5e-4a6b-8dd1-5f35a10b51be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose if you want to look at EEG or EMG data\n",
    "\n",
    "data_type = \"EEG\"\n",
    "#data_type = \"EMG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "id": "ee47cf9f-1400-43e2-8e3c-2599d414fcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose individuum\n",
    "subject = \"m292\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "id": "2edc700a-6aa2-496c-bc1c-24cbf396294f",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = [0, 1, 2, 3, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "id": "1869db59-4091-4074-8c94-15c64649d445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load persistence diagrams\n",
    "\n",
    "persistence_diagrams  = np.load('Embeddings_and_Persistence_Diagrams/'+str(subject)+'/'+str(data_type)+'/Persistence_Diagrams_All_Labels.npy', \\\n",
    "    allow_pickle=True).item() # .item() to convert the dtype to dict again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "id": "904ae63d-4c21-416c-bf19-bd88816e097b",
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_persistence_diagrams  = np.load('Embeddings_and_Persistence_Diagrams/'+str(subject)+'/'+str(data_type)+'/Extended_Persistence_Diagrams_All_Labels.npy', \\\n",
    "    allow_pickle=True).item() # .item() to convert the dtype to dict again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "id": "c2e7cf01-2f51-4be6-b610-81017b450fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_persistence_diagrams = {}\n",
    "\n",
    "for label in label_list:\n",
    "    reshaped_persistence_diagrams[\"Label_\"+str(label)] = [persistence_diagram[0] for persistence_diagram in list(persistence_diagrams[\"Label_\"+str(label)])]\n",
    "\n",
    "persistence_diagrams = reshaped_persistence_diagrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9a1c4a-e1cb-4f26-8797-02ac9ef1eb3b",
   "metadata": {},
   "source": [
    "## Get training indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "id": "afdd675f-368e-455a-a176-122b7b152df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_indices(subject):\n",
    "    train_indices = np.load(\"Train_Test_Splitting/\"+str(subject)+\"/Train_Indices_All_Labels_All_Folds.npy\", allow_pickle=True).item()\n",
    "    validation_indices = np.load(\"Train_Test_Splitting/\"+str(subject)+\"/Validation_Indices_All_Labels_All_Folds.npy\", allow_pickle=True).item()\n",
    "\n",
    "    return train_indices, validation_indices\n",
    "\n",
    "\n",
    "train_indices_dict, validation_indices_dict = load_indices(subject)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79436ddb-23f7-4a2d-a7b8-6dbab1a866e6",
   "metadata": {},
   "source": [
    "# Set parameters and important functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "id": "25d1d151-85ec-48a3-ad2f-e306fe68b327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose dimensionality of the vectorization\n",
    "\n",
    "# Later in the classification, a dimension of 4 works already works approx. optimally at least for persistence diagrams\n",
    "vector_dim = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "id": "c2a4aad5-6364-4a84-882b-e2a8bb53f2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO these functions deal with HK and PI as global variables, which is not ideal. \n",
    "\n",
    "def train_atol(training_data, label_list, vector_dim, type_of_data_to_vectorize = None):\n",
    "    \"\"\" Trains the ATOl model with the training data.\n",
    "    \n",
    "    Parameters:\n",
    "    - training_data (dictionary of np.ndarrays of np.ndarrays of np.ndarrays): Data used for training. \n",
    "    Shape (labels, #persistence diagrams/features, shape of persistence diagram/feature).\n",
    "    - label_list (list): List of labels (e.g. [1, 3, 5, 7].\n",
    "    - vector_dim (int): Dimension the vectorizations should have, e.g. 4.\n",
    "    - type_of_data_to_vectorize (object): either \"HK\", \"BC\", \"SH\" or \"PL\", or None if we are directly vectorizing the data_to_vectorize.\n",
    "\n",
    "    Returns\n",
    "    - atol_vectoriser (object): Atol() object; trained model to vectorize the data to vectorize later.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Concatenate all training data\n",
    "    all_training_data = []\n",
    "    \n",
    "    for label in label_list:\n",
    "        if not type_of_data_to_vectorize:\n",
    "            all_training_data.extend(training_data[\"Label_\"+str(label)])\n",
    "            \n",
    "         # HK & PI have a different shape than the other signatures\n",
    "        elif type_of_data_to_vectorize == HK or type_of_data_to_vectorize == PI:\n",
    "            all_training_data.extend(type_of_data_to_vectorize.fit_transform(training_data[\"Label_\"+str(label)])[0])\n",
    "        else:\n",
    "            all_training_data.extend(type_of_data_to_vectorize.fit_transform(training_data[\"Label_\"+str(label)]))\n",
    "            \n",
    "    # Train Atol vectorizer with all training data\n",
    "    atol_vectoriser = Atol(quantiser=KMeans(n_clusters=vector_dim, random_state=202006))\n",
    "    atol_vectoriser.fit(X=all_training_data).centers\n",
    "\n",
    "    return atol_vectoriser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "id": "a0d004d7-69bb-460c-96e3-2fcffde77f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vectorizations(data_to_vectorize, atol_vectoriser, label_list, type_of_data_to_vectorize = None):\n",
    "    \"\"\" Creates vectorizations from signatures.\n",
    "    \n",
    "    Parameters:\n",
    "    - data_to_vectorize (dictionary of np.ndarrays of np.ndarrays of np.ndarrays): Data to vectorize. \n",
    "    Shape (labels, #persistence diagrams/features, shape of persistence diagram/feature).\n",
    "    - atol_vectoriser (object): Atol() object; trained model to vectorize the data_to_vectorize.\n",
    "    - label_list (list): List of labels (e.g. [1, 3, 5, 7].\n",
    "    - type_of_data_to_vectorize (object): either \"HK\", \"BC\", \"SH\" or \"PL\", or None if we are directly vectorizing the data_to_vectorize.\n",
    "\n",
    "    Returns\n",
    "    - Vectorization. Shape (Number of homology dimensions, number of labels, data_to_vectorize, length of vectorization)\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    # If we are directly vectorizing persistence diagrams\n",
    "    \n",
    "    if not type_of_data_to_vectorize: \n",
    "        \n",
    "        vectorizations = {} # initialize dictionary with labels as keys and vectorizations as values\n",
    "\n",
    "        for label in label_list:\n",
    "            vectorizations[\"Label_\"+str(label)] = []\n",
    "            for diagram in data_to_vectorize[\"Label_\"+str(label)]:\n",
    "                vectorization = atol_vectoriser(diagram)\n",
    "                vectorizations[\"Label_\"+str(label)].append(vectorization)\n",
    "\n",
    "        return vectorizations\n",
    "\n",
    "\n",
    "    # If we are vectorizing features\n",
    "    \n",
    "    vectorizations = {} # initialize dictionary\n",
    "\n",
    "    \n",
    "    for hom_dim in range(3):\n",
    "        vectorizations[\"Hom_Dim_\"+str(hom_dim)] = {}\n",
    "        \n",
    "        for label in label_list:\n",
    "\n",
    "            # Initialize list of vectorizations\n",
    "            vectorizations[\"Hom_Dim_\"+str(hom_dim)][\"Label_\"+str(label)] = []\n",
    "    \n",
    "            for diagram in data_to_vectorize[\"Label_\"+str(label)]:\n",
    "                # We get a depreciation warning if we do not convert the diagram to a numeric type explicitly\n",
    "                signature = type_of_data_to_vectorize.fit_transform([diagram])\n",
    " \n",
    "                if type_of_data_to_vectorize == HK or type_of_data_to_vectorize == PI:\n",
    "\n",
    "                    vector = atol_vectoriser(signature[0][hom_dim])\n",
    "                    vectorizations[\"Hom_Dim_\"+str(hom_dim)][\"Label_\"+str(label)].append(vector)\n",
    "                else:\n",
    "                    vector = atol_vectoriser(signature[0][hom_dim].reshape(1, -1))\n",
    "                    vectorizations[\"Hom_Dim_\"+str(hom_dim)][\"Label_\"+str(label)].append(vector)\n",
    "\n",
    "    return vectorizations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "id": "6c075947-2710-4d49-8fc7-ed1178ee3231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dictionaries with all vectorizations\n",
    "\n",
    "all_vectorizations = {}\n",
    "\n",
    "for fold_idx in range(5):\n",
    "    all_vectorizations[\"Fold_\"+str(fold_idx)] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "id": "6c16e5b4-dccd-41c6-98d5-76115a326703",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_train_persistence_diagrams(persistence_diagrams, train_indices_dict, subject, label_list):\n",
    "\n",
    "    train_diagrams = {}\n",
    "\n",
    "    for fold_idx, fold_key in enumerate(train_indices_dict[\"Label_0\"].keys()):\n",
    "        train_diagrams[fold_key] = {}\n",
    "\n",
    "    \n",
    "    # Initialize dictionarys with folds as keys and the train/validation sets/ their labels as values\n",
    "    for label in label_list:\n",
    "        for fold_idx, fold_key in enumerate(train_indices_dict[\"Label_\"+str(label)].keys()):\n",
    "            train_diagrams[fold_key][\"Label_\"+str(label)] = [persistence_diagrams[\"Label_\"+str(label)][train_idx] for train_idx in train_indices_dict[\"Label_\"+str(label)][\"Fold_\"+str(fold_idx)]]\n",
    "\n",
    "    return train_diagrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9849587d-b386-4722-a800-6c3ee4e87499",
   "metadata": {},
   "source": [
    "# Vectorize persistence diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "id": "de562b81-9cde-42f0-81d7-56518ba420b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve train persistence diagrams for each fold\n",
    "train_diagrams = get_all_train_persistence_diagrams(persistence_diagrams, train_indices_dict, subject, label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "id": "d7fbadbb-2f9b-4e09-b2b0-803cbb029966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train ATOL\n",
    "for fold_idx in range(5):\n",
    "    atol_vectoriser = train_atol(train_diagrams[\"Fold_\"+str(fold_idx)], label_list, vector_dim)\n",
    "\n",
    "    #Apply trained model to the entire data\n",
    "    all_vectorizations[\"Fold_\"+str(fold_idx)][\"PD\"] = create_vectorizations(persistence_diagrams, atol_vectoriser, label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 792,
   "id": "116e95d2-1d73-494f-b36b-6af948e6a056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for final test set\n",
    "validation_diagrams = get_all_train_persistence_diagrams(persistence_diagrams, validation_indices_dict, subject, label_list)\n",
    "\n",
    "final_test_train_diagrams = {0: {}}\n",
    "\n",
    "for label in label_list:\n",
    "    final_test_train_diagrams[0][\"Label_\"+str(label)] = train_diagrams[\"Fold_0\"][\"Label_\"+str(label)] + (validation_diagrams[\"Fold_0\"][\"Label_\"+str(label)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "id": "337dc250-77fc-4011-92ac-f58d236760a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train ATOL\n",
    "atol_vectoriser = train_atol(final_test_train_diagrams[0], label_list, vector_dim)\n",
    "\n",
    "# Apply trained model to the entire data\n",
    "final_test_vectorizations = {}\n",
    "final_test_vectorizations[\"PD\"] = create_vectorizations(persistence_diagrams, atol_vectoriser, label_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9947b42c-267f-4350-9a5b-7168286eb96e",
   "metadata": {},
   "source": [
    "# Create dataframes and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "id": "2a6dfc25-4bd4-450b-9ad2-a3d7e4bd9d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO not necessary anymore?\n",
    "\n",
    "def insert_zeros_for_removed_indices(all_vectorizations, removed_indices, vector_dim, fold_idx):\n",
    "    \"\"\" Inserts zero embeddings to the places where diagrams that were to short were removed before.\n",
    "    \n",
    "    Parameters:\n",
    "    - \n",
    "    - vector_dim (int): Dimension the vectorizations should have, e.g. 4.\n",
    "\n",
    "    Returns\n",
    "    - \n",
    "    \"\"\"\n",
    "\n",
    "    for type_of_data_to_vectorize in all_vectorizations[\"Fold_\"+str(fold_idx)].keys(): # the keys are the types of the data that was vectorized (PD, BC, HK,...)\n",
    "        for label in label_list: # labels\n",
    "\n",
    "            # Persistence diagrams do not use the shortened diagrams\n",
    "            if str(type_of_data_to_vectorize) == \"PD\":                \n",
    "                pass\n",
    "                \n",
    "            # If type_of_data_to_vectorize is a signature\n",
    "            else:\n",
    "                for dim in range(3): # homology dimension\n",
    "\n",
    "                    vectorization = all_vectorizations[\"Fold_\"+str(fold_idx)][type_of_data_to_vectorize][dim][label]\n",
    "                \n",
    "                    for idx in removed_indices[label]:\n",
    "                        vectorization.insert(idx, np.zeros(vector_dim))\n",
    "\n",
    "                    all_vectorizations[\"Fold_\"+str(fold_idx)][type_of_data_to_vectorize][dim][label] = vectorization\n",
    "\n",
    "    return all_vectorizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "id": "2e02f243-d1ff-4aa0-bd59-5d8a619de4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_df(data_type, all_vectorizations, vector_dim, num_diagrams, label, fold_idx):\n",
    "    \"\"\"\n",
    "    Create DataFrame for each label from features.\n",
    "\n",
    "    Parameters:\n",
    "    - all_vectorizations (dictionary): all vectorizations for all datatypes (keys) \n",
    "    - vector_dim (int): dimension of the vectorization (e.g. 5)\n",
    "    - num_diagrams (int): How many diagrams are there in total?\n",
    "    - label (int): Label for which we want to create a dataframe. 0, 1, 2, 3 or 4\n",
    "\n",
    "    Returns:\n",
    "    - Feature DataFrame (DataFrame)\n",
    "    \"\"\"\n",
    "    \n",
    "    feature_df = pd.DataFrame(index=np.arange(0, num_diagrams))\n",
    "\n",
    "    for type_of_data_to_vectorize in all_vectorizations.keys():\n",
    "        # Persistence diagrams are shaped differently (not separated according to homology dimension)\n",
    "        for dim in range(vector_dim):\n",
    "            feature_df[str(data_type)+\"_PD_Vectorization_Coord_\"+str(dim)] = [arr[dim] for arr in \\\n",
    "                                                                    all_vectorizations[type_of_data_to_vectorize][\"Label_\"+str(label)]]\n",
    "        \n",
    "\n",
    "        \n",
    "    \n",
    "    # Label\n",
    "    feature_df[\"Label\"] = label\n",
    "    feature_df[\"Fold\"] = fold_idx\n",
    "\n",
    "\n",
    "    return feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "id": "057d2d65-5dc7-469a-be40-f754f61fb426",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = {}\n",
    "\n",
    "for fold_idx in range(5):\n",
    "    dataframes[\"Fold_\"+str(fold_idx)] = {}\n",
    "    for label in label_list:\n",
    "        dataframes[\"Fold_\"+str(fold_idx)][\"Label_\"+str(label)] = create_feature_df(data_type, \\\n",
    "                all_vectorizations[\"Fold_\"+str(fold_idx)], vector_dim, len(persistence_diagrams[\"Label_\"+str(label)]), label, fold_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "id": "2b9af6d7-c359-4710-aa0c-f5e48c4e3fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all dataframe to one\n",
    "\n",
    "fold_dataframes = {}\n",
    "\n",
    "for fold_idx in range(5):\n",
    "    current_df = dataframes[\"Fold_\"+str(fold_idx)]\n",
    "    fold_dataframes[\"Fold_\"+str(fold_idx)] = pd.concat([current_df[\"Label_\"+str(0)], current_df[\"Label_\"+str(1)], current_df[\"Label_\"+str(2)], current_df[\"Label_\"+str(3)], current_df[\"Label_\"+str(4)]], ignore_index=True)\n",
    "\n",
    "feature_df = pd.concat([fold_dataframes[\"Fold_\"+str(0)], fold_dataframes[\"Fold_\"+str(1)], fold_dataframes[\"Fold_\"+str(2)], \\\n",
    "                        fold_dataframes[\"Fold_\"+str(3)], fold_dataframes[\"Fold_\"+str(4)]], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "id": "2907d3b6-2b18-4e06-b240-954f3a6233f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df.to_csv(\"Features/\"+str(subject)+\"/\"+str(data_type)+\"/Vectorization_Features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "id": "d55351e4-953b-4644-8287-80364dc5b0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Test Set\n",
    "\n",
    "dataframes = {}\n",
    "\n",
    "for label in label_list:\n",
    "        dataframes[\"Label_\"+str(label)] = create_feature_df(data_type, \\\n",
    "                final_test_vectorizations, vector_dim, len(persistence_diagrams[\"Label_\"+str(label)]), label, -1)\n",
    "\n",
    "\n",
    "feature_df = pd.concat([dataframes[\"Label_\"+str(0)], dataframes[\"Label_\"+str(1)], dataframes[\"Label_\"+str(2)], \\\n",
    "                        dataframes[\"Label_\"+str(3)], dataframes[\"Label_\"+str(4)]], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "id": "dd47bc04-cc1a-4ef1-9e8b-c97ac8122745",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df.to_csv(\"Features/\"+str(subject)+\"/\"+str(data_type)+\"/Vectorization_Features_for_Final_Test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc18ef36-3250-4c70-bddb-6fd13e8ffbb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
