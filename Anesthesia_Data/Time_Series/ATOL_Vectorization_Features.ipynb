{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "316cdf4f-956c-4550-807c-ec0f392a4676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' This file vectorizes persistence diagrams and their signatures with the ATOL algorithm.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" This file vectorizes persistence diagrams and their signatures with the ATOL algorithm.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8d0019db-93cd-426a-9d0a-35871e57457a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyedflib\n",
    "import statistics\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "from gtda.time_series import SingleTakensEmbedding\n",
    "from gtda.homology import VietorisRipsPersistence\n",
    "from gtda.diagrams import PersistenceEntropy, Amplitude, NumberOfPoints, ComplexPolynomial, PersistenceLandscape, HeatKernel, Silhouette, BettiCurve, PairwiseDistance, ForgetDimension, PersistenceImage\n",
    "from gtda.plotting import plot_point_cloud, plot_heatmap, plot_diagram\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from gtda.pipeline import Pipeline \n",
    "from sklearn.cluster import KMeans\n",
    "from gudhi.representations.vector_methods import Atol\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0a29cb-c9eb-4e73-84ff-9acc01af18d5",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3f188cdf-bc5e-4a6b-8dd1-5f35a10b51be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose if you want to look at EEG or EMG data\n",
    "\n",
    "data_type = \"EEG\"\n",
    "data_type = \"EMG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ee47cf9f-1400-43e2-8e3c-2599d414fcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose individuum\n",
    "subject = \"m294\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2edc700a-6aa2-496c-bc1c-24cbf396294f",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = [0, 1, 2, 3, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1869db59-4091-4074-8c94-15c64649d445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load persistence diagrams\n",
    "\n",
    "persistence_diagrams  = np.load('Embeddings_and_Persistence_Diagrams/'+str(subject)+'/'+str(data_type)+'/Persistence_Diagrams_All_Labels.npy', \\\n",
    "    allow_pickle=True).item() # .item() to convert the dtype to dict again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "904ae63d-4c21-416c-bf19-bd88816e097b",
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_persistence_diagrams  = np.load('Embeddings_and_Persistence_Diagrams/'+str(subject)+'/'+str(data_type)+'/Extended_Persistence_Diagrams_All_Labels.npy', \\\n",
    "    allow_pickle=True).item() # .item() to convert the dtype to dict again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c2e7cf01-2f51-4be6-b610-81017b450fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO do this in Preprocessing_And_Computing_...\n",
    "\n",
    "reshaped_persistence_diagrams = {}\n",
    "\n",
    "for label in label_list:\n",
    "    reshaped_persistence_diagrams[\"Label_\"+str(label)] = [persistence_diagram[0] for persistence_diagram in list(persistence_diagrams[\"Label_\"+str(label)])]\n",
    "\n",
    "persistence_diagrams = reshaped_persistence_diagrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9a1c4a-e1cb-4f26-8797-02ac9ef1eb3b",
   "metadata": {},
   "source": [
    "## Get training indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "afdd675f-368e-455a-a176-122b7b152df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_indices(subject):\n",
    "    train_indices = np.load(\"Train_Test_Splitting/\"+str(subject)+\"/Train_Indices_All_Labels_All_Folds.npy\", allow_pickle=True).item()\n",
    "\n",
    "    return train_indices\n",
    "\n",
    "\n",
    "train_indices_dict = load_indices(subject)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79436ddb-23f7-4a2d-a7b8-6dbab1a866e6",
   "metadata": {},
   "source": [
    "# Set parameters and important functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "25d1d151-85ec-48a3-ad2f-e306fe68b327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose dimensionality of the vectorization\n",
    "\n",
    "# Later in the classification, a dimension of 4 works already works approx. optimally at least for persistence diagrams\n",
    "vector_dim = 4  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "37acb6b9-864c-4399-9687-70a71a0ccc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define all data type objects\n",
    "\n",
    "HK = HeatKernel(sigma=0.00003, n_bins=100)\n",
    "BC = BettiCurve()\n",
    "SH = Silhouette()\n",
    "PL = PersistenceLandscape()\n",
    "PI = PersistenceImage(sigma=0.00003, n_bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c2a4aad5-6364-4a84-882b-e2a8bb53f2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO these functions deal with HK and PI as global variables, which is not ideal. \n",
    "\n",
    "def train_atol(training_data, label_list, vector_dim, type_of_data_to_vectorize = None):\n",
    "    \"\"\" Trains the ATOl model with the training data.\n",
    "    \n",
    "    Parameters:\n",
    "    - training_data (dictionary of np.ndarrays of np.ndarrays of np.ndarrays): Data used for training. \n",
    "    Shape (labels, #persistence diagrams/features, shape of persistence diagram/feature).\n",
    "    - label_list (list): List of labels (e.g. [1, 3, 5, 7].\n",
    "    - vector_dim (int): Dimension the vectorizations should have, e.g. 4.\n",
    "    - type_of_data_to_vectorize (object): either \"HK\", \"BC\", \"SH\" or \"PL\", or None if we are directly vectorizing the data_to_vectorize.\n",
    "\n",
    "    Returns\n",
    "    - atol_vectoriser (object): Atol() object; trained model to vectorize the data to vectorize later.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Concatenate all training data\n",
    "    all_training_data = []\n",
    "    \n",
    "    for label in label_list:\n",
    "        if not type_of_data_to_vectorize:\n",
    "            all_training_data.extend(training_data[\"Label_\"+str(label)])\n",
    "            \n",
    "         # HK & PI have a different shape than the other signatures\n",
    "        elif type_of_data_to_vectorize == HK or type_of_data_to_vectorize == PI:\n",
    "            all_training_data.extend(type_of_data_to_vectorize.fit_transform(training_data[\"Label_\"+str(label)])[0])\n",
    "        else:\n",
    "            all_training_data.extend(type_of_data_to_vectorize.fit_transform(training_data[\"Label_\"+str(label)]))\n",
    "            \n",
    "    # Train Atol vectorizer with all training data\n",
    "    atol_vectoriser = Atol(quantiser=KMeans(n_clusters=vector_dim, random_state=202006))\n",
    "    atol_vectoriser.fit(X=all_training_data).centers\n",
    "\n",
    "    return atol_vectoriser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "a0d004d7-69bb-460c-96e3-2fcffde77f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vectorizations(data_to_vectorize, atol_vectoriser, label_list, type_of_data_to_vectorize = None):\n",
    "    \"\"\" Creates vectorizations from signatures.\n",
    "    \n",
    "    Parameters:\n",
    "    - data_to_vectorize (dictionary of np.ndarrays of np.ndarrays of np.ndarrays): Data to vectorize. \n",
    "    Shape (labels, #persistence diagrams/features, shape of persistence diagram/feature).\n",
    "    - atol_vectoriser (object): Atol() object; trained model to vectorize the data_to_vectorize.\n",
    "    - label_list (list): List of labels (e.g. [1, 3, 5, 7].\n",
    "    - type_of_data_to_vectorize (object): either \"HK\", \"BC\", \"SH\" or \"PL\", or None if we are directly vectorizing the data_to_vectorize.\n",
    "\n",
    "    Returns\n",
    "    - Vectorization. Shape (Number of homology dimensions, number of labels, data_to_vectorize, length of vectorization)\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    # If we are directly vectorizing persistence diagrams\n",
    "    \n",
    "    if not type_of_data_to_vectorize: \n",
    "        \n",
    "        vectorizations = {} # initialize dictionary with labels as keys and vectorizations as values\n",
    "\n",
    "        for label in label_list:\n",
    "            vectorizations[\"Label_\"+str(label)] = []\n",
    "            for diagram in data_to_vectorize[\"Label_\"+str(label)]:\n",
    "                vectorization = atol_vectoriser(diagram)\n",
    "                vectorizations[\"Label_\"+str(label)].append(vectorization)\n",
    "\n",
    "        return vectorizations\n",
    "\n",
    "\n",
    "    # If we are vectorizing features\n",
    "    \n",
    "    vectorizations = {} # initialize dictionary\n",
    "\n",
    "    \n",
    "    for hom_dim in range(3):\n",
    "        vectorizations[\"Hom_Dim_\"+str(hom_dim)] = {}\n",
    "        \n",
    "        for label in label_list:\n",
    "\n",
    "            # Initialize list of vectorizations\n",
    "            vectorizations[\"Hom_Dim_\"+str(hom_dim)][\"Label_\"+str(label)] = []\n",
    "    \n",
    "            for diagram in data_to_vectorize[\"Label_\"+str(label)]:\n",
    "                # We get a depreciation warning if we do not convert the diagram to a numeric type explicitly\n",
    "                signature = type_of_data_to_vectorize.fit_transform([diagram])\n",
    " \n",
    "                if type_of_data_to_vectorize == HK or type_of_data_to_vectorize == PI:\n",
    "\n",
    "                    vector = atol_vectoriser(signature[0][hom_dim])\n",
    "                    vectorizations[\"Hom_Dim_\"+str(hom_dim)][\"Label_\"+str(label)].append(vector)\n",
    "                else:\n",
    "                    vector = atol_vectoriser(signature[0][hom_dim].reshape(1, -1))\n",
    "                    vectorizations[\"Hom_Dim_\"+str(hom_dim)][\"Label_\"+str(label)].append(vector)\n",
    "\n",
    "    return vectorizations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "6c075947-2710-4d49-8fc7-ed1178ee3231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dictionaries with all vectorizations\n",
    "\n",
    "all_vectorizations = {}\n",
    "\n",
    "for fold_idx in range(5):\n",
    "    all_vectorizations[\"Fold_\"+str(fold_idx)] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "6c16e5b4-dccd-41c6-98d5-76115a326703",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_train_persistence_diagrams(persistence_diagrams, train_indices_dict, subject, label_list):\n",
    "\n",
    "    train_diagrams = {}\n",
    "\n",
    "    for fold_idx, fold_key in enumerate(train_indices_dict[\"Label_0\"].keys()):\n",
    "        train_diagrams[fold_key] = {}\n",
    "\n",
    "    \n",
    "    # Initialize dictionarys with folds as keys and the train/validation sets/ their labels as values\n",
    "    for label in label_list:\n",
    "        for fold_idx, fold_key in enumerate(train_indices_dict[\"Label_\"+str(label)].keys()):\n",
    "            train_diagrams[fold_key][\"Label_\"+str(label)] = [persistence_diagrams[\"Label_\"+str(label)][train_idx] for train_idx in train_indices_dict[\"Label_\"+str(label)][\"Fold_\"+str(fold_idx)]]\n",
    "\n",
    "    return train_diagrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9849587d-b386-4722-a800-6c3ee4e87499",
   "metadata": {},
   "source": [
    "# Vectorize persistence diagrams directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "de562b81-9cde-42f0-81d7-56518ba420b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve train persistence diagrams for each fold\n",
    "train_diagrams = get_all_train_persistence_diagrams(persistence_diagrams, train_indices_dict, subject, label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "d7fbadbb-2f9b-4e09-b2b0-803cbb029966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train ATOL\n",
    "for fold_idx in range(5):\n",
    "    atol_vectoriser = train_atol(train_diagrams[\"Fold_\"+str(fold_idx)], label_list, vector_dim)\n",
    "\n",
    "    #Apply trained model to the entire data\n",
    "    all_vectorizations[\"Fold_\"+str(fold_idx)][\"PD\"] = create_vectorizations(persistence_diagrams, atol_vectoriser, label_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb839e93-9f55-45a9-a1ee-f5a29a18d054",
   "metadata": {},
   "source": [
    "# Vectorize Signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "822daad6-080a-4ff6-9845-1d5b9a4d6cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve extended train persistence diagrams for each fold\n",
    "train_diagrams = get_all_train_persistence_diagrams(extended_persistence_diagrams, train_indices_dict, subject, label_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0491516c-3ecc-4f5e-8748-a2bc88fc4b4d",
   "metadata": {},
   "source": [
    "## Heatkernel vectorizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "484c75b8-d7ec-4373-8db6-14d1bdbee785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train ATOL\n",
    "for fold_idx in range(5):\n",
    "    atol_vectoriser = train_atol(train_diagrams[\"Fold_\"+str(fold_idx)], label_list, vector_dim, HK)\n",
    "\n",
    "    #Apply trained model to the entire data\n",
    "    all_vectorizations[\"Fold_\"+str(fold_idx)][\"HK\"] = create_vectorizations(extended_persistence_diagrams, atol_vectoriser, label_list, HK)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02150806-42de-468a-9277-4764d0eac6ed",
   "metadata": {},
   "source": [
    "## Betti Curve Vectorizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "e0744d0b-a94e-4011-9d8f-40abc3f1fa2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train ATOL\n",
    "for fold_idx in range(5):\n",
    "    atol_vectoriser = train_atol(train_diagrams[\"Fold_\"+str(fold_idx)], label_list, vector_dim, BC)\n",
    "\n",
    "    #Apply trained model to the entire data\n",
    "    all_vectorizations[\"Fold_\"+str(fold_idx)][\"BC\"] = create_vectorizations(extended_persistence_diagrams, atol_vectoriser, label_list, BC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0515117d-4a5c-4c3b-84b4-50e003b75188",
   "metadata": {},
   "source": [
    "## Vectorize Silhouettes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "23a964e3-1d1e-431e-9fe0-556564991130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train ATOL\n",
    "for fold_idx in range(5):\n",
    "    atol_vectoriser = train_atol(train_diagrams[\"Fold_\"+str(fold_idx)], label_list, vector_dim, SH)\n",
    "\n",
    "    #Apply trained model to the entire data\n",
    "    all_vectorizations[\"Fold_\"+str(fold_idx)][\"SH\"] = create_vectorizations(extended_persistence_diagrams, atol_vectoriser, label_list, SH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ef32f8-0871-4ec1-b0f1-4a2983bc294c",
   "metadata": {},
   "source": [
    "## Persistence Landscapes Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "51cb98f2-9b86-4aba-a6cc-cd624bbdc7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train ATOL\n",
    "for fold_idx in range(5):\n",
    "    atol_vectoriser = train_atol(train_diagrams[\"Fold_\"+str(fold_idx)], label_list, vector_dim, PL)\n",
    "\n",
    "    #Apply trained model to the entire data\n",
    "    all_vectorizations[\"Fold_\"+str(fold_idx)][\"PL\"] = create_vectorizations(extended_persistence_diagrams, atol_vectoriser, label_list, PL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1c714c-807f-4660-8e87-53601fc282c1",
   "metadata": {},
   "source": [
    "## Persistence Image Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c41f1de-8608-4cb8-a470-cd9c94846770",
   "metadata": {},
   "source": [
    "Takes long to compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "299de7a3-60a0-435b-95c0-f857ee0eea2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train ATOL\n",
    "#atol_vectoriser = train_atol(train_shortened_diagrams, label_list, vector_dim, PI)\n",
    "\n",
    "# Create vectorizations\n",
    "#train_all_vectorizations[\"PI\"] = create_vectorizations(train_shortened_diagrams, atol_vectoriser, label_list, PI)\n",
    "#test_all_vectorizations[\"PI\"] = create_vectorizations(test_shortened_diagrams, atol_vectoriser, label_list, PI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9947b42c-267f-4350-9a5b-7168286eb96e",
   "metadata": {},
   "source": [
    "# Create dataframes and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "2a6dfc25-4bd4-450b-9ad2-a3d7e4bd9d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_zeros_for_removed_indices(all_vectorizations, removed_indices, vector_dim, fold_idx):\n",
    "    \"\"\" Inserts zero embeddings to the places where diagrams that were to short were removed before.\n",
    "    \n",
    "    Parameters:\n",
    "    - \n",
    "    - vector_dim (int): Dimension the vectorizations should have, e.g. 4.\n",
    "\n",
    "    Returns\n",
    "    - \n",
    "    \"\"\"\n",
    "\n",
    "    for type_of_data_to_vectorize in all_vectorizations[\"Fold_\"+str(fold_idx)].keys(): # the keys are the types of the data that was vectorized (PD, BC, HK,...)\n",
    "        for label in label_list: # labels\n",
    "\n",
    "            # Persistence diagrams do not use the shortened diagrams\n",
    "            if str(type_of_data_to_vectorize) == \"PD\":                \n",
    "                pass\n",
    "                \n",
    "            # If type_of_data_to_vectorize is a signature\n",
    "            else:\n",
    "                for dim in range(3): # homology dimension\n",
    "\n",
    "                    vectorization = all_vectorizations[\"Fold_\"+str(fold_idx)][type_of_data_to_vectorize][dim][label]\n",
    "                \n",
    "                    for idx in removed_indices[label]:\n",
    "                        vectorization.insert(idx, np.zeros(vector_dim))\n",
    "\n",
    "                    all_vectorizations[\"Fold_\"+str(fold_idx)][type_of_data_to_vectorize][dim][label] = vectorization\n",
    "\n",
    "    return all_vectorizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "2e02f243-d1ff-4aa0-bd59-5d8a619de4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_df(data_type, all_vectorizations, vector_dim, num_diagrams, label, fold_idx):\n",
    "    \"\"\"\n",
    "    Create DataFrame for each label from features.\n",
    "\n",
    "    Parameters:\n",
    "    - all_vectorizations (dictionary): all vectorizations for all datatypes (keys) \n",
    "    - vector_dim (int): dimension of the vectorization (e.g. 5)\n",
    "    - num_diagrams (int): How many diagrams are there in total?\n",
    "    - label (int): Label for which we want to create a dataframe. 0, 1, 2, 3 or 4\n",
    "\n",
    "    Returns:\n",
    "    - Feature DataFrame (DataFrame)\n",
    "    \"\"\"\n",
    "    \n",
    "    feature_df = pd.DataFrame(index=np.arange(0, num_diagrams))\n",
    "\n",
    "    for type_of_data_to_vectorize in all_vectorizations.keys():\n",
    "        # Persistence diagrams are shaped differently (not separated according to homology dimension)\n",
    "        if str(type_of_data_to_vectorize) == \"PD\":\n",
    "            for dim in range(vector_dim):\n",
    "                feature_df[str(data_type)+\"_PD_Vectorization_Coord_\"+str(dim)] = [arr[dim] for arr in \\\n",
    "                                                                    all_vectorizations[type_of_data_to_vectorize][\"Label_\"+str(label)]]\n",
    "\n",
    "        else:\n",
    "            for hom_dim in range(3):\n",
    "                for vector_dim in range(vector_dim):\n",
    "                    feature_df[str(data_type)+\"_\"+str(type_of_data_to_vectorize)+\"_Vectorization_Dim_\"+str(hom_dim)+\"Coord_\"+str(vector_dim)] = \\\n",
    "                            [arr[vector_dim] for arr in all_vectorizations[type_of_data_to_vectorize][\"Hom_Dim_\"+str(hom_dim)][\"Label_\"+str(label)]]\n",
    "    \n",
    "    \n",
    "    # Label\n",
    "    feature_df[\"Label\"] = label\n",
    "    feature_df[\"Fold\"] = fold_idx\n",
    "\n",
    "\n",
    "    return feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "057d2d65-5dc7-469a-be40-f754f61fb426",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = {}\n",
    "\n",
    "for fold_idx in range(5):\n",
    "    dataframes[\"Fold_\"+str(fold_idx)] = {}\n",
    "    for label in label_list:\n",
    "        dataframes[\"Fold_\"+str(fold_idx)][\"Label_\"+str(label)] = create_feature_df(data_type, \\\n",
    "                all_vectorizations[\"Fold_\"+str(fold_idx)], vector_dim, len(persistence_diagrams[\"Label_\"+str(label)]), label, fold_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "2b9af6d7-c359-4710-aa0c-f5e48c4e3fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all dataframe to one\n",
    "\n",
    "fold_dataframes = {}\n",
    "\n",
    "for fold_idx in range(5):\n",
    "    current_df = dataframes[\"Fold_\"+str(fold_idx)]\n",
    "    fold_dataframes[\"Fold_\"+str(fold_idx)] = pd.concat([current_df[\"Label_\"+str(0)], current_df[\"Label_\"+str(1)], current_df[\"Label_\"+str(2)], current_df[\"Label_\"+str(3)], current_df[\"Label_\"+str(4)]], ignore_index=True)\n",
    "\n",
    "feature_df = pd.concat([fold_dataframes[\"Fold_\"+str(0)], fold_dataframes[\"Fold_\"+str(1)], fold_dataframes[\"Fold_\"+str(2)], \\\n",
    "                        fold_dataframes[\"Fold_\"+str(3)], fold_dataframes[\"Fold_\"+str(4)]], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "2907d3b6-2b18-4e06-b240-954f3a6233f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df.to_csv(\"Features/\"+str(subject)+\"/\"+str(data_type)+\"/Vectorization_Features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e9b8eb-b353-4d50-82f0-c21f8010d517",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188d52fb-1f8a-4227-ba0b-a0f73c8b8b80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c0406b-fb99-44b7-824d-fc5ab405f1fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
