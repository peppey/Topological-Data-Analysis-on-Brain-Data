{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9f3ffa4-2d95-4158-8ac6-92b145e05e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from /Users/piabaronetzky/Desktop/Helmholtz/Code/Anesthesia_Data/Time_Series/../../Anesthesia_Data/Helpers.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "from sklearn.utils import shuffle\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "import Anesthesia_Data.Helpers as helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96ef8fb-0483-47c0-a098-4765de47b4f5",
   "metadata": {},
   "source": [
    "# Import and Concatenate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "44894145-e4db-4240-8466-9ff4fa84392e",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_list = [\"m292\", \"m294\"]\n",
    "label_list  = [0, 1, 2, 3, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ddc99755-d7db-4b7e-b561-aa13c2f08b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_and_concatenate_datasets(subject_list, list_of_filenames, parent_directory):\n",
    "    \"\"\"\n",
    "    Import and concatenate feature datasets for each subject.\n",
    "\n",
    "    Args:\n",
    "    - subject_list (list): List of subject names.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: Concatenated feature DataFrame.\n",
    "    - list: List of all labels.\n",
    "    \"\"\"\n",
    "    subject_feature_dfs = {}\n",
    "\n",
    "    for subject_idx, subject in enumerate(subject_list):\n",
    "        subject_feature_dfs[subject] = pd.DataFrame()\n",
    "\n",
    "        for data_type in [\"EEG\", \"EMG\"]:\n",
    "            data_frames = []\n",
    "\n",
    "            for file in list_of_filenames:\n",
    "                path = os.path.join(str(parent_directory), \"Features\", str(subject), str(data_type), file)\n",
    "                if os.path.exists(path):\n",
    "                    data_frames.append(pd.read_csv(path))\n",
    "\n",
    "            df_both_data_types = pd.concat(data_frames, axis=1)\n",
    "\n",
    "            if not subject_feature_dfs[subject].empty:\n",
    "                subject_feature_dfs[subject] = pd.concat([subject_feature_dfs[subject], df_both_data_types], axis=1)\n",
    "            else:\n",
    "                subject_feature_dfs[subject] = df_both_data_types\n",
    "\n",
    "        subject_feature_dfs[subject][\"Subject\"] = subject_idx\n",
    "\n",
    "    feature_df = pd.concat(subject_feature_dfs.values(), ignore_index=True)\n",
    "\n",
    "    # For duplicate columns, only keep one\n",
    "    feature_df = feature_df.loc[:, ~feature_df.columns.duplicated()]\n",
    "\n",
    "    feature_df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "    \n",
    "    return feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a2209dc-3870-4f09-b6aa-e46f50298cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataframes that do not depend on folds\n",
    "list_of_filenames = [\"Topological_Summary_Statistics.csv\", \"Signature_Statistics.csv\", \"Advanced_Features.csv\"]\n",
    "\n",
    "    \n",
    "feature_df = import_and_concatenate_datasets(subject_list, list_of_filenames, parent_directory = \"\")\n",
    "\n",
    "all_labels = feature_df[\"Label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a2e758e-9f50-4db2-80e2-ca091cb0e6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframes that DO depend on folds\n",
    "\n",
    "# Import dataframes that do not depend on folds\n",
    "list_of_filenames = [\"Vectorization_Features.csv\"]\n",
    "\n",
    "    \n",
    "fold_dependant_feature_df = import_and_concatenate_datasets(subject_list, list_of_filenames, parent_directory = \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13c4ac3-9d48-4ab1-a76c-93168323ade0",
   "metadata": {},
   "source": [
    "# Experiments with Single Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eafcd9c0-7e26-4dc1-8bca-4ce7b1df4bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 41 features in the main dataframe.\n"
     ]
    }
   ],
   "source": [
    "print(\"There are \"+str(len(feature_df.columns))+\" features in the main dataframe.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b91f048c-41a3-4423-a588-776234da857e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There now are 41 features in the main dataframe.\n"
     ]
    }
   ],
   "source": [
    "list_of_strings_in_column_name = [\"_Vectorization_Coordinate_\", \"L1\"]\n",
    "\n",
    "feature_df = helpers.remove_columns_with_str(feature_df, list_of_strings_in_column_name)\n",
    "\n",
    "print(\"There now are \"+str(len(feature_df.columns))+\" features in the main dataframe.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba80e2d-e1ea-453d-b974-883ac03fff08",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e19d74b-76b3-4908-bdf9-c4733a1c9ae6",
   "metadata": {},
   "source": [
    "## Features that do not depend on folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ce54a8e-a97a-4744-a908-c79c71cd2dd4",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'Anesthesia_Data.Helpers' has no attribute 'load_folds'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_indices, validation_indices, test_indices \u001b[38;5;241m=\u001b[39m \u001b[43mhelpers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_folds\u001b[49m(subject_list, parent_directory\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'Anesthesia_Data.Helpers' has no attribute 'load_folds'"
     ]
    }
   ],
   "source": [
    "train_indices, validation_indices, test_indices = helpers.load_folds(subject_list, parent_directory=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e2516b5-e64a-47d4-8c5d-71c9854427c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_dataframe_with_indices(feature_df, indices_dict_all_subjects, label_list, n_folds = 5):\n",
    "    \n",
    "    feature_df_all_folds = {}\n",
    "    all_labels = {}\n",
    "\n",
    "    for fold_idx in range(n_folds):\n",
    "\n",
    "        fold_df = pd.DataFrame()\n",
    "        \n",
    "        \n",
    "        for subject_idx, subject in enumerate(indices_dict_all_subjects.keys()):\n",
    "            filtered_subject_df = feature_df[feature_df[\"Subject\"] == subject_idx]\n",
    "\n",
    "            for label in label_list:                \n",
    "                \n",
    "                filtered_label_df = filtered_subject_df.loc[filtered_subject_df[\"Label\"] == label]\n",
    "\n",
    "                set_indices_in_filtered_df = indices_dict_all_subjects[subject][\"Label_\"+str(label)][\"Fold_\"+str(fold_idx)]\n",
    "\n",
    "                feature_df_with_set_indices = filtered_label_df.iloc[set_indices_in_filtered_df]\n",
    "\n",
    "                fold_df = pd.concat([fold_df, feature_df_with_set_indices], ignore_index=True)\n",
    "\n",
    "        all_labels[\"Fold_\"+str(fold_idx)] = fold_df[\"Label\"]\n",
    "        fold_df.drop(columns=[\"Label\"], inplace=True)\n",
    "\n",
    "        feature_df_all_folds[\"Fold_\"+str(fold_idx)] = fold_df\n",
    "\n",
    "    return feature_df_all_folds, all_labels\n",
    "\n",
    "train_features_dfs_all_folds, train_labels_all_folds = filter_dataframe_with_indices(feature_df, train_indices, label_list)\n",
    "validation_features_dfs_all_folds, validation_labels_all_folds = filter_dataframe_with_indices(feature_df, validation_indices, label_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762a046c-c14d-4ce3-803b-6ea6b674cb41",
   "metadata": {},
   "source": [
    "## Fold-dependant Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "deef6d93-46fd-443a-b6a5-b163926f1caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_fold_dependant_dataframe_with_indices(fold_dependant_feature_df, indices_dict_all_subjects, label_list, n_folds = 5):\n",
    "\n",
    "    # TODO remove duplicate code (see above)\n",
    "    \n",
    "    feature_df_all_folds = {}\n",
    "\n",
    "    for fold_idx in range(n_folds):\n",
    "\n",
    "        filtered_fold_df = fold_dependant_feature_df[fold_dependant_feature_df[\"Fold\"] == fold_idx]\n",
    "\n",
    "        fold_df = pd.DataFrame()\n",
    "        \n",
    "        for subject_idx, subject in enumerate(indices_dict_all_subjects.keys()):\n",
    "            filtered_subject_df = filtered_fold_df[filtered_fold_df[\"Subject\"] == subject_idx]\n",
    "\n",
    "\n",
    "            for label in label_list:                \n",
    "                \n",
    "                filtered_label_df = filtered_subject_df.loc[filtered_subject_df[\"Label\"] == label]\n",
    "\n",
    "                set_indices_in_filtered_df = indices_dict_all_subjects[subject][\"Label_\"+str(label)][\"Fold_\"+str(fold_idx)]\n",
    "\n",
    "                feature_df_with_set_indices = filtered_label_df.iloc[set_indices_in_filtered_df]\n",
    "\n",
    "                fold_df = pd.concat([fold_df, feature_df_with_set_indices], ignore_index=True)\n",
    "\n",
    "        feature_df_all_folds[\"Fold_\"+str(fold_idx)] = fold_df\n",
    "\n",
    "\n",
    "    return feature_df_all_folds\n",
    "\n",
    "train_fold_dependant_features_dfs_all_folds = filter_fold_dependant_dataframe_with_indices(fold_dependant_feature_df, train_indices, label_list)\n",
    "validation_fold_dependant_features_dfs_all_folds = filter_fold_dependant_dataframe_with_indices(fold_dependant_feature_df, validation_indices, label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e3fe5e8e-f7eb-4532-976f-9b8c4cdc3004",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_all_features(features_dfs_all_folds, fold_dependant_features_dfs_all_folds, n_folds = 5):\n",
    "\n",
    "    features_df_all_folds_all_features = {}\n",
    "\n",
    "    for fold in range(n_folds):\n",
    "        features_df_all_folds_all_features[\"Fold_\"+str(fold)] = pd.concat([features_dfs_all_folds[\"Fold_\"+str(fold)], fold_dependant_features_dfs_all_folds[\"Fold_\"+str(fold)]], axis=1)\n",
    "        \n",
    "    return features_df_all_folds_all_features\n",
    "\n",
    "train_features_df_all_folds_all_features = combine_all_features(train_features_dfs_all_folds, train_fold_dependant_features_dfs_all_folds)\n",
    "validation_features_df_all_folds_all_features = combine_all_features(validation_features_dfs_all_folds, validation_fold_dependant_features_dfs_all_folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fa5ea7-ed61-4a0c-86c7-58abaa35c331",
   "metadata": {},
   "source": [
    "## Reformat data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9bf2cc5b-770b-4ddc-835e-744e33435e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_fold_dicts(train_features_dfs_all_folds, train_labels_all_folds, validation_features_dfs_all_folds, validation_labels_all_folds, n_folds = 5):\n",
    "    \"\"\"\n",
    "    Initialize dictionaries with folds as keys and assign features and labels accordingly.\n",
    "    \n",
    "    Args:\n",
    "    - train_features_dfs_all_folds (dict): Dictionary containing training features for all folds.\n",
    "    - train_labels_all_folds (dict): Dictionary containing training labels for all folds.\n",
    "    - validation_features_dfs_all_folds (dict): Dictionary containing validation features for all folds.\n",
    "    - validation_labels_all_folds (dict): Dictionary containing validation labels for all folds.\n",
    "    - n_folds (int): Number of folds.\n",
    "    \n",
    "    Returns:\n",
    "    - dict: Dictionary containing training features for each fold.\n",
    "    - dict: Dictionary containing training labels for each fold.\n",
    "    - dict: Dictionary containing validation features for each fold.\n",
    "    - dict: Dictionary containing validation labels for each fold.\n",
    "    \"\"\"\n",
    "    X_train = {}\n",
    "    y_train = {}\n",
    "    X_test = {}\n",
    "    y_test = {}\n",
    "\n",
    "    for fold in range(n_folds):\n",
    "        # Set random seed for reproducibility\n",
    "        np.random.seed(42)\n",
    "\n",
    "        # Shuffle indices\n",
    "        indices_train = np.random.permutation(len(train_features_dfs_all_folds[\"Fold_\" + str(fold)]))\n",
    "        indices_test = np.random.permutation(len(validation_features_dfs_all_folds[\"Fold_\" + str(fold)]))\n",
    "\n",
    "        # Shuffle rows of X_train[fold] and y_train[fold]\n",
    "        X_train_fold = train_features_dfs_all_folds[\"Fold_\" + str(fold)].iloc[indices_train]\n",
    "        y_train_fold = [train_labels_all_folds[\"Fold_\" + str(fold)][index] for index in indices_train]\n",
    "\n",
    "        # Shuffle rows of X_test[fold] and y_test[fold]\n",
    "        X_test_fold = validation_features_dfs_all_folds[\"Fold_\" + str(fold)].iloc[indices_test]\n",
    "        y_test_fold = [validation_labels_all_folds[\"Fold_\" + str(fold)][index] for index in indices_test]\n",
    "\n",
    "        X_train[fold] = X_train_fold\n",
    "        y_train[fold] = y_train_fold\n",
    "        X_test[fold] = X_test_fold\n",
    "        y_test[fold] = y_test_fold\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "X_train, y_train, X_test, y_test = initialize_fold_dicts(train_features_df_all_folds_all_features, train_labels_all_folds, validation_features_df_all_folds_all_features, validation_labels_all_folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd860d8-fef1-4f99-86d4-7bbc1db4f95a",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ee4598-27e5-4ad6-ac29-6ec6191e8db5",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "51a5995c-42e5-41c8-ad7a-a787e5e4029b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/piabaronetzky/anaconda3/envs/time-delay-embeddings/lib/python3.10/site-packages/sklearn/utils/validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/piabaronetzky/anaconda3/envs/time-delay-embeddings/lib/python3.10/site-packages/sklearn/utils/validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/piabaronetzky/anaconda3/envs/time-delay-embeddings/lib/python3.10/site-packages/sklearn/utils/validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for fold 1 : 0.9916666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/piabaronetzky/anaconda3/envs/time-delay-embeddings/lib/python3.10/site-packages/sklearn/utils/validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/piabaronetzky/anaconda3/envs/time-delay-embeddings/lib/python3.10/site-packages/sklearn/utils/validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for fold 2 : 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/piabaronetzky/anaconda3/envs/time-delay-embeddings/lib/python3.10/site-packages/sklearn/utils/validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/piabaronetzky/anaconda3/envs/time-delay-embeddings/lib/python3.10/site-packages/sklearn/utils/validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for fold 3 : 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/piabaronetzky/anaconda3/envs/time-delay-embeddings/lib/python3.10/site-packages/sklearn/utils/validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/piabaronetzky/anaconda3/envs/time-delay-embeddings/lib/python3.10/site-packages/sklearn/utils/validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for fold 4 : 0.9333333333333333\n",
      "Accuracy for fold 5 : 0.9636363636363636\n",
      "Average Accuracy: 0.9577272727272728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/piabaronetzky/anaconda3/envs/time-delay-embeddings/lib/python3.10/site-packages/sklearn/utils/validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n"
     ]
    }
   ],
   "source": [
    "def train_rf_cross_validation(X_train, y_train, X_test, y_test, n_estimators=900, n_folds = 5, random_state=5):\n",
    "    \"\"\"\n",
    "    Train RandomForestClassifier using cross-validation, print accuracy for each fold, and calculate average accuracy.\n",
    "    \n",
    "    Args:\n",
    "    - X_train (dict): Dictionary containing training features for each fold.\n",
    "    - y_train (dict): Dictionary containing training labels for each fold.\n",
    "    - X_test (dict): Dictionary containing validation features for each fold.\n",
    "    - y_test (dict): Dictionary containing validation labels for each fold.\n",
    "    - n_estimators (int): Number of trees in the forest (default=900).\n",
    "    - random_state (int): Random seed (default=5).\n",
    "    \n",
    "    Returns:\n",
    "    - float: Average accuracy across all folds.\n",
    "    \"\"\"\n",
    "    \n",
    "    rf = RandomForestClassifier(random_state=random_state, n_estimators=n_estimators)\n",
    "    all_accuracies = []\n",
    "\n",
    "    for fold in range(5):\n",
    "        rf.fit(X_train[fold], y_train[fold])\n",
    "        y_pred = rf.predict(X_test[fold])\n",
    "        accuracy = accuracy_score(y_pred, y_test[fold])\n",
    "        all_accuracies.append(accuracy)\n",
    "        print(\"Accuracy for fold\", fold + 1, \":\", accuracy)\n",
    "\n",
    "    average_accuracy = np.mean(all_accuracies)\n",
    "    print(\"Average Accuracy:\", average_accuracy)\n",
    "    pass\n",
    "\n",
    "train_rf_cross_validation(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ce3ff9-269c-4cd2-957d-97f599e2358c",
   "metadata": {},
   "source": [
    "## Final Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "22cf2251-60eb-474c-bc36-bf33a6016171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3644525-58b7-4c82-b8ee-f858d59e2431",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
