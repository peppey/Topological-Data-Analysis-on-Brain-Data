{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0a81b9c9-a2e9-46c2-8ae8-4a5f02dd0571",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyedflib\n",
    "import statistics\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "from gtda.time_series import SingleTakensEmbedding\n",
    "from gtda.homology import VietorisRipsPersistence\n",
    "from gtda.diagrams import PersistenceEntropy, Amplitude, NumberOfPoints, ComplexPolynomial, PersistenceLandscape, HeatKernel, Silhouette, BettiCurve, PairwiseDistance, ForgetDimension\n",
    "from gtda.plotting import plot_point_cloud, plot_heatmap, plot_diagram\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from gtda.pipeline import Pipeline \n",
    "\n",
    "\n",
    "def read_edf_file(file_path):\n",
    "    \"\"\"\n",
    "    Reads an .edf file and returns the EEG and EMG streams as pandas DataFrames.\n",
    "    \"\"\"\n",
    "    f = pyedflib.EdfReader(file_path)\n",
    "\n",
    "    # Assuming the EEG channel is the first channel and EMG is the second channel\n",
    "    eeg_signal = f.readSignal(0)\n",
    "    emg_signal = f.readSignal(1)\n",
    "\n",
    "    # Extract the channel names for the DataFrame\n",
    "    eeg_channel_name = f.getSignalLabels()[0]\n",
    "    emg_channel_name = f.getSignalLabels()[1]\n",
    "\n",
    "    # Get the sample frequency\n",
    "    sample_frequency = f.getSampleFrequency(0)  # Assuming both streams have the same frequency\n",
    "\n",
    "    # Calculate the timestamps for the samples\n",
    "    n_samples = min(len(eeg_signal), len(emg_signal))\n",
    "    time = [i / sample_frequency for i in range(n_samples)]\n",
    "\n",
    "    # Create pandas DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'Time': time,\n",
    "        eeg_channel_name: eeg_signal[:n_samples],\n",
    "        emg_channel_name: emg_signal[:n_samples],\n",
    "    })\n",
    "\n",
    "    # Close the EdfReader\n",
    "    f.close()\n",
    "\n",
    "    return df\n",
    "\n",
    "file = 'edf_293.edf'\n",
    "\n",
    "data = read_edf_file(file)\n",
    "\n",
    "\n",
    "x = data.Time\n",
    "y = data.EEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "85fd9907-0ecf-4827-bd57-da10d9c03cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels\n",
    "label_df = pd.read_csv(\"Data_293.csv\")\n",
    "labels = label_df[\"NAPS_Numeric\"].iloc[1:]\n",
    "labels = [int(label) for label in labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81daa1b7-6b26-4d6a-a46c-e28be37d6779",
   "metadata": {},
   "source": [
    "# Label List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cd9110-16dd-42ae-a665-f592c2bafd0c",
   "metadata": {},
   "source": [
    "Label 1: W (Awake)\n",
    "\n",
    "Label 2: WA (Awake Artifact)?\n",
    "\n",
    "Label 3: NR (NREM)\n",
    "\n",
    "Label 4: Not defined\n",
    "\n",
    "Label 5: R (REM)\n",
    "\n",
    "Label 7: U (Artifacts?)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ea3b4c-8747-430b-9966-2e7eaaca0b74",
   "metadata": {},
   "source": [
    "# Local Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dac52537-afd8-45ba-86a1-2f1e0dafdb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many segments per label do you want to analyze?\n",
    "no_segments = len(labels) # complete data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c2efd17e-f338-4a6f-a614-bbe3e9d83c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_dict = {}\n",
    "\n",
    "for label in list(set(labels)): \n",
    "    indices = [index for index, value in enumerate(labels) if value == label][:no_segments]\n",
    "    indices_dict[label] = indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4d599237-77e5-4221-9b79-f8a638334fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_data(df, segment_size, step_size = 2):\n",
    "    n_segments = int(df[\"Time\"].iloc[-1]) // segment_size\n",
    "    eeg_segments = []\n",
    "    emg_segments = []\n",
    "\n",
    "    for i in range(n_segments):\n",
    "        start_idx = int(i* segment_size*1000/step_size)\n",
    "        end_idx = start_idx + int(segment_size*1000/step_size)\n",
    "        segment = df.iloc[start_idx:end_idx]\n",
    "        eeg_segments.append(list(segment[\"EEG\"]))\n",
    "        emg_segments.append(list(segment[\"EMG\"]))\n",
    "\n",
    "    return eeg_segments, emg_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7696563c-9996-40dd-99bc-8ec2b960bd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment the data\n",
    "segment_length = 4  # seconds\n",
    "eeg_segments, emg_segments = segment_data(data, segment_length, step_size = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec79840c-3793-4a66-9d7f-d69e0cc90b0a",
   "metadata": {},
   "source": [
    "## Finding the optimal embedding dimension and time delay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253351f2-ad56-4641-9228-1ea72b78eb35",
   "metadata": {},
   "source": [
    "There are two techniques that can be used to determine these parameters automatically:\n",
    "- Mutual information to determine the time delay\n",
    "- False nearest neighbours to determine the embedding dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5411caea-3b14-45e6-adc5-e86f77235716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the embedding\n",
    "\n",
    "max_embedding_dimension = 30\n",
    "max_time_delay = 30\n",
    "stride = 5\n",
    "\n",
    "embedder = SingleTakensEmbedding(\n",
    "    parameters_type=\"search\",\n",
    "    time_delay=max_time_delay,\n",
    "    dimension=max_embedding_dimension,\n",
    "    stride=stride,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1cd3f263-71a8-41e8-8874-4985172c13d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_embedder(embedder: SingleTakensEmbedding, y: np.ndarray, verbose: bool=True) -> np.ndarray:\n",
    "    \"\"\"Fits a Takens embedder and displays optimal search parameters.\"\"\"\n",
    "    y_embedded = embedder.fit_transform(y)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Shape of embedded time series: {y_embedded.shape}\")\n",
    "        print(\n",
    "            f\"Optimal embedding dimension is {embedder.dimension_} and time delay is {embedder.time_delay_}\"\n",
    "        )\n",
    "\n",
    "    return y_embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "695b8367-ca0f-44da-8bdd-735a8c8794eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of embedded time series: (380, 5)\n",
      "Optimal embedding dimension is 5 and time delay is 26\n",
      "Shape of embedded time series: (383, 4)\n",
      "Optimal embedding dimension is 4 and time delay is 29\n",
      "Shape of embedded time series: (383, 5)\n",
      "Optimal embedding dimension is 5 and time delay is 22\n",
      "Shape of embedded time series: (373, 6)\n",
      "Optimal embedding dimension is 6 and time delay is 27\n"
     ]
    }
   ],
   "source": [
    "# Look at some random segments\n",
    "y_embedded = fit_embedder(embedder, eeg_segments[0])\n",
    "y_embedded = fit_embedder(embedder, eeg_segments[100])\n",
    "y_embedded = fit_embedder(embedder, eeg_segments[177])\n",
    "y_embedded = fit_embedder(embedder, eeg_segments[1000])\n",
    "# The optimal values are all similar (=> Just use embedding dimension 5 and time delay 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ae774c-2bca-448a-b292-676e26190097",
   "metadata": {},
   "source": [
    "## Creating Persistence Diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c1d6e233-e614-42cf-b4bc-e1cf83874dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting parameters for point cloud embeddings\n",
    "\n",
    "embedding_dimension= 5\n",
    "embedding_time_delay = 25\n",
    "stride = 10\n",
    "\n",
    "embedder_periodic = SingleTakensEmbedding(\n",
    "    parameters_type=\"fixed\",\n",
    "    n_jobs=2,\n",
    "    time_delay=embedding_time_delay,\n",
    "    dimension=embedding_dimension,\n",
    "    stride=stride,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1aeaf116-7c67-4b3f-849e-d827a751a0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will look at 0, 1 and 2 dimensional holes TODO try more?\n",
    "homology_dimensions = [0, 1, 2]\n",
    "\n",
    "# We will use a Vietoris Rips filtrations\n",
    "persistence = VietorisRipsPersistence(\n",
    "    homology_dimensions=homology_dimensions, n_jobs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b27aa0-db64-4d55-b188-53f3b5445523",
   "metadata": {},
   "source": [
    "### Computing Points Clouds and Persistence Diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2401965c-b159-4b12-9c08-02e89fd39713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label 1\n",
    "\n",
    "# Point cloud embeddings\n",
    "y_embedded1 = {} \n",
    "\n",
    "# Persistence diagrams\n",
    "diagrams1 = {}\n",
    "\n",
    "# Loop through the first segments with label '1'\n",
    "for label_idx in indices_dict[1]:\n",
    "    y_embedded1[label_idx] = embedder_periodic.fit_transform(eeg_segments[label_idx])[None, :, :]\n",
    "    diagrams1[label_idx] = persistence.fit_transform(y_embedded1[label_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0a057735-d761-43fd-8fb4-c1c729b0d984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label 3\n",
    "\n",
    "# Point cloud embeddings\n",
    "y_embedded3 = {} \n",
    "\n",
    "# Persistence diagrams\n",
    "diagrams3 = {}\n",
    "\n",
    "# Loop through the first segments with label '3'\n",
    "for label_idx in indices_dict[3]:\n",
    "    y_embedded3[label_idx] = embedder_periodic.fit_transform(eeg_segments[label_idx])[None, :, :]\n",
    "    diagrams3[label_idx] = persistence.fit_transform(y_embedded3[label_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2d771ce2-3ca8-4bff-a1b6-34cd36abfdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label 5\n",
    "\n",
    "# Point cloud embeddings\n",
    "y_embedded5 = {} \n",
    "\n",
    "# Persistence diagrams\n",
    "diagrams5 = {}\n",
    "\n",
    "# Loop through the first segments with label '5'\n",
    "for label_idx in indices_dict[5]:\n",
    "    y_embedded5[label_idx] = embedder_periodic.fit_transform(eeg_segments[label_idx])[None, :, :]\n",
    "    diagrams5[label_idx] = persistence.fit_transform(y_embedded5[label_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e952cace-b2fb-4586-97fb-0899d99fb509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label 7\n",
    "\n",
    "# Point cloud embeddings\n",
    "y_embedded7 = {} \n",
    "\n",
    "# Persistence diagrams\n",
    "diagrams7 = {}\n",
    "\n",
    "# Loop through the first segments with label '1'\n",
    "for label_idx in indices_dict[7]:\n",
    "    y_embedded7[label_idx] = embedder_periodic.fit_transform(eeg_segments[label_idx])[None, :, :]\n",
    "    diagrams7[label_idx] = persistence.fit_transform(y_embedded7[label_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c3e42a-c2f5-4442-8c57-bb8d07407c47",
   "metadata": {},
   "source": [
    "## Save persistence diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "01da3cb5-935d-4a2c-b491-ca2ef50fb59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "persistence_diagrams1 = [row[0] for row in diagrams1.values()]\n",
    "persistence_diagrams3 = [row[0] for row in diagrams3.values()]\n",
    "persistence_diagrams5 = [row[0] for row in diagrams5.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2f008c63-4e40-4e86-8126-67ecb0ba41a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('PD1.npy', np.array(persistence_diagrams1, dtype=object), allow_pickle=True)\n",
    "np.save('PD3.npy', np.array(persistence_diagrams3, dtype=object), allow_pickle=True)\n",
    "np.save('PD5.npy', np.array(persistence_diagrams5, dtype=object), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb59ae47-ddcc-4f8a-9a82-57100cc91ed6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
