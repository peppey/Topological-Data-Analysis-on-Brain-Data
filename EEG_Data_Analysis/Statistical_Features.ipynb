{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "0a81b9c9-a2e9-46c2-8ae8-4a5f02dd0571",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyedflib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from statsmodels.tsa import stattools\n",
    "from scipy.signal import periodogram\n",
    "import logging\n",
    "from itertools import groupby\n",
    "\n",
    "\n",
    "def read_edf_file(file_path):\n",
    "    \"\"\"\n",
    "    Reads an .edf file and returns the EEG and EMG streams as pandas DataFrames.\n",
    "    \"\"\"\n",
    "    f = pyedflib.EdfReader(file_path)\n",
    "\n",
    "    # Assuming the EEG channel is the first channel and EMG is the second channel\n",
    "    eeg_signal = f.readSignal(0)\n",
    "    emg_signal = f.readSignal(1)\n",
    "\n",
    "    # Extract the channel names for the DataFrame\n",
    "    eeg_channel_name = f.getSignalLabels()[0]\n",
    "    emg_channel_name = f.getSignalLabels()[1]\n",
    "\n",
    "    # Get the sample frequency\n",
    "    sample_frequency = f.getSampleFrequency(0)  # Assuming both streams have the same frequency\n",
    "\n",
    "    # Calculate the timestamps for the samples\n",
    "    n_samples = min(len(eeg_signal), len(emg_signal))\n",
    "    time = [i / sample_frequency for i in range(n_samples)]\n",
    "\n",
    "    # Create pandas DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'Time': time,\n",
    "        eeg_channel_name: eeg_signal[:n_samples],\n",
    "        emg_channel_name: emg_signal[:n_samples],\n",
    "    })\n",
    "\n",
    "    # Close the EdfReader\n",
    "    f.close()\n",
    "\n",
    "    return df\n",
    "\n",
    "file = 'edf_293.edf'\n",
    "\n",
    "data = read_edf_file(file)\n",
    "\n",
    "x = data.Time\n",
    "y = data.EEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb0e678-63f2-4fc8-81d4-a5fab7b6973d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "85fd9907-0ecf-4827-bd57-da10d9c03cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels\n",
    "label_df = pd.read_csv(\"Data_293.csv\")\n",
    "labels = label_df[\"NAPS_Numeric\"].iloc[1:]\n",
    "labels = [int(label) for label in labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81daa1b7-6b26-4d6a-a46c-e28be37d6779",
   "metadata": {},
   "source": [
    "# Label List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cd9110-16dd-42ae-a665-f592c2bafd0c",
   "metadata": {},
   "source": [
    "Label 1: W (Awake)\n",
    "\n",
    "Label 2: WA (Awake Artifact)?\n",
    "\n",
    "Label 3: NR (NREM)\n",
    "\n",
    "Label 4: Not defined\n",
    "\n",
    "Label 5: R (REM)\n",
    "\n",
    "Label 7: U (Artifacts?)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ea3b4c-8747-430b-9966-2e7eaaca0b74",
   "metadata": {},
   "source": [
    "# Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "dac52537-afd8-45ba-86a1-2f1e0dafdb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many segments per label do you want to analyze?\n",
    "no_segments = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "c2efd17e-f338-4a6f-a614-bbe3e9d83c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_dict = {}\n",
    "\n",
    "for label in list(set(labels)): \n",
    "    indices = [index for index, value in enumerate(labels) if value == label][:no_segments]\n",
    "    indices_dict[label] = indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "4d599237-77e5-4221-9b79-f8a638334fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_data(df, segment_size, step_size = 2):\n",
    "    n_segments = int(df[\"Time\"].iloc[-1]) // segment_size\n",
    "    eeg_segments = []\n",
    "    emg_segments = []\n",
    "\n",
    "    for i in range(n_segments):\n",
    "        start_idx = int(i* segment_size*1000/step_size)\n",
    "        end_idx = start_idx + int(segment_size*1000/step_size)\n",
    "        segment = df.iloc[start_idx:end_idx]\n",
    "        eeg_segments.append(list(segment[\"EEG\"]))\n",
    "        emg_segments.append(list(segment[\"EMG\"]))\n",
    "\n",
    "    return eeg_segments, emg_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "7696563c-9996-40dd-99bc-8ec2b960bd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment the data\n",
    "segment_length = 4  # seconds\n",
    "eeg_segments, emg_segments = segment_data(data, segment_length, step_size = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "69019e21-83ef-472a-a908-cec58fa377ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 30\n",
    "freq = 1\n",
    "lag_size = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "cb59ae47-ddcc-4f8a-9a82-57100cc91ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "means1 = []\n",
    "variance1 = []\n",
    "entropy1 = []\n",
    "lumpiness1 = []\n",
    "stability1 = []\n",
    "flat_spots1 = []\n",
    "hurst1 = []\n",
    "std_der1 = []\n",
    "crossing_points1 = []\n",
    "binarized_means1 = []\n",
    "unitroot_kpss1 = []\n",
    "heterogeneity = []\n",
    "histogram_mode = []\n",
    "linearity = []\n",
    "\n",
    "for label_idx in indices_dict[1]:\n",
    "    means1.append(statistics.mean(eeg_segments[label_idx]))\n",
    "    variance1.append(statistics.variance(eeg_segments[label_idx]))\n",
    "\n",
    "    # Entropy\n",
    "    _, psd = periodogram(eeg_segments[label_idx], freq)\n",
    "    psd_norm = psd / np.sum(psd)\n",
    "    entropy = np.nansum(psd_norm * np.log2(psd_norm))\n",
    "    entropy1.append(-(entropy / np.log2(psd_norm.size)))\n",
    "\n",
    "    # Takes too long to compute\n",
    "    # Flat Spots\n",
    "    #max_run_length = 0\n",
    "    #for i in range(0, len(x), window_size):\n",
    "    #    run_length = np.max(\n",
    "    #        [len(list(v)) for k, v in groupby(x[i : i + window_size])]\n",
    "    #)\n",
    "    #if run_length > max_run_length:\n",
    "    #    max_run_length = run_length\n",
    "\n",
    "    # Hurst\n",
    "    # Create the range of lag values\n",
    "    lags = range(2, min(lag_size, len(x) - 1))\n",
    "    # Calculate the array of the variances of the lagged differences\n",
    "    tau = [np.std(np.asarray(eeg_segments[label_idx])[lag:] - np.asarray(eeg_segments[label_idx])[:-lag]) for lag in lags]\n",
    "    # Use a linear fit to estimate the Hurst Exponent\n",
    "    poly = np.polyfit(np.log(lags), np.log(tau), 1)\n",
    "    # Return the Hurst exponent from the polyfit output\n",
    "    hurst1.append(poly[0] if not np.isnan(poly[0]) else 0)\n",
    "\n",
    "    # Standard Deviation of the first derivative\n",
    "    std_der1.append(np.std(np.gradient(eeg_segments[label_idx])))\n",
    "        \n",
    "    # Calculate the number of crossing points.\n",
    "    # Crossing points happen when a time series crosses the median line.\n",
    "    median = np.median(eeg_segments[label_idx])\n",
    "    cp = 0\n",
    "    for i in range(len(eeg_segments[label_idx]) - 1):\n",
    "        if x[i] <= median < x[i + 1] or x[i] >= median > x[i + 1]:\n",
    "            cp += 1\n",
    "    crossing_points1.append(cp)\n",
    "\n",
    "    # Binarized means\n",
    "    # Converts time series array into a binarized version.\n",
    "    # Time-series values above its mean are given 1, and those below the mean\n",
    "    # are 0. Returns the average value of the binarized vector.\n",
    "    binarized_means1.append(np.mean(np.asarray(x) > np.mean(x)))\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    lumpiness1.append(np.var([np.var(x_w) for x_w in np.array_split(eeg_segments[label_idx], len(eeg_segments[label_idx]) // window_size + 1)]))\n",
    "    stability1.append(np.var([np.mean(x_w) for x_w in np.array_split(eeg_segments[label_idx], len(eeg_segments[label_idx]) // window_size + 1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "dc9f033c-e2e1-4771-b48e-c4c062f3cc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df1 = pd.DataFrame()\n",
    "\n",
    "feature_df1[\"Mean\"] = means1\n",
    "feature_df1[\"Variance\"] = variance1\n",
    "feature_df1[\"Entropy\"] = entropy1\n",
    "feature_df1[\"Lumpiness\"] = lumpiness1\n",
    "feature_df1[\"Stability\"] = stability1\n",
    "feature_df1[\"Hurst\"] = hurst1\n",
    "feature_df1[\"STD_Derivative\"] = std_der1\n",
    "feature_df1[\"Crossing_Points\"] = crossing_points1\n",
    "feature_df1[\"Binarized_Means\"] = binarized_means1\n",
    "\n",
    "\n",
    "feature_df1[\"Label\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032c11ad-da3c-492a-89b4-0db938d7b28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "means3 = []\n",
    "variance3 = []\n",
    "entropy3 = []\n",
    "lumpiness3 = []\n",
    "stability3 = []\n",
    "hurst3 = []\n",
    "std_der3 = []\n",
    "crossing_points3 = []\n",
    "binarized_means3 = []\n",
    "\n",
    "\n",
    "for label_idx in indices_dict[3]:\n",
    "    means3.append(statistics.mean(eeg_segments[label_idx]))\n",
    "    variance3.append(statistics.variance(eeg_segments[label_idx]))\n",
    "    \n",
    "    # Entropy\n",
    "    _, psd = periodogram(eeg_segments[label_idx], freq)\n",
    "    psd_norm = psd / np.sum(psd)\n",
    "    entropy = np.nansum(psd_norm * np.log2(psd_norm))\n",
    "    entropy3.append(-(entropy / np.log2(psd_norm.size)))\n",
    "\n",
    "    # Hurst\n",
    "    # Create the range of lag values\n",
    "    lags = range(2, min(lag_size, len(x) - 1))\n",
    "    # Calculate the array of the variances of the lagged differences\n",
    "    tau = [np.std(np.asarray(eeg_segments[label_idx])[lag:] - np.asarray(eeg_segments[label_idx])[:-lag]) for lag in lags]\n",
    "    # Use a linear fit to estimate the Hurst Exponent\n",
    "    poly = np.polyfit(np.log(lags), np.log(tau), 1)\n",
    "    # Return the Hurst exponent from the polyfit output\n",
    "    hurst3.append(poly[0] if not np.isnan(poly[0]) else 0)\n",
    "\n",
    "    # Standard Deviation of the first derivative\n",
    "    std_der3.append(np.std(np.gradient(eeg_segments[label_idx])))\n",
    "\n",
    "    # Calculate the number of crossing points.\n",
    "    # Crossing points happen when a time series crosses the median line.\n",
    "    median = np.median(eeg_segments[label_idx])\n",
    "    cp = 0\n",
    "    for i in range(len(eeg_segments[label_idx]) - 1):\n",
    "        if x[i] <= median < x[i + 1] or x[i] >= median > x[i + 1]:\n",
    "            cp += 1\n",
    "    crossing_points3.append(cp)\n",
    "\n",
    "    # Binarized means\n",
    "    # Converts time series array into a binarized version.\n",
    "    # Time-series values above its mean are given 1, and those below the mean\n",
    "    # are 0. Returns the average value of the binarized vector.\n",
    "    binarized_means3.append(np.mean(np.asarray(x) > np.mean(x)))\n",
    "\n",
    "\n",
    "    \n",
    "    lumpiness3.append(np.var([np.var(x_w) for x_w in np.array_split(eeg_segments[label_idx], len(eeg_segments[label_idx]) // window_size + 1)]))\n",
    "    stability3.append(np.var([np.mean(x_w) for x_w in np.array_split(eeg_segments[label_idx], len(eeg_segments[label_idx]) // window_size + 1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c273ce10-5edc-413d-b929-f657b3acee24",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df3 = pd.DataFrame()\n",
    "\n",
    "feature_df3[\"Mean\"] = means3\n",
    "feature_df3[\"Variance\"] = variance3\n",
    "feature_df3[\"Entropy\"] = entropy3\n",
    "feature_df3[\"Lumpiness\"] = lumpiness3\n",
    "feature_df3[\"Stability\"] = stability3\n",
    "feature_df3[\"Hurst\"] = hurst3\n",
    "feature_df3[\"STD_Derivative\"] = std_der3\n",
    "feature_df3[\"Crossing_Points\"] = crossing_points3\n",
    "feature_df3[\"Binarized_Means\"] = binarized_means3\n",
    "\n",
    "\n",
    "feature_df3[\"Label\"] = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b2a28e-3a92-4100-954e-89c9b57fb165",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = pd.concat([feature_df1, feature_df3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82d601f-1a86-40eb-b090-4d29b867e93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df.to_csv(\"Statistical_Features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6c9a8d-112a-451e-8827-16fc5a2e2091",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "257522a3-afef-4af0-b82b-2d74fe873223",
   "metadata": {},
   "source": [
    "This code contains modified functions from the python package kats, which itself is only\n",
    "available for earlier Python versions.\n",
    "\n",
    "MIT License\n",
    "\n",
    "Copyright (c) Facebook, Inc. and its affiliates.\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3d8ca7-3610-48c8-861b-1c158a684b2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82009020-a884-4cc0-aaac-ff09d78a8b96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
