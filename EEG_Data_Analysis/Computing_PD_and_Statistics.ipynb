{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a81b9c9-a2e9-46c2-8ae8-4a5f02dd0571",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyedflib\n",
    "import statistics\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "from gtda.time_series import SingleTakensEmbedding\n",
    "from gtda.homology import VietorisRipsPersistence\n",
    "from gtda.diagrams import PersistenceEntropy, Amplitude, NumberOfPoints, ComplexPolynomial, PersistenceLandscape, HeatKernel, Silhouette, BettiCurve, PairwiseDistance, ForgetDimension\n",
    "from gtda.plotting import plot_point_cloud, plot_heatmap, plot_diagram\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from gtda.pipeline import Pipeline \n",
    "\n",
    "\n",
    "def read_edf_file(file_path):\n",
    "    \"\"\"\n",
    "    Reads an .edf file and returns the EEG and EMG streams as pandas DataFrames.\n",
    "    \"\"\"\n",
    "    f = pyedflib.EdfReader(file_path)\n",
    "\n",
    "    # Assuming the EEG channel is the first channel and EMG is the second channel\n",
    "    eeg_signal = f.readSignal(0)\n",
    "    emg_signal = f.readSignal(1)\n",
    "\n",
    "    # Extract the channel names for the DataFrame\n",
    "    eeg_channel_name = f.getSignalLabels()[0]\n",
    "    emg_channel_name = f.getSignalLabels()[1]\n",
    "\n",
    "    # Get the sample frequency\n",
    "    sample_frequency = f.getSampleFrequency(0)  # Assuming both streams have the same frequency\n",
    "\n",
    "    # Calculate the timestamps for the samples\n",
    "    n_samples = min(len(eeg_signal), len(emg_signal))\n",
    "    time = [i / sample_frequency for i in range(n_samples)]\n",
    "\n",
    "    # Create pandas DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'Time': time,\n",
    "        eeg_channel_name: eeg_signal[:n_samples],\n",
    "        emg_channel_name: emg_signal[:n_samples],\n",
    "    })\n",
    "\n",
    "    # Close the EdfReader\n",
    "    f.close()\n",
    "\n",
    "    return df\n",
    "\n",
    "file = 'edf_293.edf'\n",
    "\n",
    "data = read_edf_file(file)\n",
    "\n",
    "\n",
    "x = data.Time\n",
    "y = data.EEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85fd9907-0ecf-4827-bd57-da10d9c03cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels\n",
    "label_df = pd.read_csv(\"Data_293.csv\")\n",
    "labels = label_df[\"NAPS_Numeric\"].iloc[1:]\n",
    "labels = [int(label) for label in labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81daa1b7-6b26-4d6a-a46c-e28be37d6779",
   "metadata": {},
   "source": [
    "# Label List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cd9110-16dd-42ae-a665-f592c2bafd0c",
   "metadata": {},
   "source": [
    "Label 1: W (Awake)\n",
    "\n",
    "Label 2: WA (Awake Artifact)?\n",
    "\n",
    "Label 3: NR (NREM)\n",
    "\n",
    "Label 4: Not defined\n",
    "\n",
    "Label 5: R (REM)\n",
    "\n",
    "Label 7: U (Artifacts?)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ea3b4c-8747-430b-9966-2e7eaaca0b74",
   "metadata": {},
   "source": [
    "# Local Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dac52537-afd8-45ba-86a1-2f1e0dafdb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many segments per label do you want to analyze?\n",
    "no_segments = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2efd17e-f338-4a6f-a614-bbe3e9d83c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_dict = {}\n",
    "\n",
    "for label in list(set(labels)): \n",
    "    indices = [index for index, value in enumerate(labels) if value == label][:no_segments]\n",
    "    indices_dict[label] = indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d599237-77e5-4221-9b79-f8a638334fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_data(df, segment_size, step_size = 2):\n",
    "    n_segments = int(df[\"Time\"].iloc[-1]) // segment_size\n",
    "    eeg_segments = []\n",
    "    emg_segments = []\n",
    "\n",
    "    for i in range(n_segments):\n",
    "        start_idx = int(i* segment_size*1000/step_size)\n",
    "        end_idx = start_idx + int(segment_size*1000/step_size)\n",
    "        segment = df.iloc[start_idx:end_idx]\n",
    "        eeg_segments.append(list(segment[\"EEG\"]))\n",
    "        emg_segments.append(list(segment[\"EMG\"]))\n",
    "\n",
    "    return eeg_segments, emg_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7696563c-9996-40dd-99bc-8ec2b960bd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment the data\n",
    "segment_length = 4  # seconds\n",
    "eeg_segments, emg_segments = segment_data(data, segment_length, step_size = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec79840c-3793-4a66-9d7f-d69e0cc90b0a",
   "metadata": {},
   "source": [
    "## Finding the optimal embedding dimension and time delay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253351f2-ad56-4641-9228-1ea72b78eb35",
   "metadata": {},
   "source": [
    "There are two techniques that can be used to determine these parameters automatically:\n",
    "- Mutual information to determine the time delay\n",
    "- False nearest neighbours to determine the embedding dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5411caea-3b14-45e6-adc5-e86f77235716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the embedding\n",
    "\n",
    "max_embedding_dimension = 30\n",
    "max_time_delay = 30\n",
    "stride = 5\n",
    "\n",
    "embedder = SingleTakensEmbedding(\n",
    "    parameters_type=\"search\",\n",
    "    time_delay=max_time_delay,\n",
    "    dimension=max_embedding_dimension,\n",
    "    stride=stride,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cd3f263-71a8-41e8-8874-4985172c13d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_embedder(embedder: SingleTakensEmbedding, y: np.ndarray, verbose: bool=True) -> np.ndarray:\n",
    "    \"\"\"Fits a Takens embedder and displays optimal search parameters.\"\"\"\n",
    "    y_embedded = embedder.fit_transform(y)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Shape of embedded time series: {y_embedded.shape}\")\n",
    "        print(\n",
    "            f\"Optimal embedding dimension is {embedder.dimension_} and time delay is {embedder.time_delay_}\"\n",
    "        )\n",
    "\n",
    "    return y_embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "695b8367-ca0f-44da-8bdd-735a8c8794eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of embedded time series: (380, 5)\n",
      "Optimal embedding dimension is 5 and time delay is 26\n",
      "Shape of embedded time series: (383, 4)\n",
      "Optimal embedding dimension is 4 and time delay is 29\n",
      "Shape of embedded time series: (383, 5)\n",
      "Optimal embedding dimension is 5 and time delay is 22\n",
      "Shape of embedded time series: (373, 6)\n",
      "Optimal embedding dimension is 6 and time delay is 27\n"
     ]
    }
   ],
   "source": [
    "# Look at some random segments\n",
    "y_embedded = fit_embedder(embedder, eeg_segments[0])\n",
    "y_embedded = fit_embedder(embedder, eeg_segments[100])\n",
    "y_embedded = fit_embedder(embedder, eeg_segments[177])\n",
    "y_embedded = fit_embedder(embedder, eeg_segments[1000])\n",
    "# The optimal values are all similar (=> Just use embedding dimension 5 and time delay 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ae774c-2bca-448a-b292-676e26190097",
   "metadata": {},
   "source": [
    "## Creating Persistence Diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1d6e233-e614-42cf-b4bc-e1cf83874dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting parameters for point cloud embeddings\n",
    "\n",
    "embedding_dimension= 5\n",
    "embedding_time_delay = 25\n",
    "stride = 10\n",
    "\n",
    "embedder_periodic = SingleTakensEmbedding(\n",
    "    parameters_type=\"fixed\",\n",
    "    n_jobs=2,\n",
    "    time_delay=embedding_time_delay,\n",
    "    dimension=embedding_dimension,\n",
    "    stride=stride,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1aeaf116-7c67-4b3f-849e-d827a751a0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will look at 0, 1 and 2 dimensional holes TODO try more?\n",
    "homology_dimensions = [0, 1, 2]\n",
    "\n",
    "# We will use a Vietoris Rips filtrations\n",
    "persistence = VietorisRipsPersistence(\n",
    "    homology_dimensions=homology_dimensions, n_jobs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b27aa0-db64-4d55-b188-53f3b5445523",
   "metadata": {},
   "source": [
    "### Computing Points Clouds and Persistence Diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2401965c-b159-4b12-9c08-02e89fd39713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label 1\n",
    "\n",
    "# Point cloud embeddings\n",
    "y_embedded1 = {} \n",
    "\n",
    "# Persistence diagrams\n",
    "diagrams1 = {}\n",
    "\n",
    "# Loop through the first segments with label '1'\n",
    "for label_idx in indices_dict[1]:\n",
    "    y_embedded1[label_idx] = embedder_periodic.fit_transform(eeg_segments[label_idx])[None, :, :]\n",
    "    diagrams1[label_idx] = persistence.fit_transform(y_embedded1[label_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a057735-d761-43fd-8fb4-c1c729b0d984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label 3\n",
    "\n",
    "# Point cloud embeddings\n",
    "y_embedded3 = {} \n",
    "\n",
    "# Persistence diagrams\n",
    "diagrams3 = {}\n",
    "\n",
    "# Loop through the first segments with label '3'\n",
    "for label_idx in indices_dict[3]:\n",
    "    y_embedded3[label_idx] = embedder_periodic.fit_transform(eeg_segments[label_idx])[None, :, :]\n",
    "    diagrams3[label_idx] = persistence.fit_transform(y_embedded3[label_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d771ce2-3ca8-4bff-a1b6-34cd36abfdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label 5\n",
    "\n",
    "# Point cloud embeddings\n",
    "y_embedded5 = {} \n",
    "\n",
    "# Persistence diagrams\n",
    "diagrams5 = {}\n",
    "\n",
    "# Loop through the first segments with label '5'\n",
    "for label_idx in indices_dict[5]:\n",
    "    y_embedded5[label_idx] = embedder_periodic.fit_transform(eeg_segments[label_idx])[None, :, :]\n",
    "    diagrams5[label_idx] = persistence.fit_transform(y_embedded5[label_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e952cace-b2fb-4586-97fb-0899d99fb509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label 7\n",
    "\n",
    "# Point cloud embeddings\n",
    "y_embedded7 = {} \n",
    "\n",
    "# Persistence diagrams\n",
    "diagrams7 = {}\n",
    "\n",
    "# Loop through the first segments with label '1'\n",
    "for label_idx in indices_dict[7]:\n",
    "    y_embedded7[label_idx] = embedder_periodic.fit_transform(eeg_segments[label_idx])[None, :, :]\n",
    "    diagrams7[label_idx] = persistence.fit_transform(y_embedded7[label_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd32ce7-5e67-46a6-afb6-edc7a7d4190a",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b92bb533-d9f1-4db0-bdbc-46cae4b7d8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the features that we will examine for the persistence diagrams of each label\n",
    "PE = PersistenceEntropy()\n",
    "AM = Amplitude()\n",
    "NP = NumberOfPoints()\n",
    "CP = ComplexPolynomial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "22140f1c-972a-45ad-a246-326a4b302ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "persistence_entropy1 = {}\n",
    "amplitude1 = {}\n",
    "no_points1 = {}\n",
    "complex_polynomial1 = {}\n",
    "\n",
    "for label_idx in indices_dict[1]:\n",
    "    persistence_entropy1[label_idx] = PE.fit_transform(diagrams1[label_idx])\n",
    "    amplitude1[label_idx] = AM.fit_transform(diagrams1[label_idx])\n",
    "    no_points1[label_idx] = NP.fit_transform(diagrams1[label_idx])\n",
    "    complex_polynomial1[label_idx] = CP.fit_transform(diagrams1[label_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "328a2928-98ea-477e-b2a3-1796f27187f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "persistence_entropy3 = {}\n",
    "amplitude3 = {}\n",
    "no_points3 = {}\n",
    "complex_polynomial3 = {}\n",
    "\n",
    "\n",
    "for label_idx in indices_dict[3]:\n",
    "    persistence_entropy3[label_idx] = PE.fit_transform(diagrams3[label_idx])\n",
    "    amplitude3[label_idx] = AM.fit_transform(diagrams3[label_idx])\n",
    "    no_points3[label_idx] = NP.fit_transform(diagrams3[label_idx])\n",
    "    complex_polynomial3[label_idx] = CP.fit_transform(diagrams3[label_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2753354d-6938-44d7-8f97-874298212fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "persistence_entropy5 = {}\n",
    "amplitude5 = {}\n",
    "no_points5 = {}\n",
    "complex_polynomial5 = {}\n",
    "\n",
    "\n",
    "for label_idx in indices_dict[5]:\n",
    "    persistence_entropy5[label_idx] = PE.fit_transform(diagrams5[label_idx])\n",
    "    amplitude5[label_idx] = AM.fit_transform(diagrams5[label_idx])\n",
    "    no_points5[label_idx] = NP.fit_transform(diagrams5[label_idx])\n",
    "    complex_polynomial5[label_idx] = CP.fit_transform(diagrams5[label_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d34266f4-acd8-43f0-94e1-f6a3be3535cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "persistence_entropy7 = {}\n",
    "amplitude7 = {}\n",
    "no_points7 = {}\n",
    "complex_polynomial7 = {}\n",
    "\n",
    "\n",
    "for label_idx in indices_dict[7]:\n",
    "    persistence_entropy7[label_idx] = PE.fit_transform(diagrams7[label_idx])\n",
    "    amplitude7[label_idx] = AM.fit_transform(diagrams7[label_idx])\n",
    "    no_points7[label_idx] = NP.fit_transform(diagrams7[label_idx])\n",
    "    complex_polynomial7[label_idx] = CP.fit_transform(diagrams7[label_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec901fbb-6100-4f46-8b49-b8d13e2358ad",
   "metadata": {},
   "source": [
    "# Removing noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e85bbb8f-e5de-466b-a8a9-68b94e7e4b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_diagrams(flattened_diagrams, no_holes_per_dimension):\n",
    "    # no_holes_per_dimension is a list indicating how many holes for each dimension there should be left\n",
    "    shortened_diagrams = []\n",
    "\n",
    "    for diagram in flattened_diagrams: # There are no_segments many diagrams per label at max (as chosen in the beginning)\n",
    "        most_significant_holes_per_diagram = []\n",
    "        holes = {}\n",
    "        for hole_dimension, number_of_holes in zip(range(3), no_holes_per_dimension):\n",
    "            # the third entry of each point (hole) in a diagram indicates its dimensionality\n",
    "            holes[hole_dimension] = diagram[np.where(diagram[:, 2] == hole_dimension)[0]]\n",
    "\n",
    "            if number_of_holes > len(holes[hole_dimension]):\n",
    "                print(\"Watch out! There is a diagram shorter than the shortened diagrams\")\n",
    "                print(\"It has \" + str(len(holes[hole_dimension])) + \" holes of dimension \" + str(hole_dimension))\n",
    "\n",
    "            # The first and second entries of each hole indicate its birth and death, the difference is the persistence\n",
    "            large_persistence_indices = np.argsort(holes[hole_dimension][:, 0] - holes[hole_dimension][:, 1])[-number_of_holes:]\n",
    "            \n",
    "            # For each dimension, getting the holes with the above indices (the holes with the largest persistence)\n",
    "            significant_holes_with_hole_dimension = holes[hole_dimension][large_persistence_indices, :]\n",
    "            most_significant_holes_per_diagram.extend(significant_holes_with_hole_dimension)\n",
    "\n",
    "        shortened_diagrams.append(most_significant_holes_per_diagram)\n",
    "\n",
    "    return shortened_diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "07b763fb-a74d-4ea5-b905-69c7dc165135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label 1\n",
    "\n",
    "no_holes_per_dimension1 = [110, 80, 15]\n",
    "\n",
    "flattened_diagrams = []\n",
    "for key, value in diagrams1.items():\n",
    "    flattened_diagrams.append(value[0])\n",
    "\n",
    "shortened_diagrams1 = cut_diagrams(flattened_diagrams, no_holes_per_dimension1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b92f53fd-461a-42b7-9869-e9a77a05a567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label 3\n",
    "\n",
    "no_holes_per_dimension3 = [100, 68, 7]\n",
    "\n",
    "flattened_diagrams = []\n",
    "for key, value in diagrams3.items():\n",
    "    flattened_diagrams.append(value[0])\n",
    "\n",
    "shortened_diagrams3 = cut_diagrams(flattened_diagrams, no_holes_per_dimension3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4e16ae48-a3e3-4a48-85af-76257cd32ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label 5\n",
    "\n",
    "no_holes_per_dimension5 = [120, 60, 12] \n",
    "\n",
    "flattened_diagrams = []\n",
    "for key, value in diagrams5.items():\n",
    "    flattened_diagrams.append(value[0])\n",
    "\n",
    "shortened_diagrams5 = cut_diagrams(flattened_diagrams, no_holes_per_dimension5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "653e6dd0-d492-4f86-aa53-5fed72f18a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label 7\n",
    "\n",
    "# One \"outlier\" diagram only has one 2-dimensional hole\n",
    "# Later, such outliers should be deleted before computing the pairwise distances\n",
    "# between all diagrams, because eventually all diagrams should be shortened to the\n",
    "# length of the shortest diagram\n",
    "\n",
    "no_holes_per_dimension7 = [50, 9, 1] \n",
    "\n",
    "\n",
    "flattened_diagrams = []\n",
    "for key, value in diagrams7.items():\n",
    "    flattened_diagrams.append(value[0])\n",
    "\n",
    "shortened_diagrams7 = cut_diagrams(flattened_diagrams, no_holes_per_dimension7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef9b0d3-3347-454b-befa-d018ef0eac32",
   "metadata": {},
   "source": [
    "# Signatures and their Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e262908-2b56-4f7e-8c64-8b500488b882",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6175e4-00bd-443d-83af-184ea70adc10",
   "metadata": {},
   "source": [
    "## HeatKernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f076503-7c93-4873-9195-36793cf4d45a",
   "metadata": {},
   "source": [
    "In a way, the Heat Kernel shows an \"average distribution\" of the persistence diagrams for each label, seperated per hole dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dea76266-0e29-409d-92b3-a62d7b43fd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "HK = HeatKernel(sigma=0.00003, n_bins=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5366e28c-85f0-45ca-92f9-07f98151d8da",
   "metadata": {},
   "source": [
    "### Computing average intensity of the classes\n",
    "\n",
    "Does this value stay the same if I average the intensity of the single heat kernels for each PD?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db92b1fe-da54-4ca4-b40b-b5eb09c94ca2",
   "metadata": {},
   "source": [
    "Label 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f21ee4c1-5f1c-46e5-bed3-3cee654757c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatkernel = HK.fit_transform(shortened_diagrams1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9e13468b-5515-4788-bcd8-62a55ac2e98d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.200472513834635e-10\n"
     ]
    }
   ],
   "source": [
    "average_intensity1 = np.mean(heatkernel)\n",
    "print(average_intensity1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaef0d71-1e47-4c6a-9cf4-b5b6b981f8c7",
   "metadata": {},
   "source": [
    "Label 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a6545896-3526-4323-b593-e6908952e45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatkernel = HK.fit_transform(shortened_diagrams3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3f4f9812-5e6d-48d0-b4db-5744a2cec891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.141807556152343e-09\n"
     ]
    }
   ],
   "source": [
    "average_intensity3 = np.mean(heatkernel)\n",
    "print(average_intensity3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4279b179-a990-4e34-b62b-50215a00aed8",
   "metadata": {},
   "source": [
    "Label 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "799d15c0-4177-48cc-b0d9-67e705a6fd0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-7.346824363425926e-10\n"
     ]
    }
   ],
   "source": [
    "heatkernel = HK.fit_transform(shortened_diagrams5)\n",
    "\n",
    "average_intensity5 = np.mean(heatkernel)\n",
    "print(average_intensity5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4493096-9da7-44dd-9c8e-caf8370965ec",
   "metadata": {},
   "source": [
    "There is something wrong with this being negative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950a84d2-1c36-4d07-9881-8e551f7fa8f3",
   "metadata": {},
   "source": [
    "### Computing average intensity of the single PDs' heat kernels as features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "64736524-bfea-48ce-9f76-59e73aff7013",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatkernel = HK.fit_transform([shortened_diagrams3[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6d0081-5506-4009-ac47-12bcf75a438c",
   "metadata": {},
   "source": [
    "## Persistance Landscape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6fa80416-5021-4a80-ab17-6b8dab9ae2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "PL = PersistenceLandscape()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c6ce3f-c0b1-476b-b23f-bc152e3a6544",
   "metadata": {},
   "source": [
    "Label 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebab244-b14d-424b-8860-e0dff53bbea5",
   "metadata": {},
   "source": [
    "Persistence landscapes map persistence diagrams into a function space, which may often be taken to be a Banach space or even a Hilbert space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b098d888-1c0f-43fe-ad20-81f427f0b893",
   "metadata": {},
   "outputs": [],
   "source": [
    "persistence_landscape1 = PL.fit_transform(shortened_diagrams1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a68936f-995e-429e-8e45-bfa0b99c390b",
   "metadata": {},
   "source": [
    "Label 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ff49cb20-df84-438b-a158-f47dc592bf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "persistence_landscape3 = PL.fit_transform(shortened_diagrams3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a52d44-cc75-46c3-a60a-b9649e6de01b",
   "metadata": {},
   "source": [
    "Label 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8cae529e-4b85-4e95-84c7-120f72337f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "persistence_landscap5e = PL.fit_transform(shortened_diagrams5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba25a55f-fde7-4141-9212-15b73c2e4225",
   "metadata": {},
   "source": [
    "### Computing the L1 norm of the persistence landscapes for different dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa148ff-b44d-4c40-a7a6-33ba74fb0922",
   "metadata": {},
   "source": [
    "## Silhouette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c5e33f0e-0d1a-4f87-a94e-f6395289cb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SH = Silhouette()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22ea72f-1350-46cd-a1a1-6f45c40a36d8",
   "metadata": {},
   "source": [
    "Label 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "77346f99-597d-4bbe-9b48-c4a0e75af19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette1 = SH.fit_transform(shortened_diagrams1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677f8ba5-b8b7-4432-8df2-0fe77904dbce",
   "metadata": {},
   "source": [
    "Label 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0d1ec9ab-ac0e-4350-a84a-ba8e8415f68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette3 = SH.fit_transform(shortened_diagrams3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecbef81-6685-468a-a8c3-92576d2b6768",
   "metadata": {},
   "source": [
    "Label 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "838a9f94-a410-4d1d-8d10-dabe4848274c",
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette5 = SH.fit_transform(shortened_diagrams5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e3aaf9-fb85-4ac9-99c5-345879d20677",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "00c925f5-d589-47b5-a701-287ecb8c3c05",
   "metadata": {},
   "source": [
    "# Concatenate Features to one DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5866f604-799f-45f7-80e9-730fc84c68dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = pd.DataFrame(columns = [\"Label\", \"Amplitude_Dim_0\", \"Amplitude_Dim_1\", \"Amplitude_Dim_2\",  \n",
    "                                     \"Persistence Entropy_Dim_0\",  \"Persistence Entropy_Dim_1\",  \"Persistence Entropy_Dim_2\", \n",
    "                                     \"No_Points_Dim_0\", \"No_Points_Dim_1\", \"No_Points_Dim_2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "2faa621b-b1b3-4428-87e6-10f15d0364ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def column(matrix, i):\n",
    "    return [row[0][i] for row in matrix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f73d5768-ed6d-4187-b9e6-72f43fae88fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df1 = pd.DataFrame()\n",
    "\n",
    "feature_df1[\"Persistence Entropy_Dim_0\"] = column(list(persistence_entropy1.values()), 0)\n",
    "feature_df1[\"Persistence Entropy_Dim_1\"] = column(list(persistence_entropy1.values()), 1)\n",
    "feature_df1[\"Persistence Entropy_Dim_2\"] = column(list(persistence_entropy1.values()), 2)\n",
    "feature_df1[\"Amplitude_Dim_0\"] = column(list(amplitude1.values()), 0)\n",
    "feature_df1[\"Amplitude_Dim_1\"] = column(list(amplitude1.values()), 1)\n",
    "feature_df1[\"Amplitude_Dim_2\"] = column(list(amplitude1.values()), 2)\n",
    "feature_df1[\"No_Points_Dim_0\"] = column(list(no_points1.values()), 0)\n",
    "feature_df1[\"No_Points_Dim_1\"] = column(list(no_points1.values()), 1)\n",
    "feature_df1[\"No_Points_Dim_2\"] = column(list(no_points1.values()), 2)\n",
    "feature_df1[\"Label\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "a7716f67-2a11-4f05-979a-862c1f751edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df3 = pd.DataFrame()\n",
    "\n",
    "feature_df3[\"Persistence Entropy_Dim_0\"] = column(list(persistence_entropy3.values()), 0)\n",
    "feature_df3[\"Persistence Entropy_Dim_1\"] = column(list(persistence_entropy3.values()), 1)\n",
    "feature_df3[\"Persistence Entropy_Dim_2\"] = column(list(persistence_entropy3.values()), 2)\n",
    "feature_df3[\"Amplitude_Dim_0\"] = column(list(amplitude1.values()), 0)\n",
    "feature_df3[\"Amplitude_Dim_1\"] = column(list(amplitude1.values()), 1)\n",
    "feature_df3[\"Amplitude_Dim_2\"] = column(list(amplitude1.values()), 2)\n",
    "feature_df3[\"No_Points_Dim_0\"] = column(list(no_points1.values()), 0)\n",
    "feature_df3[\"No_Points_Dim_1\"] = column(list(no_points1.values()), 1)\n",
    "feature_df3[\"No_Points_Dim_2\"] = column(list(no_points1.values()), 2)\n",
    "feature_df3[\"Label\"] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "273e5219-0ca4-4fde-8ef2-bded94a33143",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = pd.concat([feature_df1, feature_df3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "c6d07977-f67a-415c-8b49-d6e583bec423",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df.to_csv(\"Features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb59ae47-ddcc-4f8a-9a82-57100cc91ed6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
