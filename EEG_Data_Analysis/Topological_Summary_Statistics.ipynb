{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a81b9c9-a2e9-46c2-8ae8-4a5f02dd0571",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyedflib\n",
    "import statistics\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "from gtda.time_series import SingleTakensEmbedding\n",
    "from gtda.homology import VietorisRipsPersistence\n",
    "from gtda.diagrams import PersistenceEntropy, Amplitude, NumberOfPoints, ComplexPolynomial, PersistenceLandscape, HeatKernel, Silhouette, BettiCurve, PairwiseDistance, ForgetDimension\n",
    "from gtda.plotting import plot_point_cloud, plot_heatmap, plot_diagram\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from gtda.pipeline import Pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c8e5867-60e2-4525-a9c4-381f9abdecf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_persistence_diagrams_label_1 = np.load(\"Embeddings_and_Persistence_Diagrams/Train_PD1.npy\", allow_pickle=True)\n",
    "test_persistence_diagrams_label_1 = np.load(\"Embeddings_and_Persistence_Diagrams/Test_PD1.npy\", allow_pickle=True)\n",
    "\n",
    "train_persistence_diagrams_label_3 = np.load(\"Embeddings_and_Persistence_Diagrams/Train_PD3.npy\", allow_pickle=True)\n",
    "test_persistence_diagrams_label_3 = np.load(\"Embeddings_and_Persistence_Diagrams/Test_PD3.npy\", allow_pickle=True)\n",
    "\n",
    "train_persistence_diagrams_label_5 = np.load(\"Embeddings_and_Persistence_Diagrams/Train_PD5.npy\", allow_pickle=True)\n",
    "test_persistence_diagrams_label_5 = np.load(\"Embeddings_and_Persistence_Diagrams/Test_PD5.npy\", allow_pickle=True)\n",
    "\n",
    "train_persistence_diagrams_label_7 = np.load(\"Embeddings_and_Persistence_Diagrams/Train_PD7.npy\", allow_pickle=True)\n",
    "test_persistence_diagrams_label_7 = np.load(\"Embeddings_and_Persistence_Diagrams/Test_PD7.npy\", allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd32ce7-5e67-46a6-afb6-edc7a7d4190a",
   "metadata": {},
   "source": [
    "# Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22140f1c-972a-45ad-a246-326a4b302ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_summary_statistics(persistence_diagrams):\n",
    "    \"\"\"\n",
    "    Compute summary statistics of list of persistence diagrams\n",
    "\n",
    "    Parameters:\n",
    "    - persistence_diagrams (list): persistence diagrams\n",
    "\n",
    "    Returns:\n",
    "    Tuple of four lists:\n",
    "    - Persistence Entropy\n",
    "    - Persistence\n",
    "    - Betti Numbers\n",
    "    - Complex Polynomials\n",
    "    \"\"\"\n",
    "    \n",
    "    PE = PersistenceEntropy()\n",
    "    AM = Amplitude()\n",
    "    NP = NumberOfPoints()\n",
    "    CP = ComplexPolynomial()\n",
    "\n",
    "    persistence_entropies = []\n",
    "    amplitudes = []\n",
    "    nos_points = []\n",
    "    complex_polynomials = []\n",
    "\n",
    "    for diagram in persistence_diagrams:\n",
    "        persistence_entropies.append(PE.fit_transform([diagram]))\n",
    "        amplitudes.append(AM.fit_transform([diagram]))\n",
    "        nos_points.append(NP.fit_transform([diagram]))\n",
    "        complex_polynomials.append(CP.fit_transform([diagram]))\n",
    "\n",
    "    return persistence_entropies, amplitudes, nos_points, complex_polynomials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8b0ab85-43ec-4357-9d46-6d4e12f063f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label 1\n",
    "train_feautures_label_1 = compute_summary_statistics(train_persistence_diagrams_label_1)\n",
    "test_feautures_label_1 = compute_summary_statistics(test_persistence_diagrams_label_1)\n",
    "\n",
    "# Label 3\n",
    "train_feautures_label_3 = compute_summary_statistics(train_persistence_diagrams_label_3)\n",
    "test_feautures_label_3 = compute_summary_statistics(test_persistence_diagrams_label_3)\n",
    "\n",
    "# Label 1\n",
    "train_feautures_label_5 = compute_summary_statistics(train_persistence_diagrams_label_5)\n",
    "test_feautures_label_5 = compute_summary_statistics(test_persistence_diagrams_label_5)\n",
    "\n",
    "# Label 1\n",
    "train_feautures_label_7 = compute_summary_statistics(train_persistence_diagrams_label_7)\n",
    "test_feautures_label_7 = compute_summary_statistics(test_persistence_diagrams_label_7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c925f5-d589-47b5-a701-287ecb8c3c05",
   "metadata": {},
   "source": [
    "# Concatenate Features to one DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2faa621b-b1b3-4428-87e6-10f15d0364ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_column_in_matrix(matrix, i):\n",
    "    return [row[0][i] for row in matrix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54d4bd2a-5a8c-4a90-ba3b-459bb13209d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_df(persistence_entropies, amplitudes, nos_points, label):\n",
    "    \"\"\"\n",
    "    Create DataFrame for each label from features\n",
    "\n",
    "    Parameters:\n",
    "    - persistence_entropies (list): persistence entropies\n",
    "    - amplitudes (list): amplitudes\n",
    "    - nos_points (list): number of points\n",
    "    - label (int): Label for which we want to create a dataframe. 1, 3, 5 or 7.\n",
    "\n",
    "    Returns:\n",
    "    - Feature DataFrame (DataFrame)\n",
    "    \"\"\"\n",
    "    \n",
    "    feature_df = pd.DataFrame()\n",
    "\n",
    "    # All 3 columns (corresponding to hole dimensions)\n",
    "    feature_df[\"Persistence Entropy_Dim_0\"] = choose_column_in_matrix(list(persistence_entropies), 0)\n",
    "    feature_df[\"Persistence Entropy_Dim_1\"] = choose_column_in_matrix(list(persistence_entropies), 1)\n",
    "    feature_df[\"Persistence Entropy_Dim_2\"] = choose_column_in_matrix(list(persistence_entropies), 2)\n",
    "\n",
    "    # All 3 columns (corresponding to hole dimensions)\n",
    "    feature_df[\"Amplitude_Dim_0\"] = choose_column_in_matrix(list(amplitudes), 0)\n",
    "    feature_df[\"Amplitude_Dim_1\"] = choose_column_in_matrix(list(amplitudes), 1)\n",
    "    feature_df[\"Amplitude_Dim_2\"] = choose_column_in_matrix(list(amplitudes), 2)\n",
    "\n",
    "    # All 3 columns (corresponding to hole dimensions)\n",
    "    feature_df[\"No_Points_Dim_0\"] = choose_column_in_matrix(list(nos_points), 0)\n",
    "    feature_df[\"No_Points_Dim_1\"] = choose_column_in_matrix(list(nos_points), 1)\n",
    "    feature_df[\"No_Points_Dim_2\"] = choose_column_in_matrix(list(nos_points), 2)\n",
    "\n",
    "    # Label\n",
    "    feature_df[\"Label\"] = label\n",
    "\n",
    "    return feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "659df5f4-0f62-4404-889f-3d29587e15af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframes for label 1\n",
    "train_df_label_1 = create_feature_df(train_feautures_label_1[0], train_feautures_label_1[1], train_feautures_label_1[2], 1)\n",
    "test_df_label_1 = create_feature_df(test_feautures_label_1[0], test_feautures_label_1[1], test_feautures_label_1[2], 1)\n",
    "\n",
    "# Create dataframes for label 3\n",
    "train_df_label_3 = create_feature_df(train_feautures_label_3[0], train_feautures_label_3[1], train_feautures_label_3[2], 1)\n",
    "test_df_label_3 = create_feature_df(test_feautures_label_3[0], test_feautures_label_3[1], test_feautures_label_3[2], 3)\n",
    "\n",
    "# Create dataframes for label 5\n",
    "train_df_label_5 = create_feature_df(train_feautures_label_5[0], train_feautures_label_5[1], train_feautures_label_5[2], 1)\n",
    "test_df_label_5 = create_feature_df(test_feautures_label_5[0], test_feautures_label_5[1], test_feautures_label_5[2], 5)\n",
    "\n",
    "# Create dataframes for label 7\n",
    "train_df_label_7 = create_feature_df(train_feautures_label_7[0], train_feautures_label_7[1], train_feautures_label_7[2], 1)\n",
    "test_df_label_7 = create_feature_df(test_feautures_label_7[0], test_feautures_label_7[1], test_feautures_label_7[2], 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "273e5219-0ca4-4fde-8ef2-bded94a33143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate and save features of training persistence diagrams\n",
    "train_feature_df = pd.concat([train_df_label_1, train_df_label_3, train_df_label_5, train_df_label_7])\n",
    "train_feature_df.to_csv(\"Features/Train_Topological_Summary_Statistics.csv\")\n",
    "\n",
    "# Concatenate and save features of training persistence diagrams\n",
    "test_feature_df = pd.concat([test_df_label_1, test_df_label_3, test_df_label_5, test_df_label_7])\n",
    "test_feature_df.to_csv(\"Features/Test_Topological_Summary_Statistics.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d07977-f67a-415c-8b49-d6e583bec423",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb59ae47-ddcc-4f8a-9a82-57100cc91ed6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8920b05c-d0c1-4ae7-b380-f15eb4ebd0df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
