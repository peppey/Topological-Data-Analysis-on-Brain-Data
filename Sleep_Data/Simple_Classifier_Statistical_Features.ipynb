{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e9f3ffa4-2d95-4158-8ac6-92b145e05e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "from sklearn.utils import shuffle\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import Utils.Time_Series_Classification_Helpers as ts_helpers\n",
    "import Utils.Classification_Helpers as helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebc64c0d-6d6c-4763-9df3-2e548c0e5e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)  # Use 'None' to display all columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa49ecfc-b04c-45b5-a328-6ff826897526",
   "metadata": {},
   "source": [
    "# Set up MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "552878fa-4803-4f83-8277-7c0ff79a90ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start MLFlow\n",
    "#!mlflow server --host 127.0.0.1 --port 8080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfebd2bd-c2ae-4213-92be-9d14b32128a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:8080\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96ef8fb-0483-47c0-a098-4765de47b4f5",
   "metadata": {},
   "source": [
    "# Import and Concatenate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44894145-e4db-4240-8466-9ff4fa84392e",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_list = [\"293\", \"294\", \"298\"]\n",
    "label_list  = [1, 2, 3, 4, 5, 7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6f9205-932a-417c-b6ff-d92f746b710d",
   "metadata": {},
   "source": [
    "## Dataframes that do not depend on folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "941a6283-a863-4098-bd77-4dffcaffb3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_and_concatenate_datasets(subject_list, list_of_filenames, parent_directory):\n",
    "    \"\"\"\n",
    "    Import and concatenate feature datasets for each subject.\n",
    "\n",
    "    Args:\n",
    "    - subject_list (list): List of subject names.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: Concatenated feature DataFrame.\n",
    "    - list: List of all labels.\n",
    "    \"\"\"\n",
    "    subject_feature_dfs = {}\n",
    "\n",
    "    for subject_idx, subject in enumerate(subject_list):\n",
    "        subject_feature_dfs[subject] = pd.DataFrame()\n",
    "\n",
    "        for data_type in [\"EEG\", \"EMG\"]:\n",
    "            data_frames = []\n",
    "\n",
    "            for file in list_of_filenames:\n",
    "                path = os.path.join(str(parent_directory), \"Features\", str(subject), str(data_type), file)\n",
    "                if os.path.exists(path):\n",
    "                    data_frames.append(pd.read_csv(path))\n",
    "\n",
    "            df_both_data_types = pd.concat(data_frames, axis=1)\n",
    "\n",
    "            if not subject_feature_dfs[subject].empty:\n",
    "                subject_feature_dfs[subject] = pd.concat([subject_feature_dfs[subject], df_both_data_types], axis=1).drop(columns=['Unnamed: 0'], inplace=False)\n",
    "                subject_feature_dfs[subject] = helpers.keep_first_duplicate_columns(subject_feature_dfs[subject])\n",
    "            else:\n",
    "                df_both_data_types = helpers.keep_first_duplicate_columns(df_both_data_types)\n",
    "                subject_feature_dfs[subject] = df_both_data_types.drop(columns=['Unnamed: 0'], inplace=False)\n",
    "\n",
    "        subject_feature_dfs[subject][\"Subject\"] = subject_idx\n",
    "\n",
    "    feature_df = pd.concat(subject_feature_dfs.values(), ignore_index=True)\n",
    "\n",
    "    # For duplicate columns, only keep one\n",
    "    feature_df = helpers.keep_first_duplicate_columns(feature_df)\n",
    "    \n",
    "    return feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a2209dc-3870-4f09-b6aa-e46f50298cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_filenames = [\"Statistical_Features_KATS_Statistics.csv\", \"Statistical_Features_Additional_Features.csv\", \"Statistical_Features_Level_Shift_Features.csv\", \"Statistical_Features_Autocorrelation_Features.csv\"]\n",
    "\n",
    "feature_df = import_and_concatenate_datasets(subject_list, list_of_filenames, parent_directory = \"\")\n",
    "\n",
    "all_labels = feature_df[\"Label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13c4ac3-9d48-4ab1-a76c-93168323ade0",
   "metadata": {},
   "source": [
    "# Experiments with Single Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eafcd9c0-7e26-4dc1-8bca-4ce7b1df4bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 56 features in the main dataframe.\n"
     ]
    }
   ],
   "source": [
    "print(\"There are \"+str(len(feature_df.columns))+\" features in the main dataframe.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069fcb66-1b39-4cc4-8106-8bebe6898c68",
   "metadata": {},
   "source": [
    "## Save features for Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72ad0052-bb36-460a-8e57-e6525645b850",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df.to_csv(\"Features/All_Features.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c438e6-7241-4d14-b4d5-0b2243f636b3",
   "metadata": {},
   "source": [
    "## Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b91f048c-41a3-4423-a588-776234da857e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There now are 56 features in the main dataframe.\n"
     ]
    }
   ],
   "source": [
    "list_of_strings_in_column_name = [\"Nothing\"]\n",
    "\n",
    "feature_df = helpers.remove_columns_with_str(feature_df, list_of_strings_in_column_name)\n",
    "\n",
    "print(\"There now are \"+str(len(feature_df.columns))+\" features in the main dataframe.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6cf73d-4845-4a3f-ab50-74282e118ba8",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a17cb31f-aff2-4dc6-9924-16ffac33e76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d3ba5fe-33ba-43fa-b903-60030ad7442d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO This can be in the helper file as well\n",
    "train_indices, validation_indices, test_indices = helpers.load_folds(subject_list, parent_directory = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ce54a8e-a97a-4744-a908-c79c71cd2dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_dfs_all_folds, train_labels_all_folds = helpers.filter_dataframe_with_indices(feature_df, train_indices, label_list)\n",
    "validation_features_dfs_all_folds, validation_labels_all_folds = helpers.filter_dataframe_with_indices(feature_df, validation_indices, label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9bf2cc5b-770b-4ddc-835e-744e33435e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train and validation sets\n",
    "# TO DO What is this step for?\n",
    "X_train, y_train, X_test, y_test = helpers.initialize_fold_dicts(train_features_dfs_all_folds, train_labels_all_folds, validation_features_dfs_all_folds, validation_labels_all_folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3e5d46-116c-4bd9-9a01-b71d2798616d",
   "metadata": {},
   "source": [
    "# MLFLow & Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14ba4f04-3db8-4cc8-a980-6a20407b2769",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices, validation_indices, test_indices = helpers.load_folds(subject_list, parent_directory=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc9505f5-a263-4f11-9d1e-ac4cff6c8c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_X  = pd.concat([X_train[0], X_test[0]], ignore_index=True)\n",
    "\n",
    "concatenated_y = y_train[0] + y_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b97438-9ecb-463f-af84-dee90a7fe26e",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e835c78c-3ed2-4158-bbbd-8f322b20f813",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "196b78ed-d4d3-4f16-a09c-a5c2b3ee9c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV 1/5] END max_depth=40, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.909 total time=   1.4s\n",
      "[CV 2/5] END max_depth=40, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.916 total time=   1.3s\n",
      "[CV 3/5] END max_depth=40, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.913 total time=   1.3s\n",
      "[CV 4/5] END max_depth=40, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.914 total time=   1.4s\n",
      "[CV 5/5] END max_depth=40, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.917 total time=   1.4s\n",
      "[CV 1/5] END max_depth=40, min_samples_leaf=1, min_samples_split=2, n_estimators=150;, score=0.913 total time=   2.0s\n",
      "[CV 2/5] END max_depth=40, min_samples_leaf=1, min_samples_split=2, n_estimators=150;, score=0.920 total time=   2.0s\n",
      "[CV 3/5] END max_depth=40, min_samples_leaf=1, min_samples_split=2, n_estimators=150;, score=0.912 total time=   2.0s\n",
      "[CV 4/5] END max_depth=40, min_samples_leaf=1, min_samples_split=2, n_estimators=150;, score=0.915 total time=   2.0s\n",
      "[CV 5/5] END max_depth=40, min_samples_leaf=1, min_samples_split=2, n_estimators=150;, score=0.917 total time=   2.1s\n",
      "[CV 1/5] END max_depth=50, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.909 total time=   1.4s\n",
      "[CV 2/5] END max_depth=50, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.916 total time=   1.4s\n",
      "[CV 3/5] END max_depth=50, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.913 total time=   1.4s\n",
      "[CV 4/5] END max_depth=50, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.914 total time=   1.4s\n",
      "[CV 5/5] END max_depth=50, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.917 total time=   1.4s\n",
      "[CV 1/5] END max_depth=50, min_samples_leaf=1, min_samples_split=2, n_estimators=150;, score=0.913 total time=   2.0s\n",
      "[CV 2/5] END max_depth=50, min_samples_leaf=1, min_samples_split=2, n_estimators=150;, score=0.920 total time=   2.1s\n",
      "[CV 3/5] END max_depth=50, min_samples_leaf=1, min_samples_split=2, n_estimators=150;, score=0.912 total time=   2.1s\n",
      "[CV 4/5] END max_depth=50, min_samples_leaf=1, min_samples_split=2, n_estimators=150;, score=0.915 total time=   2.1s\n",
      "[CV 5/5] END max_depth=50, min_samples_leaf=1, min_samples_split=2, n_estimators=150;, score=0.917 total time=   2.1s\n",
      "[CV 1/5] END max_depth=60, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.909 total time=   1.4s\n",
      "[CV 2/5] END max_depth=60, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.916 total time=   1.3s\n",
      "[CV 3/5] END max_depth=60, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.913 total time=   1.3s\n",
      "[CV 4/5] END max_depth=60, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.914 total time=   1.4s\n",
      "[CV 5/5] END max_depth=60, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.917 total time=   1.4s\n",
      "[CV 1/5] END max_depth=60, min_samples_leaf=1, min_samples_split=2, n_estimators=150;, score=0.913 total time=   2.1s\n",
      "[CV 2/5] END max_depth=60, min_samples_leaf=1, min_samples_split=2, n_estimators=150;, score=0.920 total time=   2.0s\n",
      "[CV 3/5] END max_depth=60, min_samples_leaf=1, min_samples_split=2, n_estimators=150;, score=0.912 total time=   2.1s\n",
      "[CV 4/5] END max_depth=60, min_samples_leaf=1, min_samples_split=2, n_estimators=150;, score=0.915 total time=   2.1s\n",
      "[CV 5/5] END max_depth=60, min_samples_leaf=1, min_samples_split=2, n_estimators=150;, score=0.917 total time=   2.1s\n",
      "Best Parameters: {'max_depth': 40, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 150}\n",
      "Best Score: 0.9152838224900494\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Main parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 400],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [2, 4, 6]\n",
    "}\n",
    "\n",
    "# Result: params = {'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}\n",
    "\n",
    "# Another parameter grid for finer tuning \n",
    "param_grid = {\n",
    "    'n_estimators': [150, 200, 250],\n",
    "    'max_depth': [20, 30, 40],\n",
    "    'min_samples_split': [2],\n",
    "    'min_samples_leaf': [1, 2, 3]\n",
    "}\n",
    "\n",
    "# Result: params = {'max_depth': 40, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 150}\n",
    "\n",
    "\n",
    "# Another parameter grid for finer tuning \n",
    "param_grid = {\n",
    "    'n_estimators': [100, 150],\n",
    "    'max_depth': [40, 50, 60],\n",
    "    'min_samples_split': [2],\n",
    "    'min_samples_leaf': [1]\n",
    "}\n",
    "\n",
    "# Result: params =  {'max_depth': 40, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 150}\n",
    "\n",
    "rf = RandomForestClassifier(random_state = 42)\n",
    "\n",
    "grid_search = GridSearchCV(rf, param_grid, cv=5, scoring='accuracy', verbose = 3)\n",
    "\n",
    "grid_search.fit(concatenated_X, concatenated_y)\n",
    "\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5bf79035-a8a9-4c0a-a26c-30bc5b691a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/piabaronetzky/anaconda3/envs/time-delay-embeddings/lib/python3.10/site-packages/sklearn/utils/validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/piabaronetzky/anaconda3/envs/time-delay-embeddings/lib/python3.10/site-packages/sklearn/utils/validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/piabaronetzky/anaconda3/envs/time-delay-embeddings/lib/python3.10/site-packages/sklearn/utils/validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for fold 1 : 0.906951871657754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/piabaronetzky/anaconda3/envs/time-delay-embeddings/lib/python3.10/site-packages/sklearn/utils/validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/piabaronetzky/anaconda3/envs/time-delay-embeddings/lib/python3.10/site-packages/sklearn/utils/validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for fold 2 : 0.9119226638023631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/piabaronetzky/anaconda3/envs/time-delay-embeddings/lib/python3.10/site-packages/sklearn/utils/validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/piabaronetzky/anaconda3/envs/time-delay-embeddings/lib/python3.10/site-packages/sklearn/utils/validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for fold 3 : 0.9149623250807319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/piabaronetzky/anaconda3/envs/time-delay-embeddings/lib/python3.10/site-packages/sklearn/utils/validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/piabaronetzky/anaconda3/envs/time-delay-embeddings/lib/python3.10/site-packages/sklearn/utils/validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for fold 4 : 0.9168466522678186\n",
      "Accuracy for fold 5 : 0.9119565217391304\n",
      "Average Accuracy: 0.9125280069095597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/piabaronetzky/anaconda3/envs/time-delay-embeddings/lib/python3.10/site-packages/sklearn/utils/validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n"
     ]
    }
   ],
   "source": [
    "import math \n",
    "\n",
    "params = {\"random_state\": 42, \"n_estimators\": 500, \"min_samples_split\": 2}\n",
    "rf = RandomForestClassifier(**params)\n",
    "all_accuracies = []\n",
    "\n",
    "for fold in range(5):\n",
    "    rf.fit(X_train[fold], y_train[fold])\n",
    "    y_pred = rf.predict(X_test[fold])\n",
    "    accuracy = accuracy_score(y_pred, y_test[fold])\n",
    "    all_accuracies.append(accuracy)\n",
    "    print(\"Accuracy for fold\", fold + 1, \":\", accuracy)\n",
    "\n",
    "average_accuracy = np.mean(all_accuracies)\n",
    "print(\"Average Accuracy:\", average_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "aa405cc4-7154-426f-a02b-39dc07bf0139",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow_params = params\n",
    "features = X_train[0].columns\n",
    "mlflow_params[\"features\"] = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fef990b7-24b4-4a21-8d16-80fa7a523e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Start an MLflow run\n",
    "with mlflow.start_run():\n",
    "    # Log the hyperparameters\n",
    "    mlflow.log_params(mlflow_params)\n",
    "\n",
    "    # Log the loss metric\n",
    "    mlflow.log_metric(\"accuracy\", average_accuracy)\n",
    "    mlflow.log_metric(\"minimal accuracy\",  np.min(all_accuracies))\n",
    "    mlflow.log_metric(\"maximal accuracy\",  np.max(all_accuracies))\n",
    "\n",
    "\n",
    "    # Set a tag that we can use to remind ourselves what this run was for\n",
    "    mlflow.set_tag(\"Training Info\", \"Random Forest Sleep Data\")\n",
    "\n",
    "    # Infer the model signature\n",
    "    signature = infer_signature(X_train[fold].values, rf.predict(X_train[fold].values))\n",
    "\n",
    "    # Log the model\n",
    "    model_info = mlflow.sklearn.log_model(\n",
    "        sk_model=rf,\n",
    "        artifact_path=\"random_forest-sleep-data\",\n",
    "        signature=signature,\n",
    "        input_example=X_train[fold],\n",
    "        registered_model_name=\"random_forest-sleep-data\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cc605d-75f0-4331-a1ab-f42e778386b7",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb178914-5730-419e-8978-a9dfc26f66b0",
   "metadata": {},
   "source": [
    "### GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "faf609a8-80fb-4aba-b7a9-089b773f0f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5] END learning_rate=0.18, max_depth=7, min_child_weight=0, n_estimators=600, subsample=0.5;, score=0.913 total time=  32.9s\n",
      "[CV 2/5] END learning_rate=0.18, max_depth=7, min_child_weight=0, n_estimators=600, subsample=0.5;, score=0.917 total time=  31.5s\n",
      "[CV 3/5] END learning_rate=0.18, max_depth=7, min_child_weight=0, n_estimators=600, subsample=0.5;, score=0.921 total time=  29.6s\n",
      "[CV 4/5] END learning_rate=0.18, max_depth=7, min_child_weight=0, n_estimators=600, subsample=0.5;, score=0.918 total time=  29.6s\n",
      "[CV 5/5] END learning_rate=0.18, max_depth=7, min_child_weight=0, n_estimators=600, subsample=0.5;, score=0.917 total time=  35.3s\n",
      "[CV 1/5] END learning_rate=0.18, max_depth=8, min_child_weight=0, n_estimators=600, subsample=0.5;, score=0.912 total time=  37.8s\n",
      "[CV 2/5] END learning_rate=0.18, max_depth=8, min_child_weight=0, n_estimators=600, subsample=0.5;, score=0.917 total time=  33.8s\n",
      "[CV 3/5] END learning_rate=0.18, max_depth=8, min_child_weight=0, n_estimators=600, subsample=0.5;, score=0.927 total time=  36.0s\n",
      "[CV 4/5] END learning_rate=0.18, max_depth=8, min_child_weight=0, n_estimators=600, subsample=0.5;, score=0.917 total time=  32.1s\n",
      "[CV 5/5] END learning_rate=0.18, max_depth=8, min_child_weight=0, n_estimators=600, subsample=0.5;, score=0.917 total time=  34.1s\n",
      "[CV 1/5] END learning_rate=0.18, max_depth=9, min_child_weight=0, n_estimators=600, subsample=0.5;, score=0.911 total time=  37.0s\n",
      "[CV 2/5] END learning_rate=0.18, max_depth=9, min_child_weight=0, n_estimators=600, subsample=0.5;, score=0.917 total time=  36.0s\n",
      "[CV 3/5] END learning_rate=0.18, max_depth=9, min_child_weight=0, n_estimators=600, subsample=0.5;, score=0.923 total time=  39.1s\n",
      "[CV 4/5] END learning_rate=0.18, max_depth=9, min_child_weight=0, n_estimators=600, subsample=0.5;, score=0.918 total time=  36.1s\n",
      "[CV 5/5] END learning_rate=0.18, max_depth=9, min_child_weight=0, n_estimators=600, subsample=0.5;, score=0.914 total time=  38.5s\n",
      "[CV 1/5] END learning_rate=0.19, max_depth=7, min_child_weight=0, n_estimators=600, subsample=0.5;, score=0.913 total time=  28.0s\n",
      "[CV 2/5] END learning_rate=0.19, max_depth=7, min_child_weight=0, n_estimators=600, subsample=0.5;, score=0.915 total time=  28.1s\n",
      "[CV 3/5] END learning_rate=0.19, max_depth=7, min_child_weight=0, n_estimators=600, subsample=0.5;, score=0.921 total time=  28.5s\n",
      "[CV 4/5] END learning_rate=0.19, max_depth=7, min_child_weight=0, n_estimators=600, subsample=0.5;, score=0.919 total time=  30.7s\n",
      "[CV 5/5] END learning_rate=0.19, max_depth=7, min_child_weight=0, n_estimators=600, subsample=0.5;, score=0.917 total time=  29.7s\n",
      "[CV 1/5] END learning_rate=0.19, max_depth=8, min_child_weight=0, n_estimators=600, subsample=0.5;, score=0.917 total time=  33.5s\n",
      "[CV 2/5] END learning_rate=0.19, max_depth=8, min_child_weight=0, n_estimators=600, subsample=0.5;, score=0.919 total time=  34.7s\n",
      "[CV 3/5] END learning_rate=0.19, max_depth=8, min_child_weight=0, n_estimators=600, subsample=0.5;, score=0.922 total time=  31.3s\n",
      "[CV 4/5] END learning_rate=0.19, max_depth=8, min_child_weight=0, n_estimators=600, subsample=0.5;, score=0.920 total time=  32.1s\n",
      "[CV 5/5] END learning_rate=0.19, max_depth=8, min_child_weight=0, n_estimators=600, subsample=0.5;, score=0.917 total time=  33.1s\n",
      "[CV 1/5] END learning_rate=0.19, max_depth=9, min_child_weight=0, n_estimators=600, subsample=0.5;, score=0.915 total time=  37.6s\n",
      "[CV 2/5] END learning_rate=0.19, max_depth=9, min_child_weight=0, n_estimators=600, subsample=0.5;, score=0.922 total time=  37.3s\n",
      "[CV 3/5] END learning_rate=0.19, max_depth=9, min_child_weight=0, n_estimators=600, subsample=0.5;, score=0.922 total time=  35.7s\n",
      "[CV 4/5] END learning_rate=0.19, max_depth=9, min_child_weight=0, n_estimators=600, subsample=0.5;, score=0.916 total time=  35.5s\n",
      "[CV 5/5] END learning_rate=0.19, max_depth=9, min_child_weight=0, n_estimators=600, subsample=0.5;, score=0.917 total time=  37.1s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=7, min_child_weight=0, n_estimators=600, subsample=0.5;, score=0.914 total time=  28.0s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=7, min_child_weight=0, n_estimators=600, subsample=0.5;, score=0.918 total time=  28.5s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=7, min_child_weight=0, n_estimators=600, subsample=0.5;, score=0.921 total time=  32.2s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=7, min_child_weight=0, n_estimators=600, subsample=0.5;, score=0.916 total time=  29.5s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=7, min_child_weight=0, n_estimators=600, subsample=0.5;, score=0.918 total time=  28.7s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=8, min_child_weight=0, n_estimators=600, subsample=0.5;, score=0.913 total time=  33.1s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=8, min_child_weight=0, n_estimators=600, subsample=0.5;, score=0.920 total time=  32.8s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=8, min_child_weight=0, n_estimators=600, subsample=0.5;, score=0.919 total time=  31.7s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=8, min_child_weight=0, n_estimators=600, subsample=0.5;, score=0.915 total time=  33.5s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=8, min_child_weight=0, n_estimators=600, subsample=0.5;, score=0.917 total time=  36.9s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=9, min_child_weight=0, n_estimators=600, subsample=0.5;, score=0.913 total time=  39.1s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=9, min_child_weight=0, n_estimators=600, subsample=0.5;, score=0.921 total time=  41.4s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=9, min_child_weight=0, n_estimators=600, subsample=0.5;, score=0.922 total time=  40.1s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=9, min_child_weight=0, n_estimators=600, subsample=0.5;, score=0.919 total time=  43.1s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=9, min_child_weight=0, n_estimators=600, subsample=0.5;, score=0.918 total time=  36.1s\n",
      "Best Parameters: {'learning_rate': 0.19, 'max_depth': 8, 'min_child_weight': 0, 'n_estimators': 600, 'subsample': 0.5}\n",
      "Best Score: 0.9191631328348772\n"
     ]
    }
   ],
   "source": [
    "# Main parameter grid for finetuning after first manual experiments\n",
    "param_grid = {\n",
    "    \"learning_rate\": [0.19, 0.21, 0.23],\n",
    "    \"n_estimators\": [400, 500, 600],\n",
    "    \"max_depth\": [5, 8, 15],\n",
    "    \"min_child_weight\": [0],\n",
    "    \"subsample\": [0.5]\n",
    "}\n",
    "\n",
    "# Result: {'learning_rate': 0.19, 'max_depth': 8, 'min_child_weight': 0, 'n_estimators': 600, 'subsample': 0.5}\n",
    "\n",
    "# Another parameter grid for finer tuning\n",
    "param_grid = {\n",
    "    \"learning_rate\": [0.18, 0.19, 0.2],\n",
    "    \"n_estimators\": [600],\n",
    "    \"max_depth\": [7, 8, 9],\n",
    "    \"min_child_weight\": [0],\n",
    "    \"subsample\": [0.5]\n",
    "}\n",
    "\n",
    "# Result: {'learning_rate': 0.19, 'max_depth': 8, 'min_child_weight': 0, 'n_estimators': 600, 'subsample': 0.5}\n",
    "\n",
    "\n",
    "xb = xgb.XGBClassifier(seed=1)\n",
    "\n",
    "# GridSearchCV\n",
    "grid_search = GridSearchCV(xb, param_grid, cv=5, scoring='accuracy', verbose = 3)\n",
    "\n",
    "grid_search.fit(concatenated_X, concatenated_y)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9d52970d-aba8-46b3-8848-406df4bc6762",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m mapping \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m1\u001b[39m: \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m: \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m: \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m4\u001b[39m: \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m5\u001b[39m: \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m7\u001b[39m: \u001b[38;5;241m5\u001b[39m}\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fold \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m----> 5\u001b[0m     y_train[fold] \u001b[38;5;241m=\u001b[39m [mapping[num] \u001b[38;5;28;01mfor\u001b[39;00m num \u001b[38;5;129;01min\u001b[39;00m y_train[fold]]\n\u001b[1;32m      6\u001b[0m     y_test[fold] \u001b[38;5;241m=\u001b[39m [mapping[num] \u001b[38;5;28;01mfor\u001b[39;00m num \u001b[38;5;129;01min\u001b[39;00m y_test[fold]]\n",
      "Cell \u001b[0;32mIn[55], line 5\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m mapping \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m1\u001b[39m: \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m: \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m: \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m4\u001b[39m: \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m5\u001b[39m: \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m7\u001b[39m: \u001b[38;5;241m5\u001b[39m}\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fold \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m----> 5\u001b[0m     y_train[fold] \u001b[38;5;241m=\u001b[39m [\u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnum\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m num \u001b[38;5;129;01min\u001b[39;00m y_train[fold]]\n\u001b[1;32m      6\u001b[0m     y_test[fold] \u001b[38;5;241m=\u001b[39m [mapping[num] \u001b[38;5;28;01mfor\u001b[39;00m num \u001b[38;5;129;01min\u001b[39;00m y_test[fold]]\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "# Change the labels to adequate labels for XGBoost\n",
    "mapping = {1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 7: 5}\n",
    "\n",
    "for fold in range(5):\n",
    "    y_train[fold] = [mapping[num] for num in y_train[fold]]\n",
    "    y_test[fold] = [mapping[num] for num in y_test[fold]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "11f77b40-9ae1-448d-970c-5353dcc84934",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 12\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fold \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X_train)):\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# Remove duplicate columns\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     X_train[fold] \u001b[38;5;241m=\u001b[39m helpers\u001b[38;5;241m.\u001b[39mkeep_first_duplicate_columns(X_train[fold])\n\u001b[0;32m---> 12\u001b[0m     \u001b[43mxb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfold\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfold\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     X_test[fold] \u001b[38;5;241m=\u001b[39m X_test[fold]\u001b[38;5;241m.\u001b[39mloc[:, \u001b[38;5;241m~\u001b[39mX_test[fold]\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mduplicated()]\n\u001b[1;32m     16\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m xb\u001b[38;5;241m.\u001b[39mpredict(X_test[fold])\n",
      "File \u001b[0;32m~/anaconda3/envs/time-delay-embeddings/lib/python3.10/site-packages/xgboost/core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    728\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 729\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/time-delay-embeddings/lib/python3.10/site-packages/xgboost/sklearn.py:1515\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1487\u001b[0m (\n\u001b[1;32m   1488\u001b[0m     model,\n\u001b[1;32m   1489\u001b[0m     metric,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1494\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m   1495\u001b[0m )\n\u001b[1;32m   1496\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1497\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[1;32m   1498\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1512\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[1;32m   1513\u001b[0m )\n\u001b[0;32m-> 1515\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1518\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1519\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1521\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1523\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1524\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1525\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1526\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/time-delay-embeddings/lib/python3.10/site-packages/xgboost/core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    728\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 729\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/time-delay-embeddings/lib/python3.10/site-packages/xgboost/training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/time-delay-embeddings/lib/python3.10/site-packages/xgboost/core.py:2050\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   2046\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[1;32m   2048\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2049\u001b[0m     _check_call(\n\u001b[0;32m-> 2050\u001b[0m         \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2051\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\n\u001b[1;32m   2052\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2053\u001b[0m     )\n\u001b[1;32m   2054\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2055\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "params = {\"seed\": 1, \"learning_rate\": 0.2, \"n_estimators\": 500, \"max_depth\": 15, \"min_child_weight\": 0, \"subsample\":0.5}\n",
    "\n",
    "#params = best_params\n",
    "xb = xgb.XGBClassifier(**params)\n",
    "all_accuracies = []\n",
    "all_feature_importances = []\n",
    "\n",
    "for fold in range(len(X_train)):\n",
    "    # Remove duplicate columns\n",
    "    X_train[fold] = helpers.keep_first_duplicate_columns(X_train[fold])\n",
    "\n",
    "    xb.fit(X_train[fold], y_train[fold])\n",
    "\n",
    "    X_test[fold] = X_test[fold].loc[:, ~X_test[fold].columns.duplicated()]\n",
    "\n",
    "    y_pred = xb.predict(X_test[fold])\n",
    "    accuracy = accuracy_score(y_pred, y_test[fold])\n",
    "    all_accuracies.append(accuracy)\n",
    "    print(\"Accuracy for fold\", accuracy)\n",
    "\n",
    "    # Get feature importances for the current fold\n",
    "    feature_importances = xb.feature_importances_\n",
    "    all_feature_importances.append(feature_importances)\n",
    "\n",
    "average_accuracy = np.mean(all_accuracies)\n",
    "print(\"Mean Accuracy:\", average_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8dfc6b3-5291-4298-957e-998f1f2ceccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start an MLflow run\n",
    "with mlflow.start_run():\n",
    "    # Log the hyperparameters\n",
    "    mlflow.log_params(mlflow_params)\n",
    "\n",
    "    # Log the loss metric\n",
    "    mlflow.log_metric(\"accuracy\", average_accuracy)\n",
    "    mlflow.log_metric(\"minimal accuracy\",  np.min(all_accuracies))\n",
    "    mlflow.log_metric(\"maximal accuracy\",  np.max(all_accuracies))\n",
    "\n",
    "\n",
    "    # Set a tag that we can use to remind ourselves what this run was for\n",
    "    mlflow.set_tag(\"Training Info\", \"XGBoost Sleep Data\")\n",
    "\n",
    "    # Infer the model signature\n",
    "    signature = infer_signature(X_train[fold].values, rf.predict(X_train[fold].values))\n",
    "\n",
    "    # Log the model\n",
    "    model_info = mlflow.sklearn.log_model(\n",
    "        sk_model=rf,\n",
    "        artifact_path=\"xgboost-sleep-data\",\n",
    "        signature=signature,\n",
    "        input_example=X_train[fold],\n",
    "        registered_model_name=\"xgboost-sleep-data\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bb8455-03c8-4334-8635-5de6e00e0845",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e85d4ab5-f68b-44fc-9b7c-539ae2e1b378",
   "metadata": {},
   "source": [
    "# Final Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1730e067-6c82-43f3-989a-3a79a35f5943",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_final_training_and_test_indices(train_indices, validation_indices, subject_list, label_list):\n",
    "    \"\"\"\n",
    "    The new training data consists of the previous training plus the previous validation data\n",
    "    \"\"\"\n",
    "\n",
    "    final_train_indices = {}\n",
    "\n",
    "    for subject in subject_list:\n",
    "\n",
    "        # Initialize\n",
    "        final_train_indices[subject] = {}\n",
    "        \n",
    "        train_indices_for_subject = train_indices[subject]\n",
    "        validation_indices_for_subject = validation_indices[subject]\n",
    "\n",
    "        for label in label_list:\n",
    "            # It does not matter which fold we choose, so simply choose fold 0\n",
    "            if isinstance(train_indices_for_subject[\"Label_\"+str(label)][\"Fold_0\"], (np.ndarray, list)):\n",
    "                train_indices_to_combine = train_indices_for_subject[\"Label_\"+str(label)][\"Fold_0\"]\n",
    "            else:\n",
    "                train_indices_to_combine = [train_indices_for_subject[\"Label_\"+str(label)][\"Fold_0\"]]\n",
    "\n",
    "            if isinstance(validation_indices_for_subject[\"Label_\"+str(label)][\"Fold_0\"], (np.ndarray, list)):\n",
    "                validation_indices_to_combine = validation_indices_for_subject[\"Label_\"+str(label)][\"Fold_0\"]\n",
    "            else:\n",
    "                validation_indices_to_combine = [validation_indices_for_subject[\"Label_\"+str(label)][\"Fold_0\"]]\n",
    "\n",
    "            final_train_indices[subject][\"Label_\"+str(label)] = np.concatenate((train_indices_to_combine, validation_indices_to_combine))\n",
    "\n",
    "\n",
    "    return final_train_indices\n",
    "      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6853b43c-4209-48b4-bf54-070bd7a5c493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get final training indices\n",
    "final_train_indices = concatenate_final_training_and_test_indices(train_indices, \\\n",
    "                            validation_indices, subject_list, label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8f9d44e3-9774-48be-9ad2-2cfd515b5e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get final test sets\n",
    "X_train_final, y_train_final, X_test_final, y_test_final = helpers.create_final_input_data_dicts(feature_df,          \n",
    "                                        final_train_indices, test_indices, label_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb347f7-c11d-48ae-9673-b66927bee38c",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8f7352b2-bf92-4b3c-aa7f-43cf9cb5ebfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the labels to adequate labels for XGBoost\n",
    "mapping = {1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 7: 5}\n",
    "\n",
    "y_train_final = [mapping[num] for num in y_train_final]\n",
    "y_test_final = [mapping[num] for num in y_test_final]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4fd8e57a-2118-4da6-8364-858895ea051e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9177377892030848\n",
      "Accuracy: 0.9177377892030848\n",
      "Accuracy: 0.921165381319623\n",
      "Accuracy: 0.9177377892030848\n",
      "Accuracy: 0.9143101970865467\n",
      "Accuracy: 0.9177377892030848\n",
      "Accuracy: 0.9160239931448158\n",
      "Accuracy: 0.9185946872322194\n",
      "Accuracy: 0.9203084832904884\n",
      "Accuracy: 0.9160239931448158\n",
      "Mean accuracy 0.9177377892030847, with standard deviation 0.0019160822429304186.\n"
     ]
    }
   ],
   "source": [
    "final_accuracies = [] \n",
    "\n",
    "for seed in range(10):\n",
    "\n",
    "    params = {'seed': seed, 'learning_rate': 0.19, 'max_depth': 8, 'min_child_weight': 0, 'n_estimators': 600, 'subsample': 0.5}\n",
    "\n",
    "    xb = xgb.XGBClassifier(**params)\n",
    "\n",
    "    xb.fit(X_train_final, y_train_final)\n",
    "    y_pred = xb.predict(X_test_final)\n",
    "    accuracy = accuracy_score(y_pred, y_test_final)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "\n",
    "    final_accuracies.append(accuracy)\n",
    "\n",
    "print(\"Mean accuracy \" + str(np.mean(final_accuracies)) + \", with standard deviation \"+str(np.std(final_accuracies)) + \".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2b3313-4bd1-4806-b19c-12b2f0ca2ea3",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "25275729-3eeb-47ae-ad6e-e69b435aff48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9134532990574121\n",
      "Accuracy: 0.9134532990574121\n",
      "Accuracy: 0.9143101970865467\n",
      "Accuracy: 0.9160239931448158\n",
      "Accuracy: 0.9177377892030848\n",
      "Accuracy: 0.9134532990574121\n",
      "Accuracy: 0.9151670951156813\n",
      "Accuracy: 0.9160239931448158\n",
      "Accuracy: 0.9143101970865467\n",
      "Accuracy: 0.9177377892030848\n",
      "Mean accuracy 0.9151670951156812, with standard deviation 0.001580041894994496.\n"
     ]
    }
   ],
   "source": [
    "final_accuracies = [] \n",
    "\n",
    "for seed in range(10):\n",
    "\n",
    "    params =  {'random_state': seed, 'max_depth': 40, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 150}\n",
    "\n",
    "    rf = RandomForestClassifier(**params)\n",
    "\n",
    "    rf.fit(X_train_final, y_train_final)\n",
    "    y_pred = rf.predict(X_test_final)\n",
    "    accuracy = accuracy_score(y_pred, y_test_final)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    \n",
    "    final_accuracies.append(accuracy)\n",
    "\n",
    "print(\"Mean accuracy \" + str(np.mean(final_accuracies)) + \", with standard deviation \"+str(np.std(final_accuracies)) + \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6ad918-b039-43cd-ba79-042c42ea63f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
