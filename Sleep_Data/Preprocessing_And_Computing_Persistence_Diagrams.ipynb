{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "0a81b9c9-a2e9-46c2-8ae8-4a5f02dd0571",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyedflib\n",
    "\n",
    "import pandas as pd\n",
    "from gtda.time_series import SingleTakensEmbedding\n",
    "from gtda.homology import VietorisRipsPersistence\n",
    "from gtda.diagrams import PersistenceEntropy, Amplitude, NumberOfPoints, ComplexPolynomial, PersistenceLandscape, HeatKernel, Silhouette, BettiCurve, PairwiseDistance, ForgetDimension\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9823a6-57bc-4bef-9350-14eb32a035fe",
   "metadata": {},
   "source": [
    "# Choose EEG or EMG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "1a556dad-ea22-4937-811d-6efbdc4aa317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose if you want to look at EEG or EMG data\n",
    "\n",
    "data_type = \"EEG\" # Does not have an effect yet, will be added later when processing anesthesia data\n",
    "#data_type = \"EMG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "id": "bd469fbe-dbb1-4072-86c8-2d0940c16a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = \"293\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "id": "c8dc6d20-d675-46a9-81a6-3238f4e42427",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = [1, 2, 3, 4, 5, 7]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc1f407-122b-4eda-86f0-622f93ccf082",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "id": "85fd9907-0ecf-4827-bd57-da10d9c03cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels\n",
    "\n",
    "# Read data\n",
    "label_data = pd.read_csv(\"Data/Labels_\"+str(subject)+\".csv\")\n",
    "labels = label_data[\"NAPS_Numeric\"].iloc[1:] # The first label is NaN, so remove it\n",
    "\n",
    "# Convert to list\n",
    "labels = [int(label) for label in labels]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "id": "4e523bab-c512-4ef9-b33d-8cecf8ae9082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EEG & EMG data\n",
    "\n",
    "data = pd.read_csv(\"Data/EDF_as_CSV_\"+str(subject)+\"_complete.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "id": "9b634187-6f81-47e7-84e0-b08be141bf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data, labels):\n",
    "\n",
    "    data = data.iloc[2000:] # The first label is NaN... Therefore we have to remove the first 2000 values corresponding to the first label\n",
    "\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Add labels to the main dataframe and Assign labels to data rows in segments \n",
    "    data['Label'] = np.nan\n",
    "    \n",
    "    for label_idx in range(len(labels) - 1):\n",
    "        data.loc[2000 * label_idx : 2000 * (label_idx + 1) - 1, 'Label'] = labels[label_idx]\n",
    "        \n",
    "    # Drop rows where 'Label' is NaN\n",
    "    data.dropna(subset=['Label'], inplace=True)\n",
    "\n",
    "    # Drop columns containing 'Unnamed' in their column name\n",
    "    columns_to_drop = data.filter(like='Unnamed').columns\n",
    "    data.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "id": "09a9749f-b323-4232-9973-33c08ec834fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f_/tyg450s17m53dh3ylrjcmpqc0000gn/T/ipykernel_22972/316733124.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Label'] = np.nan\n",
      "/var/folders/f_/tyg450s17m53dh3ylrjcmpqc0000gn/T/ipykernel_22972/316733124.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.dropna(subset=['Label'], inplace=True)\n",
      "/var/folders/f_/tyg450s17m53dh3ylrjcmpqc0000gn/T/ipykernel_22972/316733124.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.drop(columns=columns_to_drop, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "data = preprocess_data(data, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ea3b4c-8747-430b-9966-2e7eaaca0b74",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53aa0e08-3e63-44f0-90a7-9c713ad37943",
   "metadata": {},
   "source": [
    "## Segmenting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "id": "d49884a0-8301-4331-a50d-fe982c6c6c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labelled_segments_and_indices(label_list, df, data_type, segment_size, step_size = 2):\n",
    "    \"\"\"\n",
    "    Segments time-series data into EEG and EMG segments.\n",
    "\n",
    "    Parameters:\n",
    "    - label_list (list): List of all possible labels\n",
    "    - data (DataFrame): The input dataframe containing the columns \"Time\", \"EEG\" and \"EMG\".\n",
    "    - segment_size (float): The desired size of each segment in seconds.\n",
    "    - step_size (float, optional): The step size of \"Time\" in milliseconds. Default is 2 millisecond.\n",
    "\n",
    "    Returns:\n",
    "    Tuple of two lists:\n",
    "    - List of EEG segments.\n",
    "    - List of EMG segments.\n",
    "    \"\"\"\n",
    "\n",
    "    all_indices = {}\n",
    "\n",
    "    all_segments = {}\n",
    "\n",
    "    for label in label_list:\n",
    "\n",
    "        segments = []\n",
    "       \n",
    "        label_df = df[df['Label'] == label]\n",
    "        \n",
    "        label_df.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        all_indices[\"Label_\"+str(label)] = set(label_df.index*step_size // segment_size // 1000)\n",
    "        \n",
    "        n_segments_of_label = int((len(label_df.index))*step_size) // segment_size // 1000\n",
    "\n",
    "        for segment_idx in range(n_segments_of_label):\n",
    "            start_idx = int(segment_idx* segment_size*1000/step_size)\n",
    "            end_idx = start_idx + int(segment_size*1000/step_size)\n",
    "            segment = label_df[data_type].iloc[start_idx:end_idx]\n",
    "            segments.append(list(segment))\n",
    "\n",
    "        all_segments[label] = segments\n",
    "\n",
    "    \n",
    "    return all_segments, all_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "id": "7696563c-9996-40dd-99bc-8ec2b960bd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment the datass\n",
    "segment_size = 4  # seconds\n",
    "\n",
    "\n",
    "segments, all_indices_dict = get_labelled_segments_and_indices(label_list, data, data_type, segment_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ef2d4e-e600-4c5e-922c-2c475ca13583",
   "metadata": {},
   "source": [
    "# Compute Indices for Cross Validation and Final Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "id": "f4c27549-949f-4bb3-84bc-39b764acb038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose test data set size for classification later (recommended: 0.2-0.3)\n",
    "\n",
    "test_size = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "id": "4db60d9c-1a1c-438d-af72-32095a744099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose number of folds for Cross Validation of the training/validation data\n",
    "\n",
    "n_folds = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00aaf69c-11ab-4c62-9dd3-07289f5e2fe5",
   "metadata": {},
   "source": [
    "### Choose Train and Test Data Indices for Test Set and for Each Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "id": "8b4cd76b-d087-436e-9b23-b441da83d0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_test_set_indices(label_list, segments, test_size):\n",
    "    total_data_length = 0\n",
    "\n",
    "    for label in label_list:\n",
    "        total_data_length += len(segments[label])\n",
    "\n",
    "    train_indices_dict = {}\n",
    "    test_indices_dict = {}\n",
    "    all_indices_dict = {}\n",
    "\n",
    "\n",
    "    for label in label_list:\n",
    "        data_length = len(segments[label])\n",
    "        indices = np.arange(data_length)\n",
    "\n",
    "        # This weird reshaping will later allow us to handle train/test indices of the final test set\n",
    "        # splitting and the Cross Validation sets the same way\n",
    "        # Both of these dictionaries will only contain one key, 0, as if there would be only one fold\n",
    "        train_indices_dict[\"Label_\"+str(label)] = {}\n",
    "        test_indices_dict[\"Label_\"+str(label)] = {}\n",
    "\n",
    "        _, _, _, _, train_indices_dict[\"Label_\"+str(label)][0], test_indices_dict[\"Label_\"+str(label)][0] = train_test_split(segments[label], [label]*data_length, indices, test_size=test_size, random_state=32)\n",
    "\n",
    "        all_indices_dict[\"Label_\"+str(label)] = np.concatenate((train_indices_dict[\"Label_\"+str(label)][0], test_indices_dict[\"Label_\"+str(label)][0]))\n",
    "\n",
    "\n",
    "    return train_indices_dict, test_indices_dict, all_indices_dict\n",
    "\n",
    "\n",
    "# Compute indices for final test set\n",
    "train_indices_dict, test_indices_dict, all_indices_dict = compute_test_set_indices(label_list, segments, test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "id": "528d3fc3-1bff-4a7c-9006-7811597f26e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_train_and_test_indices(all_indices_dict, segments, test_size):\n",
    "    train_indices_dict = {}\n",
    "    test_indices_dict = {}\n",
    "\n",
    "    # Iterate through each label and perform train/test split\n",
    "    for label, indices in all_indices_dict.items():\n",
    "\n",
    "\n",
    "        # Perform train/test split\n",
    "        train_indices, test_indices = train_test_split(all_indices_dict[label], test_size=test_size, random_state=32)\n",
    "\n",
    "\n",
    "        # Store the split indices\n",
    "        train_indices_dict[label] = train_indices\n",
    "        test_indices_dict[label] = test_indices\n",
    "\n",
    "\n",
    "    return train_indices_dict, test_indices_dict\n",
    "\n",
    "\n",
    "# Choose train and test indices\n",
    "train_indices_dict, test_indices_dict = choose_train_and_test_indices(all_indices_dict, segments, test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "id": "dac52537-afd8-45ba-86a1-2f1e0dafdb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_train_and_validation_set_indices_for_cross_validation(label_list, segments, train_indices_dict, n_folds):\n",
    "    \n",
    "    # Initialize Cross Validation\n",
    "    kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "    \n",
    "    train_indices_dict_for_folds = {}\n",
    "    validation_indices_dict_for_folds = {}\n",
    "    \n",
    "    for label in label_list:\n",
    "        label_key = \"Label_\" + str(label)\n",
    "        \n",
    "        # Initialize dictionary for each label\n",
    "        train_indices_dict_for_folds[label_key] = {}\n",
    "        validation_indices_dict_for_folds[label_key] = {}\n",
    "        \n",
    "        label_indices = train_indices_dict[label_key]\n",
    "        \n",
    "        # Use KFold only if there are enough samples for cross-validation\n",
    "        if len(label_indices) >= 5:\n",
    "            for fold, (train_indices, validation_indices) in enumerate(kf.split(label_indices)):\n",
    "                train_indices_dict_for_folds[label_key][f\"Fold_{fold}\"] = label_indices[train_indices]\n",
    "                validation_indices_dict_for_folds[label_key][f\"Fold_{fold}\"] = label_indices[validation_indices]\n",
    "        else:\n",
    "            # Handle case where fewer than 5 samples are available\n",
    "            for fold in range(len(label_indices)):\n",
    "                train_indices_dict_for_folds[label_key][f\"Fold_{fold}\"] = [label_indices[fold]]\n",
    "                validation_indices_dict_for_folds[label_key][f\"Fold_{fold}\"] = [label_indices[fold]]\n",
    "\n",
    "            # Fill in remaining folds with empty lists if needed\n",
    "            for remaining_fold in range(len(label_indices), n_folds):\n",
    "                train_indices_dict_for_folds[label_key][f\"Fold_{remaining_fold}\"] = []\n",
    "                validation_indices_dict_for_folds[label_key][f\"Fold_{remaining_fold}\"] = []\n",
    "    \n",
    "    return train_indices_dict_for_folds, validation_indices_dict_for_folds\n",
    "\n",
    "\n",
    "train_indices_dict_for_folds, validation_indices_dict_for_folds = compute_train_and_validation_set_indices_for_cross_validation(label_list,\n",
    "                                                                                    segments, train_indices_dict, n_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "73f9ea6a-632a-462c-a44f-d8c1194f6a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all indices\n",
    "\n",
    "# Train indices\n",
    "np.save(\"Train_Test_Splitting/\"+str(subject)+\"/Train_Indices_All_Labels_All_Folds.npy\",\\\n",
    "    np.array(train_indices_dict_for_folds, dtype=object), allow_pickle=True)\n",
    "\n",
    "# Validation indices\n",
    "np.save(\"Train_Test_Splitting/\"+str(subject)+\"/Validation_Indices_All_Labels_All_Folds.npy\",\\\n",
    "    np.array(validation_indices_dict_for_folds, dtype=object), allow_pickle=True)\n",
    "\n",
    "# Final Test set indices\n",
    "np.save(\"Train_Test_Splitting/\"+str(subject)+\"/Final_Test_Set_Indices_All_Labels.npy\",\\\n",
    "    np.array(test_indices_dict, dtype=object), allow_pickle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec79840c-3793-4a66-9d7f-d69e0cc90b0a",
   "metadata": {},
   "source": [
    "# Persistence Diagrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0460ed-23ef-45a5-bf45-eafa66888669",
   "metadata": {},
   "source": [
    "## Finding the optimal embedding dimension and time delay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253351f2-ad56-4641-9228-1ea72b78eb35",
   "metadata": {},
   "source": [
    "There are two techniques that can be used to determine these parameters automatically:\n",
    "- Mutual information to determine the time delay\n",
    "- False nearest neighbours to determine the embedding dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5411caea-3b14-45e6-adc5-e86f77235716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the embedding\n",
    "max_embedding_dimension = 30\n",
    "max_time_delay = 30\n",
    "stride = 10\n",
    "\n",
    "embedder = SingleTakensEmbedding(\n",
    "    parameters_type=\"search\",\n",
    "    time_delay=max_time_delay,\n",
    "    dimension=max_embedding_dimension,\n",
    "    stride=stride,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695b8367-ca0f-44da-8bdd-735a8c8794eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_optimal_parameters(embedder, segments, max_index, iterations = 8):\n",
    "    \"\"\"\n",
    "    Finds (approximate) optimal embedding parameters by averaging optimal parameters of random segments.\n",
    "\n",
    "    Parameters:\n",
    "    - embedder (object): defined by SingleTakensEmbedding() or similar\n",
    "    - segments (list of lists): Complete EEG/EMG segments\n",
    "    - max_index (int): How many segments there are\n",
    "    - iteratiors (int): How many random indices to sample\n",
    "\n",
    "    Returns:\n",
    "    Tuple of two floats:\n",
    "    - Average optimal embedding dimension\n",
    "    - Average optimal time delay\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    optimal_embeddings_dimensions = []\n",
    "    optimal_time_delays = []\n",
    "    \n",
    "    for _ in range(iterations):\n",
    "        random_index = random.randint(0, max_index)\n",
    "        embedding = embedder.fit_transform(segments[random_index])\n",
    "        \n",
    "         # append optimal embedding dimension for this segment\n",
    "        optimal_embeddings_dimensions.append(embedder.dimension_)\n",
    "\n",
    "        # append optimal time delay for this segment\n",
    "        optimal_time_delays.append(embedder.time_delay_)\n",
    "\n",
    "        print(\"The optimal embedding dimension is \" + str(np.mean(optimal_embeddings_dimensions)) + \n",
    "              \" and the optimal time delay is \" + str(np.mean(optimal_time_delays)))\n",
    "        \n",
    "        return int(np.mean(optimal_embeddings_dimensions)), int(np.mean(optimal_time_delays))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9909742-300d-43a9-91cf-fa7b1a579007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute optimal embedding parameters\n",
    "    \n",
    "embedding_dimension, embedding_time_delay = find_optimal_parameters(embedder, all_segments, len(all_segments), iterations = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24ae14f-02bd-46f3-86dc-36059171e678",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ae774c-2bca-448a-b292-676e26190097",
   "metadata": {},
   "source": [
    "## Creating Persistence Diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d6e233-e614-42cf-b4bc-e1cf83874dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting parameters for point cloud embeddings\n",
    "\n",
    "#embedding_dimension= 3 # for data exploration\n",
    "\n",
    "embedder = SingleTakensEmbedding(\n",
    "    parameters_type=\"fixed\",\n",
    "    n_jobs=2,\n",
    "    time_delay=embedding_time_delay, # computed above\n",
    "    dimension=embedding_dimension, # computed above\n",
    "    stride=stride,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aeaf116-7c67-4b3f-849e-d827a751a0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will look at 0, 1 and 2 dimensional holes\n",
    "homology_dimensions = [0, 1, 2]\n",
    "\n",
    "# We will use a Vietoris Rips filtrations\n",
    "persistence = VietorisRipsPersistence(\n",
    "    homology_dimensions=homology_dimensions, n_jobs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b27aa0-db64-4d55-b188-53f3b5445523",
   "metadata": {},
   "source": [
    "### Computing Points Clouds and Persistence Diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6b0723-13f1-44c1-9d5c-a3e0b4dd0d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_embeddings_and_diagrams(segments, time_delay_embeddings, persistence_diagrams, all_indices_dict, label):\n",
    "\n",
    "    time_delay_embeddings[\"Label_\"+str(label)] = []\n",
    "    persistence_diagrams[\"Label_\"+str(label)] = []\n",
    "\n",
    "    # Compute embeddings and diagrams for the complete data\n",
    "    for diagram_idx in range(len(segments[label])):\n",
    "        time_delay_embeddings[\"Label_\"+str(label)].append(embedder.fit_transform(segments[label][diagram_idx])[None, :, :])\n",
    "        persistence_diagrams[\"Label_\"+str(label)].append(persistence.fit_transform(time_delay_embeddings[\"Label_\"+str(label)][diagram_idx]))\n",
    "    \n",
    "    return time_delay_embeddings, persistence_diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03146bc-60f9-4e04-9422-0d864900104e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute embeddings and persistence diagrams for the complete data\n",
    "\n",
    "time_delay_embeddings = {}\n",
    "persistence_diagrams = {}\n",
    "\n",
    "for label in label_list:\n",
    "    time_delay_embeddings, persistence_diagrams = compute_embeddings_and_diagrams(segments, time_delay_embeddings, persistence_diagrams, all_indices_dict, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c3e42a-c2f5-4442-8c57-bb8d07407c47",
   "metadata": {},
   "source": [
    "## Save persistence diagrams and embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f008c63-4e40-4e86-8126-67ecb0ba41a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persistence diagrams\n",
    "np.save('Embeddings_and_Persistence_Diagrams/'+str(subject)+'/'+str(data_type)+'/Persistence_Diagrams_All_Labels.npy', \\\n",
    "            np.array(persistence_diagrams, dtype=object), allow_pickle=True)\n",
    "\n",
    "# Embeddings\n",
    "np.save('Embeddings_and_Persistence_Diagrams/'+str(subject)+'/'+str(data_type)+'/Embeddings_All_Labels'+\\\n",
    "            '_Embedding_Dim'+str(embedding_dimension)+'.npy', np.array(time_delay_embeddings, dtype=object), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3448e0e-df40-4181-b408-024740fde8b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd054e7c-9a3e-42cc-bcfc-810036cd48f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
